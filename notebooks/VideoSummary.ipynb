{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in AI_101(5min).mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Path to your video file\n",
    "video_path = \"AI_101.mp4\"\n",
    "\n",
    "# Create a video clip object\n",
    "clip = VideoFileClip(video_path)\n",
    "\n",
    "clip = clip.subclip(127, 427) \n",
    "\n",
    "# Extract audio and save as mp3\n",
    "clip.audio.write_audiofile(\"AI_101(5min).mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate transcripts with timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper_timestamped as whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.load_audio(\"../../../AI_101(5min).mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:54<00:00, 549.90frames/s]\n"
     ]
    }
   ],
   "source": [
    "result = whisper.transcribe(model, audio, language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway. So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time. All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI. Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI. So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far. Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand. So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do. As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 13.14,\n",
       "   'text': ' the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult.',\n",
       "   'tokens': [50364,\n",
       "    264,\n",
       "    2135,\n",
       "    30681,\n",
       "    11,\n",
       "    597,\n",
       "    307,\n",
       "    365,\n",
       "    264,\n",
       "    558,\n",
       "    1412,\n",
       "    293,\n",
       "    264,\n",
       "    558,\n",
       "    2316,\n",
       "    11,\n",
       "    11677,\n",
       "    7599,\n",
       "    393,\n",
       "    5039,\n",
       "    867,\n",
       "    2740,\n",
       "    11,\n",
       "    457,\n",
       "    10875,\n",
       "    264,\n",
       "    558,\n",
       "    1154,\n",
       "    11,\n",
       "    5006,\n",
       "    264,\n",
       "    558,\n",
       "    1412,\n",
       "    293,\n",
       "    3097,\n",
       "    264,\n",
       "    558,\n",
       "    2316,\n",
       "    393,\n",
       "    312,\n",
       "    2252,\n",
       "    13,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11746751240321568,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.027983587235212326,\n",
       "   'confidence': 0.871,\n",
       "   'words': [{'text': 'the', 'start': 0.0, 'end': 0.06, 'confidence': 0.097},\n",
       "    {'text': 'main', 'start': 0.06, 'end': 0.32, 'confidence': 0.9},\n",
       "    {'text': 'takeaway,', 'start': 0.32, 'end': 0.78, 'confidence': 0.972},\n",
       "    {'text': 'which', 'start': 1.3, 'end': 1.38, 'confidence': 0.965},\n",
       "    {'text': 'is', 'start': 1.38, 'end': 1.82, 'confidence': 0.996},\n",
       "    {'text': 'with', 'start': 1.82, 'end': 2.16, 'confidence': 0.712},\n",
       "    {'text': 'the', 'start': 2.16, 'end': 2.34, 'confidence': 0.969},\n",
       "    {'text': 'right', 'start': 2.34, 'end': 2.52, 'confidence': 0.995},\n",
       "    {'text': 'data', 'start': 2.52, 'end': 2.88, 'confidence': 0.991},\n",
       "    {'text': 'and', 'start': 2.88, 'end': 3.18, 'confidence': 0.716},\n",
       "    {'text': 'the', 'start': 3.18, 'end': 3.28, 'confidence': 0.986},\n",
       "    {'text': 'right', 'start': 3.28, 'end': 3.42, 'confidence': 0.982},\n",
       "    {'text': 'model,', 'start': 3.42, 'end': 3.9, 'confidence': 0.93},\n",
       "    {'text': 'artificial', 'start': 4.02, 'end': 4.58, 'confidence': 0.723},\n",
       "    {'text': 'intelligence', 'start': 4.58, 'end': 5.06, 'confidence': 0.961},\n",
       "    {'text': 'can', 'start': 5.06, 'end': 5.28, 'confidence': 0.533},\n",
       "    {'text': 'solve', 'start': 5.28, 'end': 5.56, 'confidence': 0.991},\n",
       "    {'text': 'many', 'start': 5.56, 'end': 5.78, 'confidence': 0.968},\n",
       "    {'text': 'problems,', 'start': 5.78, 'end': 6.38, 'confidence': 0.987},\n",
       "    {'text': 'but', 'start': 6.76, 'end': 7.56, 'confidence': 0.897},\n",
       "    {'text': 'choosing', 'start': 7.56, 'end': 8.38, 'confidence': 0.971},\n",
       "    {'text': 'the', 'start': 8.38, 'end': 8.52, 'confidence': 0.99},\n",
       "    {'text': 'right', 'start': 8.52, 'end': 8.68, 'confidence': 0.991},\n",
       "    {'text': 'problem,', 'start': 8.68, 'end': 9.34, 'confidence': 0.975},\n",
       "    {'text': 'finding', 'start': 10.0, 'end': 10.1, 'confidence': 0.916},\n",
       "    {'text': 'the', 'start': 10.1, 'end': 10.28, 'confidence': 0.996},\n",
       "    {'text': 'right', 'start': 10.28, 'end': 10.46, 'confidence': 0.997},\n",
       "    {'text': 'data', 'start': 10.46, 'end': 10.78, 'confidence': 0.995},\n",
       "    {'text': 'and', 'start': 10.78, 'end': 11.04, 'confidence': 0.922},\n",
       "    {'text': 'training', 'start': 11.04, 'end': 11.28, 'confidence': 0.963},\n",
       "    {'text': 'the', 'start': 11.28, 'end': 11.44, 'confidence': 0.974},\n",
       "    {'text': 'right', 'start': 11.44, 'end': 11.6, 'confidence': 0.996},\n",
       "    {'text': 'model', 'start': 11.6, 'end': 11.98, 'confidence': 0.994},\n",
       "    {'text': 'can', 'start': 11.98, 'end': 12.4, 'confidence': 0.847},\n",
       "    {'text': 'be', 'start': 12.4, 'end': 12.76, 'confidence': 0.996},\n",
       "    {'text': 'difficult.', 'start': 12.76, 'end': 13.14, 'confidence': 0.99}]},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 13.5,\n",
       "   'end': 16.04,\n",
       "   'text': \" So, there's nothing else that you remember from today's workshop.\",\n",
       "   'tokens': [51064,\n",
       "    407,\n",
       "    11,\n",
       "    456,\n",
       "    311,\n",
       "    1825,\n",
       "    1646,\n",
       "    300,\n",
       "    291,\n",
       "    1604,\n",
       "    490,\n",
       "    965,\n",
       "    311,\n",
       "    13541,\n",
       "    13,\n",
       "    51214],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11746751240321568,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.027983587235212326,\n",
       "   'confidence': 0.993,\n",
       "   'words': [{'text': 'So,', 'start': 13.5, 'end': 13.9, 'confidence': 0.985},\n",
       "    {'text': \"there's\", 'start': 14.16, 'end': 14.34, 'confidence': 0.993},\n",
       "    {'text': 'nothing', 'start': 14.34, 'end': 14.56, 'confidence': 1.0},\n",
       "    {'text': 'else', 'start': 14.56, 'end': 14.76, 'confidence': 0.999},\n",
       "    {'text': 'that', 'start': 14.76, 'end': 14.88, 'confidence': 0.961},\n",
       "    {'text': 'you', 'start': 14.88, 'end': 14.98, 'confidence': 0.999},\n",
       "    {'text': 'remember', 'start': 14.98, 'end': 15.18, 'confidence': 0.991},\n",
       "    {'text': 'from', 'start': 15.18, 'end': 15.36, 'confidence': 0.999},\n",
       "    {'text': \"today's\", 'start': 15.36, 'end': 15.68, 'confidence': 0.999},\n",
       "    {'text': 'workshop.', 'start': 15.68, 'end': 16.04, 'confidence': 0.998}]},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 16.5,\n",
       "   'end': 18.42,\n",
       "   'text': ' This slide is the key takeaway.',\n",
       "   'tokens': [51214, 639, 4137, 307, 264, 2141, 30681, 13, 51414],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11746751240321568,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.027983587235212326,\n",
       "   'confidence': 0.994,\n",
       "   'words': [{'text': 'This',\n",
       "     'start': 16.5,\n",
       "     'end': 17.24,\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'slide', 'start': 17.24, 'end': 17.52, 'confidence': 0.999},\n",
       "    {'text': 'is', 'start': 17.52, 'end': 17.7, 'confidence': 0.999},\n",
       "    {'text': 'the', 'start': 17.7, 'end': 17.82, 'confidence': 0.999},\n",
       "    {'text': 'key', 'start': 17.82, 'end': 18.02, 'confidence': 0.998},\n",
       "    {'text': 'takeaway.', 'start': 18.02, 'end': 18.42, 'confidence': 0.993}]},\n",
       "  {'id': 3,\n",
       "   'seek': 2100,\n",
       "   'start': 21.0,\n",
       "   'end': 30.18,\n",
       "   'text': \" So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning.\",\n",
       "   'tokens': [50364,\n",
       "    407,\n",
       "    11,\n",
       "    411,\n",
       "    286,\n",
       "    848,\n",
       "    11,\n",
       "    321,\n",
       "    603,\n",
       "    2060,\n",
       "    11677,\n",
       "    7599,\n",
       "    11,\n",
       "    321,\n",
       "    486,\n",
       "    536,\n",
       "    257,\n",
       "    1326,\n",
       "    819,\n",
       "    5110,\n",
       "    295,\n",
       "    3873,\n",
       "    300,\n",
       "    393,\n",
       "    312,\n",
       "    1143,\n",
       "    281,\n",
       "    4445,\n",
       "    11677,\n",
       "    7599,\n",
       "    3009,\n",
       "    746,\n",
       "    1219,\n",
       "    3479,\n",
       "    2539,\n",
       "    13,\n",
       "    50864],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0935305186680385,\n",
       "   'compression_ratio': 1.9715447154471544,\n",
       "   'no_speech_prob': 0.4981095492839813,\n",
       "   'confidence': 0.925,\n",
       "   'words': [{'text': 'So,', 'start': 21.0, 'end': 21.02, 'confidence': 0.381},\n",
       "    {'text': 'like', 'start': 21.02, 'end': 21.06, 'confidence': 0.537},\n",
       "    {'text': 'I', 'start': 21.06, 'end': 21.18, 'confidence': 0.994},\n",
       "    {'text': 'said,', 'start': 21.18, 'end': 21.56, 'confidence': 0.999},\n",
       "    {'text': \"we'll\", 'start': 21.8, 'end': 21.92, 'confidence': 0.969},\n",
       "    {'text': 'cover', 'start': 21.92, 'end': 22.1, 'confidence': 0.995},\n",
       "    {'text': 'artificial', 'start': 22.1, 'end': 22.54, 'confidence': 0.943},\n",
       "    {'text': 'intelligence,',\n",
       "     'start': 22.54,\n",
       "     'end': 23.1,\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'we', 'start': 23.5, 'end': 23.52, 'confidence': 0.995},\n",
       "    {'text': 'will', 'start': 23.52, 'end': 23.88, 'confidence': 0.998},\n",
       "    {'text': 'see', 'start': 23.88, 'end': 24.6, 'confidence': 0.999},\n",
       "    {'text': 'a', 'start': 24.6, 'end': 24.76, 'confidence': 0.987},\n",
       "    {'text': 'few', 'start': 24.76, 'end': 24.82, 'confidence': 1.0},\n",
       "    {'text': 'different', 'start': 24.82, 'end': 25.1, 'confidence': 0.999},\n",
       "    {'text': 'examples', 'start': 25.1, 'end': 25.54, 'confidence': 0.998},\n",
       "    {'text': 'of', 'start': 25.54, 'end': 25.78, 'confidence': 0.999},\n",
       "    {'text': 'tools', 'start': 25.78, 'end': 26.24, 'confidence': 0.999},\n",
       "    {'text': 'that', 'start': 26.24, 'end': 26.52, 'confidence': 0.996},\n",
       "    {'text': 'can', 'start': 26.52, 'end': 26.7, 'confidence': 1.0},\n",
       "    {'text': 'be', 'start': 26.7, 'end': 26.84, 'confidence': 1.0},\n",
       "    {'text': 'used', 'start': 26.84, 'end': 27.02, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 27.02, 'end': 27.22, 'confidence': 0.982},\n",
       "    {'text': 'implement', 'start': 27.22, 'end': 27.5, 'confidence': 0.996},\n",
       "    {'text': 'artificial', 'start': 27.5, 'end': 28.04, 'confidence': 0.964},\n",
       "    {'text': 'intelligence',\n",
       "     'start': 28.04,\n",
       "     'end': 28.56,\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'including', 'start': 28.56, 'end': 28.98, 'confidence': 0.579},\n",
       "    {'text': 'something', 'start': 28.98, 'end': 29.26, 'confidence': 0.999},\n",
       "    {'text': 'called', 'start': 29.26, 'end': 29.52, 'confidence': 0.999},\n",
       "    {'text': 'machine', 'start': 29.52, 'end': 29.76, 'confidence': 0.963},\n",
       "    {'text': 'learning.', 'start': 29.76, 'end': 30.18, 'confidence': 0.996}]},\n",
       "  {'id': 4,\n",
       "   'seek': 2100,\n",
       "   'start': 30.58,\n",
       "   'end': 42.57,\n",
       "   'text': \" We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a\",\n",
       "   'tokens': [50864,\n",
       "    492,\n",
       "    603,\n",
       "    751,\n",
       "    466,\n",
       "    819,\n",
       "    3685,\n",
       "    295,\n",
       "    3479,\n",
       "    2539,\n",
       "    293,\n",
       "    819,\n",
       "    2740,\n",
       "    300,\n",
       "    393,\n",
       "    312,\n",
       "    13041,\n",
       "    538,\n",
       "    3479,\n",
       "    2539,\n",
       "    13,\n",
       "    400,\n",
       "    718,\n",
       "    385,\n",
       "    445,\n",
       "    584,\n",
       "    1670,\n",
       "    1391,\n",
       "    257,\n",
       "    688,\n",
       "    295,\n",
       "    291,\n",
       "    366,\n",
       "    1217,\n",
       "    6359,\n",
       "    11,\n",
       "    437,\n",
       "    307,\n",
       "    2452,\n",
       "    2539,\n",
       "    2452,\n",
       "    2539,\n",
       "    307,\n",
       "    2139,\n",
       "    257,\n",
       "    25993,\n",
       "    420,\n",
       "    257,\n",
       "    25993,\n",
       "    295,\n",
       "    257,\n",
       "    51464],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0935305186680385,\n",
       "   'compression_ratio': 1.9715447154471544,\n",
       "   'no_speech_prob': 0.4981095492839813,\n",
       "   'confidence': 0.931,\n",
       "   'words': [{'text': \"We'll\",\n",
       "     'start': 30.58,\n",
       "     'end': 30.84,\n",
       "     'confidence': 0.898},\n",
       "    {'text': 'talk', 'start': 30.84, 'end': 30.96, 'confidence': 0.999},\n",
       "    {'text': 'about', 'start': 30.96, 'end': 31.22, 'confidence': 1.0},\n",
       "    {'text': 'different', 'start': 31.22, 'end': 31.54, 'confidence': 0.999},\n",
       "    {'text': 'kinds', 'start': 31.54, 'end': 31.88, 'confidence': 0.999},\n",
       "    {'text': 'of', 'start': 31.88, 'end': 32.04, 'confidence': 1.0},\n",
       "    {'text': 'machine', 'start': 32.04, 'end': 32.24, 'confidence': 0.991},\n",
       "    {'text': 'learning', 'start': 32.24, 'end': 32.52, 'confidence': 0.999},\n",
       "    {'text': 'and', 'start': 32.52, 'end': 32.68, 'confidence': 0.94},\n",
       "    {'text': 'different', 'start': 32.68, 'end': 32.88, 'confidence': 0.997},\n",
       "    {'text': 'problems', 'start': 32.88, 'end': 33.24, 'confidence': 0.999},\n",
       "    {'text': 'that', 'start': 33.24, 'end': 33.42, 'confidence': 0.999},\n",
       "    {'text': 'can', 'start': 33.42, 'end': 33.56, 'confidence': 1.0},\n",
       "    {'text': 'be', 'start': 33.56, 'end': 33.68, 'confidence': 1.0},\n",
       "    {'text': 'solved', 'start': 33.68, 'end': 34.2, 'confidence': 0.999},\n",
       "    {'text': 'by', 'start': 34.2, 'end': 34.58, 'confidence': 0.991},\n",
       "    {'text': 'machine', 'start': 34.58, 'end': 34.84, 'confidence': 0.995},\n",
       "    {'text': 'learning.', 'start': 34.84, 'end': 35.2, 'confidence': 0.999},\n",
       "    {'text': 'And', 'start': 35.44, 'end': 35.92, 'confidence': 0.966},\n",
       "    {'text': 'let', 'start': 35.92, 'end': 36.14, 'confidence': 0.952},\n",
       "    {'text': 'me', 'start': 36.14, 'end': 36.28, 'confidence': 1.0},\n",
       "    {'text': 'just', 'start': 36.28, 'end': 36.48, 'confidence': 1.0},\n",
       "    {'text': 'say', 'start': 36.48, 'end': 36.66, 'confidence': 0.999},\n",
       "    {'text': 'since', 'start': 36.66, 'end': 36.86, 'confidence': 0.94},\n",
       "    {'text': 'probably', 'start': 36.86, 'end': 37.2, 'confidence': 0.998},\n",
       "    {'text': 'a', 'start': 37.2, 'end': 37.32, 'confidence': 0.999},\n",
       "    {'text': 'lot', 'start': 37.32, 'end': 37.42, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 37.42, 'end': 37.5, 'confidence': 1.0},\n",
       "    {'text': 'you', 'start': 37.5, 'end': 37.66, 'confidence': 0.999},\n",
       "    {'text': 'are', 'start': 37.66, 'end': 37.86, 'confidence': 0.997},\n",
       "    {'text': 'already', 'start': 37.86, 'end': 38.12, 'confidence': 0.999},\n",
       "    {'text': 'wondering,', 'start': 38.12, 'end': 38.5, 'confidence': 0.999},\n",
       "    {'text': 'what', 'start': 38.84, 'end': 38.9, 'confidence': 0.916},\n",
       "    {'text': 'is', 'start': 38.9, 'end': 39.04, 'confidence': 0.765},\n",
       "    {'text': 'deep', 'start': 39.04, 'end': 39.18, 'confidence': 0.965},\n",
       "    {'text': 'learning', 'start': 39.18, 'end': 39.54, 'confidence': 0.995},\n",
       "    {'text': 'deep', 'start': 39.54, 'end': 39.94, 'confidence': 0.533},\n",
       "    {'text': 'learning', 'start': 39.94, 'end': 40.22, 'confidence': 0.989},\n",
       "    {'text': 'is', 'start': 40.22, 'end': 40.52, 'confidence': 0.971},\n",
       "    {'text': 'either', 'start': 40.52, 'end': 40.78, 'confidence': 0.969},\n",
       "    {'text': 'a', 'start': 40.78, 'end': 41.08, 'confidence': 0.888},\n",
       "    {'text': 'subset', 'start': 41.08, 'end': 41.44, 'confidence': 0.98},\n",
       "    {'text': 'or', 'start': 41.44, 'end': 41.8, 'confidence': 0.665},\n",
       "    {'text': 'a', 'start': 41.8, 'end': 42.0, 'confidence': 0.851},\n",
       "    {'text': 'subset', 'start': 42.0, 'end': 42.34, 'confidence': 0.726},\n",
       "    {'text': 'of', 'start': 42.34, 'end': 42.52, 'confidence': 0.629},\n",
       "    {'text': 'a', 'start': 42.52, 'end': 42.57, 'confidence': 0.683}]},\n",
       "  {'id': 5,\n",
       "   'seek': 2100,\n",
       "   'start': 42.57,\n",
       "   'end': 44.4,\n",
       "   'text': ' subset of machine learning.',\n",
       "   'tokens': [51464, 25993, 295, 3479, 2539, 13, 51564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0935305186680385,\n",
       "   'compression_ratio': 1.9715447154471544,\n",
       "   'no_speech_prob': 0.4981095492839813,\n",
       "   'confidence': 0.871,\n",
       "   'words': [{'text': 'subset',\n",
       "     'start': 42.57,\n",
       "     'end': 43.02,\n",
       "     'confidence': 0.586},\n",
       "    {'text': 'of', 'start': 43.02, 'end': 43.74, 'confidence': 0.994},\n",
       "    {'text': 'machine', 'start': 43.74, 'end': 44.02, 'confidence': 0.99},\n",
       "    {'text': 'learning.', 'start': 44.02, 'end': 44.4, 'confidence': 0.995}]},\n",
       "  {'id': 6,\n",
       "   'seek': 4500,\n",
       "   'start': 45.0,\n",
       "   'end': 57.54,\n",
       "   'text': \" So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals\",\n",
       "   'tokens': [50364,\n",
       "    407,\n",
       "    337,\n",
       "    729,\n",
       "    295,\n",
       "    291,\n",
       "    567,\n",
       "    366,\n",
       "    4963,\n",
       "    365,\n",
       "    18161,\n",
       "    9590,\n",
       "    420,\n",
       "    2452,\n",
       "    2539,\n",
       "    300,\n",
       "    307,\n",
       "    257,\n",
       "    2290,\n",
       "    300,\n",
       "    1062,\n",
       "    312,\n",
       "    1143,\n",
       "    294,\n",
       "    3479,\n",
       "    2539,\n",
       "    2740,\n",
       "    11,\n",
       "    321,\n",
       "    1582,\n",
       "    380,\n",
       "    751,\n",
       "    466,\n",
       "    300,\n",
       "    294,\n",
       "    604,\n",
       "    7161,\n",
       "    412,\n",
       "    439,\n",
       "    965,\n",
       "    457,\n",
       "    286,\n",
       "    1454,\n",
       "    300,\n",
       "    538,\n",
       "    264,\n",
       "    917,\n",
       "    295,\n",
       "    264,\n",
       "    13541,\n",
       "    11,\n",
       "    291,\n",
       "    1074,\n",
       "    486,\n",
       "    362,\n",
       "    264,\n",
       "    29505,\n",
       "    51014],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08318398215553978,\n",
       "   'compression_ratio': 1.6496062992125984,\n",
       "   'no_speech_prob': 0.19128207862377167,\n",
       "   'confidence': 0.946,\n",
       "   'words': [{'text': 'So', 'start': 45.0, 'end': 45.16, 'confidence': 0.904},\n",
       "    {'text': 'for', 'start': 45.16, 'end': 45.4, 'confidence': 0.808},\n",
       "    {'text': 'those', 'start': 45.4, 'end': 45.56, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 45.56, 'end': 45.68, 'confidence': 0.999},\n",
       "    {'text': 'you', 'start': 45.68, 'end': 45.8, 'confidence': 0.998},\n",
       "    {'text': 'who', 'start': 45.8, 'end': 46.44, 'confidence': 0.856},\n",
       "    {'text': 'are', 'start': 46.44, 'end': 46.62, 'confidence': 0.998},\n",
       "    {'text': 'familiar', 'start': 46.62, 'end': 46.88, 'confidence': 0.871},\n",
       "    {'text': 'with', 'start': 46.88, 'end': 47.1, 'confidence': 0.999},\n",
       "    {'text': 'neural', 'start': 47.1, 'end': 47.32, 'confidence': 0.968},\n",
       "    {'text': 'networks', 'start': 47.32, 'end': 47.68, 'confidence': 0.999},\n",
       "    {'text': 'or', 'start': 47.68, 'end': 47.84, 'confidence': 0.885},\n",
       "    {'text': 'deep', 'start': 47.84, 'end': 47.98, 'confidence': 0.994},\n",
       "    {'text': 'learning', 'start': 47.98, 'end': 48.2, 'confidence': 0.999},\n",
       "    {'text': 'that', 'start': 48.2, 'end': 48.46, 'confidence': 0.836},\n",
       "    {'text': 'is', 'start': 48.46, 'end': 49.2, 'confidence': 0.999},\n",
       "    {'text': 'a', 'start': 49.2, 'end': 49.84, 'confidence': 0.994},\n",
       "    {'text': 'tool', 'start': 49.84, 'end': 50.14, 'confidence': 0.999},\n",
       "    {'text': 'that', 'start': 50.14, 'end': 50.28, 'confidence': 1.0},\n",
       "    {'text': 'might', 'start': 50.28, 'end': 50.46, 'confidence': 0.999},\n",
       "    {'text': 'be', 'start': 50.46, 'end': 50.58, 'confidence': 1.0},\n",
       "    {'text': 'used', 'start': 50.58, 'end': 50.84, 'confidence': 0.999},\n",
       "    {'text': 'in', 'start': 50.84, 'end': 51.16, 'confidence': 0.999},\n",
       "    {'text': 'machine', 'start': 51.16, 'end': 51.4, 'confidence': 0.992},\n",
       "    {'text': 'learning', 'start': 51.4, 'end': 51.62, 'confidence': 1.0},\n",
       "    {'text': 'problems,', 'start': 51.62, 'end': 51.96, 'confidence': 0.996},\n",
       "    {'text': 'we', 'start': 52.28, 'end': 52.32, 'confidence': 0.997},\n",
       "    {'text': \"won't\", 'start': 52.32, 'end': 52.56, 'confidence': 0.959},\n",
       "    {'text': 'talk', 'start': 52.56, 'end': 52.8, 'confidence': 0.99},\n",
       "    {'text': 'about', 'start': 52.8, 'end': 53.04, 'confidence': 1.0},\n",
       "    {'text': 'that', 'start': 53.04, 'end': 53.28, 'confidence': 0.999},\n",
       "    {'text': 'in', 'start': 53.28, 'end': 53.44, 'confidence': 0.955},\n",
       "    {'text': 'any', 'start': 53.44, 'end': 53.6, 'confidence': 0.997},\n",
       "    {'text': 'depth', 'start': 53.6, 'end': 53.78, 'confidence': 0.999},\n",
       "    {'text': 'at', 'start': 53.78, 'end': 53.94, 'confidence': 0.945},\n",
       "    {'text': 'all', 'start': 53.94, 'end': 54.1, 'confidence': 1.0},\n",
       "    {'text': 'today', 'start': 54.1, 'end': 54.4, 'confidence': 0.994},\n",
       "    {'text': 'but', 'start': 54.4, 'end': 54.6, 'confidence': 0.84},\n",
       "    {'text': 'I', 'start': 54.6, 'end': 54.74, 'confidence': 0.989},\n",
       "    {'text': 'hope', 'start': 54.74, 'end': 54.94, 'confidence': 1.0},\n",
       "    {'text': 'that', 'start': 54.94, 'end': 55.06, 'confidence': 0.999},\n",
       "    {'text': 'by', 'start': 55.06, 'end': 55.16, 'confidence': 0.986},\n",
       "    {'text': 'the', 'start': 55.16, 'end': 55.26, 'confidence': 0.999},\n",
       "    {'text': 'end', 'start': 55.26, 'end': 55.36, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 55.36, 'end': 55.46, 'confidence': 0.999},\n",
       "    {'text': 'the', 'start': 55.46, 'end': 55.56, 'confidence': 0.998},\n",
       "    {'text': 'workshop,', 'start': 55.56, 'end': 55.96, 'confidence': 0.999},\n",
       "    {'text': 'you', 'start': 56.24, 'end': 56.36, 'confidence': 0.843},\n",
       "    {'text': 'guys', 'start': 56.36, 'end': 56.5, 'confidence': 0.941},\n",
       "    {'text': 'will', 'start': 56.5, 'end': 56.7, 'confidence': 0.913},\n",
       "    {'text': 'have', 'start': 56.7, 'end': 56.9, 'confidence': 0.844},\n",
       "    {'text': 'the', 'start': 56.9, 'end': 57.06, 'confidence': 0.559},\n",
       "    {'text': 'fundamentals',\n",
       "     'start': 57.06,\n",
       "     'end': 57.54,\n",
       "     'confidence': 0.597}]},\n",
       "  {'id': 7,\n",
       "   'seek': 4500,\n",
       "   'start': 57.54,\n",
       "   'end': 65.28,\n",
       "   'text': ' necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.',\n",
       "   'tokens': [51014,\n",
       "    4818,\n",
       "    281,\n",
       "    2528,\n",
       "    666,\n",
       "    2452,\n",
       "    2539,\n",
       "    412,\n",
       "    257,\n",
       "    24106,\n",
       "    1496,\n",
       "    13,\n",
       "    759,\n",
       "    291,\n",
       "    528,\n",
       "    281,\n",
       "    360,\n",
       "    300,\n",
       "    13,\n",
       "    2188,\n",
       "    661,\n",
       "    565,\n",
       "    13,\n",
       "    51464],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08318398215553978,\n",
       "   'compression_ratio': 1.6496062992125984,\n",
       "   'no_speech_prob': 0.19128207862377167,\n",
       "   'confidence': 0.943,\n",
       "   'words': [{'text': 'necessary',\n",
       "     'start': 57.54,\n",
       "     'end': 58.18,\n",
       "     'confidence': 0.937},\n",
       "    {'text': 'to', 'start': 58.18, 'end': 59.08, 'confidence': 0.998},\n",
       "    {'text': 'dig', 'start': 59.08, 'end': 59.42, 'confidence': 0.998},\n",
       "    {'text': 'into', 'start': 59.42, 'end': 59.62, 'confidence': 0.991},\n",
       "    {'text': 'deep', 'start': 59.62, 'end': 59.84, 'confidence': 0.996},\n",
       "    {'text': 'learning', 'start': 59.84, 'end': 60.26, 'confidence': 0.999},\n",
       "    {'text': 'at', 'start': 60.26, 'end': 60.78, 'confidence': 0.894},\n",
       "    {'text': 'a', 'start': 60.78, 'end': 60.94, 'confidence': 0.998},\n",
       "    {'text': 'conceptual', 'start': 60.94, 'end': 61.34, 'confidence': 0.999},\n",
       "    {'text': 'level.', 'start': 61.34, 'end': 61.84, 'confidence': 0.999},\n",
       "    {'text': 'If', 'start': 61.98, 'end': 62.48, 'confidence': 0.774},\n",
       "    {'text': 'you', 'start': 62.48, 'end': 62.6, 'confidence': 1.0},\n",
       "    {'text': 'want', 'start': 62.6, 'end': 62.7, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 62.7, 'end': 62.78, 'confidence': 1.0},\n",
       "    {'text': 'do', 'start': 62.78, 'end': 62.92, 'confidence': 0.999},\n",
       "    {'text': 'that.', 'start': 62.92, 'end': 63.66, 'confidence': 0.998},\n",
       "    {'text': 'Some', 'start': 63.84, 'end': 63.86, 'confidence': 0.537},\n",
       "    {'text': 'other', 'start': 63.86, 'end': 64.02, 'confidence': 0.985},\n",
       "    {'text': 'time.', 'start': 64.02, 'end': 65.28, 'confidence': 0.975}]},\n",
       "  {'id': 8,\n",
       "   'seek': 4500,\n",
       "   'start': 66.5,\n",
       "   'end': 69.64,\n",
       "   'text': \" All that being said, let's get into basics of AI.\",\n",
       "   'tokens': [51464,\n",
       "    1057,\n",
       "    300,\n",
       "    885,\n",
       "    848,\n",
       "    11,\n",
       "    718,\n",
       "    311,\n",
       "    483,\n",
       "    666,\n",
       "    14688,\n",
       "    295,\n",
       "    7318,\n",
       "    13,\n",
       "    51664],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08318398215553978,\n",
       "   'compression_ratio': 1.6496062992125984,\n",
       "   'no_speech_prob': 0.19128207862377167,\n",
       "   'confidence': 0.918,\n",
       "   'words': [{'text': 'All', 'start': 66.5, 'end': 66.7, 'confidence': 0.55},\n",
       "    {'text': 'that', 'start': 66.7, 'end': 66.84, 'confidence': 0.814},\n",
       "    {'text': 'being', 'start': 66.84, 'end': 67.04, 'confidence': 0.998},\n",
       "    {'text': 'said,', 'start': 67.04, 'end': 67.42, 'confidence': 1.0},\n",
       "    {'text': \"let's\", 'start': 67.76, 'end': 67.98, 'confidence': 0.99},\n",
       "    {'text': 'get', 'start': 67.98, 'end': 68.16, 'confidence': 0.999},\n",
       "    {'text': 'into', 'start': 68.16, 'end': 68.32, 'confidence': 0.999},\n",
       "    {'text': 'basics', 'start': 68.32, 'end': 68.82, 'confidence': 0.963},\n",
       "    {'text': 'of', 'start': 68.82, 'end': 69.22, 'confidence': 0.971},\n",
       "    {'text': 'AI.', 'start': 69.22, 'end': 69.64, 'confidence': 0.961}]},\n",
       "  {'id': 9,\n",
       "   'seek': 7100,\n",
       "   'start': 71.0,\n",
       "   'end': 73.66,\n",
       "   'text': ' So, AI can be general, or it can be narrow.',\n",
       "   'tokens': [50364,\n",
       "    407,\n",
       "    11,\n",
       "    7318,\n",
       "    393,\n",
       "    312,\n",
       "    2674,\n",
       "    11,\n",
       "    420,\n",
       "    309,\n",
       "    393,\n",
       "    312,\n",
       "    9432,\n",
       "    13,\n",
       "    50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15347844583016854,\n",
       "   'compression_ratio': 1.7132075471698114,\n",
       "   'no_speech_prob': 0.6496715545654297,\n",
       "   'confidence': 0.708,\n",
       "   'words': [{'text': 'So,', 'start': 71.0, 'end': 71.02, 'confidence': 0.309},\n",
       "    {'text': 'AI', 'start': 71.02, 'end': 71.04, 'confidence': 0.186},\n",
       "    {'text': 'can', 'start': 71.04, 'end': 71.06, 'confidence': 0.752},\n",
       "    {'text': 'be', 'start': 71.06, 'end': 71.14, 'confidence': 0.982},\n",
       "    {'text': 'general,', 'start': 71.14, 'end': 71.68, 'confidence': 0.855},\n",
       "    {'text': 'or', 'start': 72.64, 'end': 72.84, 'confidence': 0.979},\n",
       "    {'text': 'it', 'start': 72.84, 'end': 73.14, 'confidence': 0.929},\n",
       "    {'text': 'can', 'start': 73.14, 'end': 73.28, 'confidence': 0.999},\n",
       "    {'text': 'be', 'start': 73.28, 'end': 73.38, 'confidence': 0.999},\n",
       "    {'text': 'narrow.', 'start': 73.38, 'end': 73.66, 'confidence': 0.962}]},\n",
       "  {'id': 10,\n",
       "   'seek': 7100,\n",
       "   'start': 74.5,\n",
       "   'end': 83.08,\n",
       "   'text': \" When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots.\",\n",
       "   'tokens': [50564,\n",
       "    1133,\n",
       "    321,\n",
       "    751,\n",
       "    466,\n",
       "    2674,\n",
       "    11677,\n",
       "    7599,\n",
       "    11,\n",
       "    309,\n",
       "    311,\n",
       "    562,\n",
       "    257,\n",
       "    3479,\n",
       "    393,\n",
       "    1466,\n",
       "    604,\n",
       "    9608,\n",
       "    300,\n",
       "    257,\n",
       "    1952,\n",
       "    393,\n",
       "    2042,\n",
       "    13,\n",
       "    639,\n",
       "    775,\n",
       "    406,\n",
       "    2514,\n",
       "    456,\n",
       "    366,\n",
       "    572,\n",
       "    19835,\n",
       "    31927,\n",
       "    14733,\n",
       "    13,\n",
       "    51014],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15347844583016854,\n",
       "   'compression_ratio': 1.7132075471698114,\n",
       "   'no_speech_prob': 0.6496715545654297,\n",
       "   'confidence': 0.914,\n",
       "   'words': [{'text': 'When',\n",
       "     'start': 74.5,\n",
       "     'end': 74.82,\n",
       "     'confidence': 0.949},\n",
       "    {'text': 'we', 'start': 74.82, 'end': 74.94, 'confidence': 0.999},\n",
       "    {'text': 'talk', 'start': 74.94, 'end': 75.08, 'confidence': 0.983},\n",
       "    {'text': 'about', 'start': 75.08, 'end': 75.34, 'confidence': 1.0},\n",
       "    {'text': 'general', 'start': 75.34, 'end': 75.74, 'confidence': 0.987},\n",
       "    {'text': 'artificial', 'start': 75.74, 'end': 76.16, 'confidence': 0.993},\n",
       "    {'text': 'intelligence,',\n",
       "     'start': 76.16,\n",
       "     'end': 76.72,\n",
       "     'confidence': 0.999},\n",
       "    {'text': \"it's\", 'start': 76.96, 'end': 77.06, 'confidence': 0.993},\n",
       "    {'text': 'when', 'start': 77.06, 'end': 77.18, 'confidence': 0.644},\n",
       "    {'text': 'a', 'start': 77.18, 'end': 77.36, 'confidence': 0.949},\n",
       "    {'text': 'machine', 'start': 77.36, 'end': 77.66, 'confidence': 1.0},\n",
       "    {'text': 'can', 'start': 77.66, 'end': 77.9, 'confidence': 0.999},\n",
       "    {'text': 'learn', 'start': 77.9, 'end': 78.12, 'confidence': 0.955},\n",
       "    {'text': 'any', 'start': 78.12, 'end': 78.38, 'confidence': 0.974},\n",
       "    {'text': 'tasks', 'start': 78.38, 'end': 78.74, 'confidence': 0.666},\n",
       "    {'text': 'that', 'start': 78.74, 'end': 78.92, 'confidence': 0.996},\n",
       "    {'text': 'a', 'start': 78.92, 'end': 79.06, 'confidence': 0.982},\n",
       "    {'text': 'human', 'start': 79.06, 'end': 79.2, 'confidence': 0.999},\n",
       "    {'text': 'can', 'start': 79.2, 'end': 79.4, 'confidence': 0.999},\n",
       "    {'text': 'perform.', 'start': 79.4, 'end': 79.74, 'confidence': 0.996},\n",
       "    {'text': 'This', 'start': 79.96, 'end': 80.44, 'confidence': 0.988},\n",
       "    {'text': 'does', 'start': 80.44, 'end': 80.92, 'confidence': 0.999},\n",
       "    {'text': 'not', 'start': 80.92, 'end': 81.2, 'confidence': 1.0},\n",
       "    {'text': 'exist', 'start': 81.2, 'end': 81.58, 'confidence': 0.979},\n",
       "    {'text': 'there', 'start': 81.58, 'end': 81.84, 'confidence': 0.429},\n",
       "    {'text': 'are', 'start': 81.84, 'end': 82.02, 'confidence': 0.997},\n",
       "    {'text': 'no', 'start': 82.02, 'end': 82.22, 'confidence': 0.998},\n",
       "    {'text': 'Terminator', 'start': 82.22, 'end': 82.6, 'confidence': 0.678},\n",
       "    {'text': 'robots.', 'start': 82.6, 'end': 83.08, 'confidence': 0.98}]},\n",
       "  {'id': 11,\n",
       "   'seek': 7100,\n",
       "   'start': 83.5,\n",
       "   'end': 98.74,\n",
       "   'text': \" There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our\",\n",
       "   'tokens': [51014,\n",
       "    821,\n",
       "    366,\n",
       "    572,\n",
       "    11,\n",
       "    456,\n",
       "    366,\n",
       "    456,\n",
       "    307,\n",
       "    572,\n",
       "    1270,\n",
       "    551,\n",
       "    382,\n",
       "    2674,\n",
       "    7318,\n",
       "    293,\n",
       "    8572,\n",
       "    11,\n",
       "    588,\n",
       "    13371,\n",
       "    294,\n",
       "    2115,\n",
       "    295,\n",
       "    641,\n",
       "    21264,\n",
       "    322,\n",
       "    562,\n",
       "    341,\n",
       "    815,\n",
       "    767,\n",
       "    1051,\n",
       "    370,\n",
       "    456,\n",
       "    366,\n",
       "    512,\n",
       "    561,\n",
       "    567,\n",
       "    584,\n",
       "    1954,\n",
       "    1266,\n",
       "    2009,\n",
       "    924,\n",
       "    11,\n",
       "    293,\n",
       "    456,\n",
       "    311,\n",
       "    512,\n",
       "    561,\n",
       "    567,\n",
       "    584,\n",
       "    11,\n",
       "    406,\n",
       "    294,\n",
       "    527,\n",
       "    51764],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15347844583016854,\n",
       "   'compression_ratio': 1.7132075471698114,\n",
       "   'no_speech_prob': 0.6496715545654297,\n",
       "   'confidence': 0.909,\n",
       "   'words': [{'text': 'There',\n",
       "     'start': 83.5,\n",
       "     'end': 84.1,\n",
       "     'confidence': 0.634},\n",
       "    {'text': 'are', 'start': 84.1, 'end': 84.34, 'confidence': 0.997},\n",
       "    {'text': 'no,', 'start': 84.34, 'end': 84.74, 'confidence': 0.996},\n",
       "    {'text': 'there', 'start': 85.24, 'end': 85.38, 'confidence': 0.995},\n",
       "    {'text': 'are', 'start': 85.38, 'end': 85.6, 'confidence': 0.993},\n",
       "    {'text': 'there', 'start': 85.6, 'end': 85.88, 'confidence': 0.779},\n",
       "    {'text': 'is', 'start': 85.88, 'end': 86.24, 'confidence': 0.919},\n",
       "    {'text': 'no', 'start': 86.24, 'end': 86.44, 'confidence': 0.998},\n",
       "    {'text': 'such', 'start': 86.44, 'end': 86.6, 'confidence': 0.999},\n",
       "    {'text': 'thing', 'start': 86.6, 'end': 86.78, 'confidence': 0.983},\n",
       "    {'text': 'as', 'start': 86.78, 'end': 86.94, 'confidence': 0.997},\n",
       "    {'text': 'general', 'start': 86.94, 'end': 87.28, 'confidence': 0.965},\n",
       "    {'text': 'AI', 'start': 87.28, 'end': 87.64, 'confidence': 0.963},\n",
       "    {'text': 'and', 'start': 87.64, 'end': 87.92, 'confidence': 0.997},\n",
       "    {'text': 'experts,', 'start': 87.92, 'end': 88.34, 'confidence': 0.998},\n",
       "    {'text': 'very', 'start': 88.88, 'end': 89.0, 'confidence': 0.978},\n",
       "    {'text': 'widely', 'start': 89.0, 'end': 89.54, 'confidence': 0.996},\n",
       "    {'text': 'in', 'start': 89.54, 'end': 90.08, 'confidence': 0.464},\n",
       "    {'text': 'terms', 'start': 90.08, 'end': 90.22, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 90.22, 'end': 90.3, 'confidence': 1.0},\n",
       "    {'text': 'their', 'start': 90.3, 'end': 90.5, 'confidence': 0.998},\n",
       "    {'text': 'predictions', 'start': 90.5, 'end': 90.92, 'confidence': 0.998},\n",
       "    {'text': 'on', 'start': 90.92, 'end': 91.14, 'confidence': 0.992},\n",
       "    {'text': 'when', 'start': 91.14, 'end': 91.48, 'confidence': 0.998},\n",
       "    {'text': 'this', 'start': 91.48, 'end': 92.12, 'confidence': 0.998},\n",
       "    {'text': 'may', 'start': 92.12, 'end': 92.54, 'confidence': 1.0},\n",
       "    {'text': 'actually', 'start': 92.54, 'end': 92.94, 'confidence': 1.0},\n",
       "    {'text': 'happen', 'start': 92.94, 'end': 93.32, 'confidence': 0.936},\n",
       "    {'text': 'so', 'start': 93.32, 'end': 93.94, 'confidence': 0.726},\n",
       "    {'text': 'there', 'start': 93.94, 'end': 94.54, 'confidence': 0.978},\n",
       "    {'text': 'are', 'start': 94.54, 'end': 94.76, 'confidence': 1.0},\n",
       "    {'text': 'some', 'start': 94.76, 'end': 94.96, 'confidence': 1.0},\n",
       "    {'text': 'people', 'start': 94.96, 'end': 95.14, 'confidence': 1.0},\n",
       "    {'text': 'who', 'start': 95.14, 'end': 95.34, 'confidence': 0.999},\n",
       "    {'text': 'say', 'start': 95.34, 'end': 95.54, 'confidence': 0.999},\n",
       "    {'text': 'oh', 'start': 95.54, 'end': 95.86, 'confidence': 0.696},\n",
       "    {'text': '1020', 'start': 95.86, 'end': 96.64, 'confidence': 0.665},\n",
       "    {'text': 'years,', 'start': 96.64, 'end': 97.02, 'confidence': 0.997},\n",
       "    {'text': 'and', 'start': 97.28, 'end': 97.34, 'confidence': 0.629},\n",
       "    {'text': \"there's\", 'start': 97.34, 'end': 97.46, 'confidence': 0.879},\n",
       "    {'text': 'some', 'start': 97.46, 'end': 97.58, 'confidence': 0.959},\n",
       "    {'text': 'people', 'start': 97.58, 'end': 97.78, 'confidence': 0.996},\n",
       "    {'text': 'who', 'start': 97.78, 'end': 97.94, 'confidence': 0.973},\n",
       "    {'text': 'say,', 'start': 97.94, 'end': 98.18, 'confidence': 0.984},\n",
       "    {'text': 'not', 'start': 98.46, 'end': 98.52, 'confidence': 0.932},\n",
       "    {'text': 'in', 'start': 98.52, 'end': 98.62, 'confidence': 0.929},\n",
       "    {'text': 'our', 'start': 98.62, 'end': 98.74, 'confidence': 0.68}]},\n",
       "  {'id': 12,\n",
       "   'seek': 9900,\n",
       "   'start': 99.0,\n",
       "   'end': 116.16,\n",
       "   'text': ' times and some people who say, not ever. So, really really broad range of guesses in any case, most AI. Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer',\n",
       "   'tokens': [50364,\n",
       "    1413,\n",
       "    293,\n",
       "    512,\n",
       "    561,\n",
       "    567,\n",
       "    584,\n",
       "    11,\n",
       "    406,\n",
       "    1562,\n",
       "    13,\n",
       "    407,\n",
       "    11,\n",
       "    534,\n",
       "    534,\n",
       "    4152,\n",
       "    3613,\n",
       "    295,\n",
       "    42703,\n",
       "    294,\n",
       "    604,\n",
       "    1389,\n",
       "    11,\n",
       "    881,\n",
       "    7318,\n",
       "    13,\n",
       "    4919,\n",
       "    11,\n",
       "    439,\n",
       "    295,\n",
       "    264,\n",
       "    7318,\n",
       "    300,\n",
       "    8198,\n",
       "    965,\n",
       "    11,\n",
       "    293,\n",
       "    881,\n",
       "    295,\n",
       "    264,\n",
       "    7318,\n",
       "    300,\n",
       "    291,\n",
       "    1568,\n",
       "    561,\n",
       "    1417,\n",
       "    466,\n",
       "    307,\n",
       "    9432,\n",
       "    293,\n",
       "    9432,\n",
       "    7318,\n",
       "    307,\n",
       "    562,\n",
       "    257,\n",
       "    3820,\n",
       "    51214],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15250057960624125,\n",
       "   'compression_ratio': 1.5625,\n",
       "   'no_speech_prob': 0.664045512676239,\n",
       "   'confidence': 0.881,\n",
       "   'words': [{'text': 'times',\n",
       "     'start': 99.0,\n",
       "     'end': 99.16,\n",
       "     'confidence': 0.086},\n",
       "    {'text': 'and', 'start': 99.16, 'end': 99.7, 'confidence': 0.749},\n",
       "    {'text': 'some', 'start': 99.7, 'end': 99.88, 'confidence': 0.956},\n",
       "    {'text': 'people', 'start': 99.88, 'end': 100.06, 'confidence': 0.999},\n",
       "    {'text': 'who', 'start': 100.06, 'end': 100.22, 'confidence': 0.964},\n",
       "    {'text': 'say,', 'start': 100.22, 'end': 100.42, 'confidence': 0.998},\n",
       "    {'text': 'not', 'start': 100.64, 'end': 100.78, 'confidence': 0.971},\n",
       "    {'text': 'ever.', 'start': 100.78, 'end': 101.1, 'confidence': 0.994},\n",
       "    {'text': 'So,', 'start': 101.7, 'end': 101.78, 'confidence': 0.964},\n",
       "    {'text': 'really', 'start': 101.98, 'end': 102.24, 'confidence': 0.994},\n",
       "    {'text': 'really', 'start': 102.24, 'end': 102.78, 'confidence': 0.605},\n",
       "    {'text': 'broad', 'start': 102.78, 'end': 103.3, 'confidence': 0.997},\n",
       "    {'text': 'range', 'start': 103.3, 'end': 103.8, 'confidence': 0.992},\n",
       "    {'text': 'of', 'start': 103.8, 'end': 103.9, 'confidence': 0.999},\n",
       "    {'text': 'guesses', 'start': 103.9, 'end': 104.26, 'confidence': 0.896},\n",
       "    {'text': 'in', 'start': 104.26, 'end': 104.5, 'confidence': 0.49},\n",
       "    {'text': 'any', 'start': 104.5, 'end': 104.64, 'confidence': 0.996},\n",
       "    {'text': 'case,', 'start': 104.64, 'end': 105.06, 'confidence': 0.994},\n",
       "    {'text': 'most', 'start': 106.52, 'end': 106.78, 'confidence': 0.879},\n",
       "    {'text': 'AI.', 'start': 106.78, 'end': 107.42, 'confidence': 0.931},\n",
       "    {'text': 'Sorry,', 'start': 107.54, 'end': 108.06, 'confidence': 0.962},\n",
       "    {'text': 'all', 'start': 108.42, 'end': 108.64, 'confidence': 0.997},\n",
       "    {'text': 'of', 'start': 108.64, 'end': 108.72, 'confidence': 0.718},\n",
       "    {'text': 'the', 'start': 108.72, 'end': 108.86, 'confidence': 0.999},\n",
       "    {'text': 'AI', 'start': 108.86, 'end': 109.0, 'confidence': 0.995},\n",
       "    {'text': 'that', 'start': 109.0, 'end': 109.2, 'confidence': 0.999},\n",
       "    {'text': 'exists', 'start': 109.2, 'end': 109.46, 'confidence': 0.993},\n",
       "    {'text': 'today,', 'start': 109.46, 'end': 109.86, 'confidence': 0.999},\n",
       "    {'text': 'and', 'start': 110.14, 'end': 110.32, 'confidence': 0.999},\n",
       "    {'text': 'most', 'start': 110.32, 'end': 110.54, 'confidence': 0.999},\n",
       "    {'text': 'of', 'start': 110.54, 'end': 110.66, 'confidence': 0.998},\n",
       "    {'text': 'the', 'start': 110.66, 'end': 110.8, 'confidence': 0.999},\n",
       "    {'text': 'AI', 'start': 110.8, 'end': 110.98, 'confidence': 0.987},\n",
       "    {'text': 'that', 'start': 110.98, 'end': 111.12, 'confidence': 0.995},\n",
       "    {'text': 'you', 'start': 111.12, 'end': 111.16, 'confidence': 0.999},\n",
       "    {'text': 'hear', 'start': 111.16, 'end': 111.32, 'confidence': 0.942},\n",
       "    {'text': 'people', 'start': 111.32, 'end': 111.46, 'confidence': 0.996},\n",
       "    {'text': 'talking', 'start': 111.46, 'end': 111.76, 'confidence': 0.997},\n",
       "    {'text': 'about', 'start': 111.76, 'end': 112.5, 'confidence': 1.0},\n",
       "    {'text': 'is', 'start': 112.5, 'end': 113.72, 'confidence': 0.822},\n",
       "    {'text': 'narrow', 'start': 113.72, 'end': 114.18, 'confidence': 0.991},\n",
       "    {'text': 'and', 'start': 114.18, 'end': 115.0, 'confidence': 0.732},\n",
       "    {'text': 'narrow', 'start': 115.0, 'end': 115.28, 'confidence': 0.979},\n",
       "    {'text': 'AI', 'start': 115.28, 'end': 115.6, 'confidence': 0.85},\n",
       "    {'text': 'is', 'start': 115.6, 'end': 115.76, 'confidence': 0.963},\n",
       "    {'text': 'when', 'start': 115.76, 'end': 115.9, 'confidence': 0.968},\n",
       "    {'text': 'a', 'start': 115.9, 'end': 116.06, 'confidence': 0.868},\n",
       "    {'text': 'computer',\n",
       "     'start': 116.06,\n",
       "     'end': 116.16,\n",
       "     'confidence': 0.794}]},\n",
       "  {'id': 13,\n",
       "   'seek': 9900,\n",
       "   'start': 116.16,\n",
       "   'end': 118.54,\n",
       "   'text': ' exhibits intelligence at one task.',\n",
       "   'tokens': [51214, 39205, 7599, 412, 472, 5633, 13, 51414],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15250057960624125,\n",
       "   'compression_ratio': 1.5625,\n",
       "   'no_speech_prob': 0.664045512676239,\n",
       "   'confidence': 0.961,\n",
       "   'words': [{'text': 'exhibits',\n",
       "     'start': 116.16,\n",
       "     'end': 116.76,\n",
       "     'confidence': 0.911},\n",
       "    {'text': 'intelligence',\n",
       "     'start': 116.76,\n",
       "     'end': 117.34,\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'at', 'start': 117.34, 'end': 117.72, 'confidence': 0.937},\n",
       "    {'text': 'one', 'start': 117.72, 'end': 117.92, 'confidence': 0.997},\n",
       "    {'text': 'task.', 'start': 117.92, 'end': 118.54, 'confidence': 0.982}]},\n",
       "  {'id': 14,\n",
       "   'seek': 12000,\n",
       "   'start': 120.0,\n",
       "   'end': 122.8,\n",
       "   'text': ' To be clear, you can do pretty impressive things with narrow AI.',\n",
       "   'tokens': [50364,\n",
       "    1407,\n",
       "    312,\n",
       "    1850,\n",
       "    11,\n",
       "    291,\n",
       "    393,\n",
       "    360,\n",
       "    1238,\n",
       "    8992,\n",
       "    721,\n",
       "    365,\n",
       "    9432,\n",
       "    7318,\n",
       "    13,\n",
       "    50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.125052547454834,\n",
       "   'compression_ratio': 1.8235294117647058,\n",
       "   'no_speech_prob': 0.5140997767448425,\n",
       "   'confidence': 0.866,\n",
       "   'words': [{'text': 'To',\n",
       "     'start': 120.0,\n",
       "     'end': 120.08,\n",
       "     'confidence': 0.295},\n",
       "    {'text': 'be', 'start': 120.08, 'end': 120.24, 'confidence': 0.987},\n",
       "    {'text': 'clear,', 'start': 120.24, 'end': 120.54, 'confidence': 0.975},\n",
       "    {'text': 'you', 'start': 120.9, 'end': 120.92, 'confidence': 0.987},\n",
       "    {'text': 'can', 'start': 120.92, 'end': 121.06, 'confidence': 0.999},\n",
       "    {'text': 'do', 'start': 121.06, 'end': 121.16, 'confidence': 0.994},\n",
       "    {'text': 'pretty', 'start': 121.16, 'end': 121.36, 'confidence': 0.995},\n",
       "    {'text': 'impressive',\n",
       "     'start': 121.36,\n",
       "     'end': 121.66,\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'things', 'start': 121.66, 'end': 121.94, 'confidence': 0.997},\n",
       "    {'text': 'with', 'start': 121.94, 'end': 122.12, 'confidence': 0.868},\n",
       "    {'text': 'narrow', 'start': 122.12, 'end': 122.32, 'confidence': 0.787},\n",
       "    {'text': 'AI.', 'start': 122.32, 'end': 122.8, 'confidence': 0.942}]},\n",
       "  {'id': 15,\n",
       "   'seek': 12000,\n",
       "   'start': 123.5,\n",
       "   'end': 134.02,\n",
       "   'text': \" A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car.\",\n",
       "   'tokens': [50564,\n",
       "    316,\n",
       "    2698,\n",
       "    4840,\n",
       "    1032,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    575,\n",
       "    472,\n",
       "    9432,\n",
       "    7318,\n",
       "    1185,\n",
       "    300,\n",
       "    775,\n",
       "    5201,\n",
       "    11,\n",
       "    1542,\n",
       "    412,\n",
       "    264,\n",
       "    3060,\n",
       "    293,\n",
       "    17489,\n",
       "    1373,\n",
       "    721,\n",
       "    13,\n",
       "    821,\n",
       "    311,\n",
       "    1071,\n",
       "    7318,\n",
       "    1185,\n",
       "    300,\n",
       "    775,\n",
       "    14823,\n",
       "    300,\n",
       "    9003,\n",
       "    264,\n",
       "    1032,\n",
       "    13,\n",
       "    51114],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.125052547454834,\n",
       "   'compression_ratio': 1.8235294117647058,\n",
       "   'no_speech_prob': 0.5140997767448425,\n",
       "   'confidence': 0.945,\n",
       "   'words': [{'text': 'A', 'start': 123.5, 'end': 123.52, 'confidence': 0.858},\n",
       "    {'text': 'self', 'start': 123.52, 'end': 123.64, 'confidence': 0.994},\n",
       "    {'text': 'driving', 'start': 123.64, 'end': 123.9, 'confidence': 0.978},\n",
       "    {'text': 'car', 'start': 123.9, 'end': 124.2, 'confidence': 0.998},\n",
       "    {'text': 'for', 'start': 124.2, 'end': 124.44, 'confidence': 0.671},\n",
       "    {'text': 'example,', 'start': 124.44, 'end': 124.88, 'confidence': 1.0},\n",
       "    {'text': 'has', 'start': 125.18, 'end': 125.46, 'confidence': 0.997},\n",
       "    {'text': 'one', 'start': 125.46, 'end': 126.08, 'confidence': 0.994},\n",
       "    {'text': 'narrow', 'start': 126.08, 'end': 126.52, 'confidence': 0.971},\n",
       "    {'text': 'AI', 'start': 126.52, 'end': 126.76, 'confidence': 0.936},\n",
       "    {'text': 'system', 'start': 126.76, 'end': 127.26, 'confidence': 0.997},\n",
       "    {'text': 'that', 'start': 127.26, 'end': 128.0, 'confidence': 0.985},\n",
       "    {'text': 'does', 'start': 128.0, 'end': 128.64, 'confidence': 0.998},\n",
       "    {'text': 'vision,', 'start': 128.64, 'end': 129.02, 'confidence': 0.974},\n",
       "    {'text': 'looks', 'start': 129.24, 'end': 129.4, 'confidence': 0.607},\n",
       "    {'text': 'at', 'start': 129.4, 'end': 129.52, 'confidence': 0.999},\n",
       "    {'text': 'the', 'start': 129.52, 'end': 129.64, 'confidence': 1.0},\n",
       "    {'text': 'road', 'start': 129.64, 'end': 129.78, 'confidence': 0.997},\n",
       "    {'text': 'and', 'start': 129.78, 'end': 129.96, 'confidence': 0.957},\n",
       "    {'text': 'interprets',\n",
       "     'start': 129.96,\n",
       "     'end': 130.22,\n",
       "     'confidence': 0.862},\n",
       "    {'text': 'things.', 'start': 130.22, 'end': 130.5, 'confidence': 0.996},\n",
       "    {'text': \"There's\", 'start': 130.86, 'end': 130.94, 'confidence': 0.991},\n",
       "    {'text': 'another', 'start': 130.94, 'end': 131.26, 'confidence': 0.998},\n",
       "    {'text': 'AI', 'start': 131.26, 'end': 131.56, 'confidence': 0.991},\n",
       "    {'text': 'system', 'start': 131.56, 'end': 131.9, 'confidence': 0.998},\n",
       "    {'text': 'that', 'start': 131.9, 'end': 132.1, 'confidence': 0.999},\n",
       "    {'text': 'does', 'start': 132.1, 'end': 132.4, 'confidence': 0.998},\n",
       "    {'text': 'steering', 'start': 132.4, 'end': 132.72, 'confidence': 0.942},\n",
       "    {'text': 'that', 'start': 132.72, 'end': 133.14, 'confidence': 0.769},\n",
       "    {'text': 'controls', 'start': 133.14, 'end': 133.52, 'confidence': 0.999},\n",
       "    {'text': 'the', 'start': 133.52, 'end': 133.76, 'confidence': 0.999},\n",
       "    {'text': 'car.', 'start': 133.76, 'end': 134.02, 'confidence': 0.999}]},\n",
       "  {'id': 16,\n",
       "   'seek': 12000,\n",
       "   'start': 134.5,\n",
       "   'end': 141.28,\n",
       "   'text': \" There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together.\",\n",
       "   'tokens': [51114,\n",
       "    821,\n",
       "    311,\n",
       "    1071,\n",
       "    7318,\n",
       "    1185,\n",
       "    300,\n",
       "    775,\n",
       "    7955,\n",
       "    5038,\n",
       "    300,\n",
       "    1619,\n",
       "    322,\n",
       "    257,\n",
       "    4152,\n",
       "    1496,\n",
       "    437,\n",
       "    366,\n",
       "    321,\n",
       "    1382,\n",
       "    281,\n",
       "    291,\n",
       "    458,\n",
       "    689,\n",
       "    321,\n",
       "    516,\n",
       "    11,\n",
       "    577,\n",
       "    360,\n",
       "    321,\n",
       "    483,\n",
       "    456,\n",
       "    13,\n",
       "    400,\n",
       "    562,\n",
       "    291,\n",
       "    5635,\n",
       "    439,\n",
       "    729,\n",
       "    1214,\n",
       "    13,\n",
       "    51514],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.125052547454834,\n",
       "   'compression_ratio': 1.8235294117647058,\n",
       "   'no_speech_prob': 0.5140997767448425,\n",
       "   'confidence': 0.903,\n",
       "   'words': [{'text': \"There's\",\n",
       "     'start': 134.5,\n",
       "     'end': 134.52,\n",
       "     'confidence': 0.953},\n",
       "    {'text': 'another', 'start': 134.52, 'end': 134.72, 'confidence': 0.998},\n",
       "    {'text': 'AI', 'start': 134.72, 'end': 134.92, 'confidence': 0.982},\n",
       "    {'text': 'system', 'start': 134.92, 'end': 135.22, 'confidence': 0.999},\n",
       "    {'text': 'that', 'start': 135.22, 'end': 135.34, 'confidence': 0.999},\n",
       "    {'text': 'does', 'start': 135.34, 'end': 135.56, 'confidence': 0.992},\n",
       "    {'text': 'route', 'start': 135.56, 'end': 135.82, 'confidence': 0.993},\n",
       "    {'text': 'planning', 'start': 135.82, 'end': 136.08, 'confidence': 0.998},\n",
       "    {'text': 'that', 'start': 136.08, 'end': 136.28, 'confidence': 0.962},\n",
       "    {'text': 'says', 'start': 136.28, 'end': 136.5, 'confidence': 0.997},\n",
       "    {'text': 'on', 'start': 136.5, 'end': 136.84, 'confidence': 0.628},\n",
       "    {'text': 'a', 'start': 136.84, 'end': 137.04, 'confidence': 0.981},\n",
       "    {'text': 'broad', 'start': 137.04, 'end': 137.24, 'confidence': 1.0},\n",
       "    {'text': 'level', 'start': 137.24, 'end': 137.52, 'confidence': 0.999},\n",
       "    {'text': 'what', 'start': 137.52, 'end': 137.64, 'confidence': 0.62},\n",
       "    {'text': 'are', 'start': 137.64, 'end': 137.74, 'confidence': 0.965},\n",
       "    {'text': 'we', 'start': 137.74, 'end': 137.84, 'confidence': 0.998},\n",
       "    {'text': 'trying', 'start': 137.84, 'end': 138.0, 'confidence': 0.939},\n",
       "    {'text': 'to', 'start': 138.0, 'end': 138.02, 'confidence': 0.663},\n",
       "    {'text': 'you', 'start': 138.02, 'end': 138.14, 'confidence': 0.714},\n",
       "    {'text': 'know', 'start': 138.14, 'end': 138.24, 'confidence': 0.995},\n",
       "    {'text': 'where', 'start': 138.24, 'end': 138.38, 'confidence': 0.971},\n",
       "    {'text': 'we', 'start': 138.38, 'end': 138.54, 'confidence': 0.787},\n",
       "    {'text': 'going,', 'start': 138.54, 'end': 138.68, 'confidence': 0.652},\n",
       "    {'text': 'how', 'start': 138.78, 'end': 138.88, 'confidence': 0.979},\n",
       "    {'text': 'do', 'start': 138.88, 'end': 139.0, 'confidence': 0.984},\n",
       "    {'text': 'we', 'start': 139.0, 'end': 139.04, 'confidence': 1.0},\n",
       "    {'text': 'get', 'start': 139.04, 'end': 139.22, 'confidence': 1.0},\n",
       "    {'text': 'there.', 'start': 139.22, 'end': 139.5, 'confidence': 0.604},\n",
       "    {'text': 'And', 'start': 139.6, 'end': 140.0, 'confidence': 0.775},\n",
       "    {'text': 'when', 'start': 140.0, 'end': 140.12, 'confidence': 0.999},\n",
       "    {'text': 'you', 'start': 140.12, 'end': 140.22, 'confidence': 1.0},\n",
       "    {'text': 'stitch', 'start': 140.22, 'end': 140.44, 'confidence': 0.814},\n",
       "    {'text': 'all', 'start': 140.44, 'end': 140.58, 'confidence': 0.994},\n",
       "    {'text': 'those', 'start': 140.58, 'end': 140.72, 'confidence': 0.949},\n",
       "    {'text': 'together.',\n",
       "     'start': 140.72,\n",
       "     'end': 141.28,\n",
       "     'confidence': 0.996}]},\n",
       "  {'id': 17,\n",
       "   'seek': 14300,\n",
       "   'start': 143.0,\n",
       "   'end': 147.16,\n",
       "   'text': \" So, it's a very impressive system but you cannot sit this card down and play chess with it.\",\n",
       "   'tokens': [50364,\n",
       "    407,\n",
       "    11,\n",
       "    309,\n",
       "    311,\n",
       "    257,\n",
       "    588,\n",
       "    8992,\n",
       "    1185,\n",
       "    457,\n",
       "    291,\n",
       "    2644,\n",
       "    1394,\n",
       "    341,\n",
       "    2920,\n",
       "    760,\n",
       "    293,\n",
       "    862,\n",
       "    24122,\n",
       "    365,\n",
       "    309,\n",
       "    13,\n",
       "    50614],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.755,\n",
       "   'words': [{'text': 'So,',\n",
       "     'start': 143.0,\n",
       "     'end': 143.02,\n",
       "     'confidence': 0.166},\n",
       "    {'text': \"it's\", 'start': 143.02, 'end': 143.04, 'confidence': 0.498},\n",
       "    {'text': 'a', 'start': 143.04, 'end': 143.06, 'confidence': 0.699},\n",
       "    {'text': 'very', 'start': 143.06, 'end': 143.16, 'confidence': 0.912},\n",
       "    {'text': 'impressive',\n",
       "     'start': 143.16,\n",
       "     'end': 143.52,\n",
       "     'confidence': 0.816},\n",
       "    {'text': 'system', 'start': 143.52, 'end': 143.84, 'confidence': 0.995},\n",
       "    {'text': 'but', 'start': 143.84, 'end': 144.26, 'confidence': 0.729},\n",
       "    {'text': 'you', 'start': 144.26, 'end': 144.66, 'confidence': 0.993},\n",
       "    {'text': 'cannot', 'start': 144.66, 'end': 145.0, 'confidence': 0.83},\n",
       "    {'text': 'sit', 'start': 145.0, 'end': 145.24, 'confidence': 0.946},\n",
       "    {'text': 'this', 'start': 145.24, 'end': 145.48, 'confidence': 0.985},\n",
       "    {'text': 'card', 'start': 145.48, 'end': 145.64, 'confidence': 0.596},\n",
       "    {'text': 'down', 'start': 145.64, 'end': 145.82, 'confidence': 0.69},\n",
       "    {'text': 'and', 'start': 145.82, 'end': 145.94, 'confidence': 0.996},\n",
       "    {'text': 'play', 'start': 145.94, 'end': 146.08, 'confidence': 0.996},\n",
       "    {'text': 'chess', 'start': 146.08, 'end': 146.28, 'confidence': 0.999},\n",
       "    {'text': 'with', 'start': 146.28, 'end': 146.44, 'confidence': 0.998},\n",
       "    {'text': 'it.', 'start': 146.44, 'end': 147.16, 'confidence': 0.996}]},\n",
       "  {'id': 18,\n",
       "   'seek': 14300,\n",
       "   'start': 147.5,\n",
       "   'end': 148.46,\n",
       "   'text': ' This car will not learn how to paint.',\n",
       "   'tokens': [50614, 639, 1032, 486, 406, 1466, 577, 281, 4225, 13, 50714],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.972,\n",
       "   'words': [{'text': 'This',\n",
       "     'start': 147.5,\n",
       "     'end': 147.52,\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'car', 'start': 147.52, 'end': 147.58, 'confidence': 0.824},\n",
       "    {'text': 'will', 'start': 147.58, 'end': 147.74, 'confidence': 0.992},\n",
       "    {'text': 'not', 'start': 147.74, 'end': 147.86, 'confidence': 0.999},\n",
       "    {'text': 'learn', 'start': 147.86, 'end': 148.0, 'confidence': 0.999},\n",
       "    {'text': 'how', 'start': 148.0, 'end': 148.12, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 148.12, 'end': 148.18, 'confidence': 1.0},\n",
       "    {'text': 'paint.', 'start': 148.18, 'end': 148.46, 'confidence': 0.996}]},\n",
       "  {'id': 19,\n",
       "   'seek': 14300,\n",
       "   'start': 149.5,\n",
       "   'end': 152.8,\n",
       "   'text': ' This car will not learn how to speak Russian.',\n",
       "   'tokens': [50714,\n",
       "    639,\n",
       "    1032,\n",
       "    486,\n",
       "    406,\n",
       "    1466,\n",
       "    577,\n",
       "    281,\n",
       "    1710,\n",
       "    7220,\n",
       "    13,\n",
       "    50914],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.992,\n",
       "   'words': [{'text': 'This',\n",
       "     'start': 149.5,\n",
       "     'end': 149.56,\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'car', 'start': 149.56, 'end': 149.68, 'confidence': 0.977},\n",
       "    {'text': 'will', 'start': 149.68, 'end': 149.84, 'confidence': 0.999},\n",
       "    {'text': 'not', 'start': 149.84, 'end': 150.4, 'confidence': 1.0},\n",
       "    {'text': 'learn', 'start': 150.4, 'end': 151.22, 'confidence': 0.983},\n",
       "    {'text': 'how', 'start': 151.22, 'end': 151.52, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 151.52, 'end': 152.0, 'confidence': 1.0},\n",
       "    {'text': 'speak', 'start': 152.0, 'end': 152.36, 'confidence': 0.999},\n",
       "    {'text': 'Russian.', 'start': 152.36, 'end': 152.8, 'confidence': 0.988}]},\n",
       "  {'id': 20,\n",
       "   'seek': 14300,\n",
       "   'start': 153.72,\n",
       "   'end': 158.64,\n",
       "   'text': \" Right, it's doing a specific set of tasks, each of which has been trained separately.\",\n",
       "   'tokens': [50914,\n",
       "    1779,\n",
       "    11,\n",
       "    309,\n",
       "    311,\n",
       "    884,\n",
       "    257,\n",
       "    2685,\n",
       "    992,\n",
       "    295,\n",
       "    9608,\n",
       "    11,\n",
       "    1184,\n",
       "    295,\n",
       "    597,\n",
       "    575,\n",
       "    668,\n",
       "    8895,\n",
       "    14759,\n",
       "    13,\n",
       "    51214],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.984,\n",
       "   'words': [{'text': 'Right,',\n",
       "     'start': 153.72,\n",
       "     'end': 153.92,\n",
       "     'confidence': 0.904},\n",
       "    {'text': \"it's\", 'start': 154.04, 'end': 154.14, 'confidence': 0.997},\n",
       "    {'text': 'doing', 'start': 154.14, 'end': 154.54, 'confidence': 1.0},\n",
       "    {'text': 'a', 'start': 154.54, 'end': 155.04, 'confidence': 0.996},\n",
       "    {'text': 'specific', 'start': 155.04, 'end': 155.6, 'confidence': 1.0},\n",
       "    {'text': 'set', 'start': 155.6, 'end': 155.98, 'confidence': 0.999},\n",
       "    {'text': 'of', 'start': 155.98, 'end': 156.12, 'confidence': 1.0},\n",
       "    {'text': 'tasks,', 'start': 156.12, 'end': 156.6, 'confidence': 0.999},\n",
       "    {'text': 'each', 'start': 157.08, 'end': 157.24, 'confidence': 0.998},\n",
       "    {'text': 'of', 'start': 157.24, 'end': 157.36, 'confidence': 0.999},\n",
       "    {'text': 'which', 'start': 157.36, 'end': 157.6, 'confidence': 1.0},\n",
       "    {'text': 'has', 'start': 157.6, 'end': 157.84, 'confidence': 0.873},\n",
       "    {'text': 'been', 'start': 157.84, 'end': 157.98, 'confidence': 1.0},\n",
       "    {'text': 'trained', 'start': 157.98, 'end': 158.18, 'confidence': 0.988},\n",
       "    {'text': 'separately.',\n",
       "     'start': 158.18,\n",
       "     'end': 158.64,\n",
       "     'confidence': 0.999}]},\n",
       "  {'id': 21,\n",
       "   'seek': 14300,\n",
       "   'start': 159.5,\n",
       "   'end': 161.28,\n",
       "   'text': ' And that is narrow AI.',\n",
       "   'tokens': [51214, 400, 300, 307, 9432, 7318, 13, 51314],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.948,\n",
       "   'words': [{'text': 'And',\n",
       "     'start': 159.5,\n",
       "     'end': 160.04,\n",
       "     'confidence': 0.967},\n",
       "    {'text': 'that', 'start': 160.04, 'end': 160.38, 'confidence': 0.99},\n",
       "    {'text': 'is', 'start': 160.38, 'end': 160.56, 'confidence': 0.998},\n",
       "    {'text': 'narrow', 'start': 160.56, 'end': 160.82, 'confidence': 0.898},\n",
       "    {'text': 'AI.', 'start': 160.82, 'end': 161.28, 'confidence': 0.893}]},\n",
       "  {'id': 22,\n",
       "   'seek': 14300,\n",
       "   'start': 161.74,\n",
       "   'end': 165.96,\n",
       "   'text': \" So, now on when I say AI I'm talking about narrow artificial intelligence.\",\n",
       "   'tokens': [51314,\n",
       "    407,\n",
       "    11,\n",
       "    586,\n",
       "    322,\n",
       "    562,\n",
       "    286,\n",
       "    584,\n",
       "    7318,\n",
       "    286,\n",
       "    478,\n",
       "    1417,\n",
       "    466,\n",
       "    9432,\n",
       "    11677,\n",
       "    7599,\n",
       "    13,\n",
       "    51564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.873,\n",
       "   'words': [{'text': 'So,',\n",
       "     'start': 161.74,\n",
       "     'end': 162.18,\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'now', 'start': 162.36, 'end': 162.48, 'confidence': 0.578},\n",
       "    {'text': 'on', 'start': 162.48, 'end': 162.64, 'confidence': 0.442},\n",
       "    {'text': 'when', 'start': 162.64, 'end': 162.76, 'confidence': 0.977},\n",
       "    {'text': 'I', 'start': 162.76, 'end': 162.9, 'confidence': 0.999},\n",
       "    {'text': 'say', 'start': 162.9, 'end': 163.12, 'confidence': 0.998},\n",
       "    {'text': 'AI', 'start': 163.12, 'end': 163.48, 'confidence': 0.904},\n",
       "    {'text': \"I'm\", 'start': 163.48, 'end': 163.78, 'confidence': 0.842},\n",
       "    {'text': 'talking', 'start': 163.78, 'end': 164.0, 'confidence': 1.0},\n",
       "    {'text': 'about', 'start': 164.0, 'end': 164.42, 'confidence': 1.0},\n",
       "    {'text': 'narrow', 'start': 164.42, 'end': 164.94, 'confidence': 0.979},\n",
       "    {'text': 'artificial', 'start': 164.94, 'end': 165.4, 'confidence': 0.974},\n",
       "    {'text': 'intelligence.',\n",
       "     'start': 165.4,\n",
       "     'end': 165.96,\n",
       "     'confidence': 0.999}]},\n",
       "  {'id': 23,\n",
       "   'seek': 14300,\n",
       "   'start': 166.6,\n",
       "   'end': 168.26,\n",
       "   'text': ' Any questions so far.',\n",
       "   'tokens': [51564, 2639, 1651, 370, 1400, 13, 51664],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.985,\n",
       "   'words': [{'text': 'Any',\n",
       "     'start': 166.6,\n",
       "     'end': 166.8,\n",
       "     'confidence': 0.965},\n",
       "    {'text': 'questions', 'start': 166.8, 'end': 167.04, 'confidence': 0.99},\n",
       "    {'text': 'so', 'start': 167.04, 'end': 167.26, 'confidence': 0.989},\n",
       "    {'text': 'far.', 'start': 167.26, 'end': 168.26, 'confidence': 0.996}]},\n",
       "  {'id': 24,\n",
       "   'seek': 14300,\n",
       "   'start': 168.5,\n",
       "   'end': 169.8,\n",
       "   'text': ' Question from participant.',\n",
       "   'tokens': [51664, 14464, 490, 24950, 13, 51814],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1291509645956534,\n",
       "   'compression_ratio': 1.6518218623481782,\n",
       "   'no_speech_prob': 0.30686819553375244,\n",
       "   'confidence': 0.907,\n",
       "   'words': [{'text': 'Question',\n",
       "     'start': 168.5,\n",
       "     'end': 168.92,\n",
       "     'confidence': 0.781},\n",
       "    {'text': 'from', 'start': 168.92, 'end': 169.2, 'confidence': 0.995},\n",
       "    {'text': 'participant.',\n",
       "     'start': 169.2,\n",
       "     'end': 169.8,\n",
       "     'confidence': 0.96}]},\n",
       "  {'id': 25,\n",
       "   'seek': 17200,\n",
       "   'start': 172.0,\n",
       "   'end': 176.76,\n",
       "   'text': ' In January, do you fall in with regard to general AI. When do you think it will be possible.',\n",
       "   'tokens': [50364,\n",
       "    682,\n",
       "    7061,\n",
       "    11,\n",
       "    360,\n",
       "    291,\n",
       "    2100,\n",
       "    294,\n",
       "    365,\n",
       "    3843,\n",
       "    281,\n",
       "    2674,\n",
       "    7318,\n",
       "    13,\n",
       "    1133,\n",
       "    360,\n",
       "    291,\n",
       "    519,\n",
       "    309,\n",
       "    486,\n",
       "    312,\n",
       "    1944,\n",
       "    13,\n",
       "    50714],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10477360258711145,\n",
       "   'compression_ratio': 1.672811059907834,\n",
       "   'no_speech_prob': 0.03844000771641731,\n",
       "   'confidence': 0.869,\n",
       "   'words': [{'text': 'In',\n",
       "     'start': 172.0,\n",
       "     'end': 172.02,\n",
       "     'confidence': 0.461},\n",
       "    {'text': 'January,', 'start': 172.02, 'end': 172.26, 'confidence': 0.288},\n",
       "    {'text': 'do', 'start': 172.28, 'end': 172.54, 'confidence': 0.862},\n",
       "    {'text': 'you', 'start': 172.54, 'end': 172.74, 'confidence': 0.999},\n",
       "    {'text': 'fall', 'start': 172.74, 'end': 172.94, 'confidence': 0.967},\n",
       "    {'text': 'in', 'start': 172.94, 'end': 173.12, 'confidence': 0.994},\n",
       "    {'text': 'with', 'start': 173.12, 'end': 173.32, 'confidence': 0.981},\n",
       "    {'text': 'regard', 'start': 173.32, 'end': 173.66, 'confidence': 0.993},\n",
       "    {'text': 'to', 'start': 173.66, 'end': 173.8, 'confidence': 1.0},\n",
       "    {'text': 'general', 'start': 173.8, 'end': 174.26, 'confidence': 0.933},\n",
       "    {'text': 'AI.', 'start': 174.26, 'end': 174.68, 'confidence': 0.919},\n",
       "    {'text': 'When', 'start': 174.92, 'end': 175.4, 'confidence': 0.771},\n",
       "    {'text': 'do', 'start': 175.4, 'end': 175.52, 'confidence': 0.986},\n",
       "    {'text': 'you', 'start': 175.52, 'end': 175.56, 'confidence': 1.0},\n",
       "    {'text': 'think', 'start': 175.56, 'end': 175.72, 'confidence': 1.0},\n",
       "    {'text': 'it', 'start': 175.72, 'end': 175.82, 'confidence': 0.998},\n",
       "    {'text': 'will', 'start': 175.82, 'end': 175.94, 'confidence': 0.995},\n",
       "    {'text': 'be', 'start': 175.94, 'end': 176.06, 'confidence': 1.0},\n",
       "    {'text': 'possible.',\n",
       "     'start': 176.06,\n",
       "     'end': 176.76,\n",
       "     'confidence': 0.998}]},\n",
       "  {'id': 26,\n",
       "   'seek': 17200,\n",
       "   'start': 178.5,\n",
       "   'end': 186.96,\n",
       "   'text': \" I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point.\",\n",
       "   'tokens': [50714,\n",
       "    286,\n",
       "    500,\n",
       "    380,\n",
       "    519,\n",
       "    309,\n",
       "    311,\n",
       "    516,\n",
       "    281,\n",
       "    1051,\n",
       "    337,\n",
       "    257,\n",
       "    1339,\n",
       "    13,\n",
       "    1743,\n",
       "    867,\n",
       "    867,\n",
       "    7878,\n",
       "    11,\n",
       "    457,\n",
       "    286,\n",
       "    611,\n",
       "    519,\n",
       "    300,\n",
       "    309,\n",
       "    311,\n",
       "    2138,\n",
       "    516,\n",
       "    281,\n",
       "    1051,\n",
       "    412,\n",
       "    512,\n",
       "    935,\n",
       "    13,\n",
       "    51264],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10477360258711145,\n",
       "   'compression_ratio': 1.672811059907834,\n",
       "   'no_speech_prob': 0.03844000771641731,\n",
       "   'confidence': 0.955,\n",
       "   'words': [{'text': 'I', 'start': 178.5, 'end': 179.06, 'confidence': 0.972},\n",
       "    {'text': \"don't\", 'start': 179.06, 'end': 179.2, 'confidence': 1.0},\n",
       "    {'text': 'think', 'start': 179.2, 'end': 179.32, 'confidence': 1.0},\n",
       "    {'text': \"it's\", 'start': 179.32, 'end': 179.44, 'confidence': 0.999},\n",
       "    {'text': 'going', 'start': 179.44, 'end': 179.52, 'confidence': 0.807},\n",
       "    {'text': 'to', 'start': 179.52, 'end': 179.6, 'confidence': 1.0},\n",
       "    {'text': 'happen', 'start': 179.6, 'end': 179.76, 'confidence': 0.999},\n",
       "    {'text': 'for', 'start': 179.76, 'end': 179.94, 'confidence': 0.999},\n",
       "    {'text': 'a', 'start': 179.94, 'end': 180.1, 'confidence': 0.981},\n",
       "    {'text': 'while.', 'start': 180.1, 'end': 180.52, 'confidence': 1.0},\n",
       "    {'text': 'Like', 'start': 180.92, 'end': 181.04, 'confidence': 0.692},\n",
       "    {'text': 'many', 'start': 181.04, 'end': 181.3, 'confidence': 0.93},\n",
       "    {'text': 'many', 'start': 181.3, 'end': 181.52, 'confidence': 0.755},\n",
       "    {'text': 'decades,', 'start': 181.52, 'end': 181.96, 'confidence': 1.0},\n",
       "    {'text': 'but', 'start': 182.34, 'end': 182.44, 'confidence': 0.998},\n",
       "    {'text': 'I', 'start': 182.44, 'end': 182.58, 'confidence': 0.999},\n",
       "    {'text': 'also', 'start': 182.58, 'end': 182.8, 'confidence': 0.999},\n",
       "    {'text': 'think', 'start': 182.8, 'end': 183.06, 'confidence': 1.0},\n",
       "    {'text': 'that', 'start': 183.06, 'end': 183.22, 'confidence': 1.0},\n",
       "    {'text': \"it's\", 'start': 183.22, 'end': 183.38, 'confidence': 0.998},\n",
       "    {'text': 'definitely', 'start': 183.38, 'end': 184.06, 'confidence': 1.0},\n",
       "    {'text': 'going', 'start': 184.06, 'end': 185.2, 'confidence': 0.791},\n",
       "    {'text': 'to', 'start': 185.2, 'end': 185.32, 'confidence': 0.999},\n",
       "    {'text': 'happen', 'start': 185.32, 'end': 185.5, 'confidence': 0.998},\n",
       "    {'text': 'at', 'start': 185.5, 'end': 185.64, 'confidence': 0.948},\n",
       "    {'text': 'some', 'start': 185.64, 'end': 185.76, 'confidence': 0.934},\n",
       "    {'text': 'point.', 'start': 185.76, 'end': 186.96, 'confidence': 0.969}]},\n",
       "  {'id': 27,\n",
       "   'seek': 17200,\n",
       "   'start': 190.04,\n",
       "   'end': 192.98,\n",
       "   'text': \" Many decades to maybe centuries I don't know.\",\n",
       "   'tokens': [51264,\n",
       "    5126,\n",
       "    7878,\n",
       "    281,\n",
       "    1310,\n",
       "    13926,\n",
       "    286,\n",
       "    500,\n",
       "    380,\n",
       "    458,\n",
       "    13,\n",
       "    51464],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10477360258711145,\n",
       "   'compression_ratio': 1.672811059907834,\n",
       "   'no_speech_prob': 0.03844000771641731,\n",
       "   'confidence': 0.915,\n",
       "   'words': [{'text': 'Many',\n",
       "     'start': 190.04,\n",
       "     'end': 190.34,\n",
       "     'confidence': 0.831},\n",
       "    {'text': 'decades', 'start': 190.34, 'end': 190.74, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 190.74, 'end': 191.04, 'confidence': 0.959},\n",
       "    {'text': 'maybe', 'start': 191.04, 'end': 191.36, 'confidence': 0.958},\n",
       "    {'text': 'centuries', 'start': 191.36, 'end': 191.86, 'confidence': 0.966},\n",
       "    {'text': 'I', 'start': 191.86, 'end': 192.04, 'confidence': 0.615},\n",
       "    {'text': \"don't\", 'start': 192.04, 'end': 192.2, 'confidence': 0.997},\n",
       "    {'text': 'know.', 'start': 192.2, 'end': 192.98, 'confidence': 0.996}]},\n",
       "  {'id': 28,\n",
       "   'seek': 17200,\n",
       "   'start': 193.5,\n",
       "   'end': 197.02,\n",
       "   'text': \" I think technological progress is hard to guess at so I think it's a fool's errand.\",\n",
       "   'tokens': [51464,\n",
       "    286,\n",
       "    519,\n",
       "    18439,\n",
       "    4205,\n",
       "    307,\n",
       "    1152,\n",
       "    281,\n",
       "    2041,\n",
       "    412,\n",
       "    370,\n",
       "    286,\n",
       "    519,\n",
       "    309,\n",
       "    311,\n",
       "    257,\n",
       "    7979,\n",
       "    311,\n",
       "    45810,\n",
       "    13,\n",
       "    51714],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10477360258711145,\n",
       "   'compression_ratio': 1.672811059907834,\n",
       "   'no_speech_prob': 0.03844000771641731,\n",
       "   'confidence': 0.903,\n",
       "   'words': [{'text': 'I', 'start': 193.5, 'end': 193.68, 'confidence': 0.847},\n",
       "    {'text': 'think', 'start': 193.68, 'end': 193.88, 'confidence': 0.999},\n",
       "    {'text': 'technological',\n",
       "     'start': 193.88,\n",
       "     'end': 194.3,\n",
       "     'confidence': 0.833},\n",
       "    {'text': 'progress', 'start': 194.3, 'end': 194.62, 'confidence': 0.993},\n",
       "    {'text': 'is', 'start': 194.62, 'end': 194.74, 'confidence': 0.987},\n",
       "    {'text': 'hard', 'start': 194.74, 'end': 194.86, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 194.86, 'end': 194.96, 'confidence': 1.0},\n",
       "    {'text': 'guess', 'start': 194.96, 'end': 195.16, 'confidence': 0.924},\n",
       "    {'text': 'at', 'start': 195.16, 'end': 195.36, 'confidence': 0.529},\n",
       "    {'text': 'so', 'start': 195.36, 'end': 195.58, 'confidence': 0.607},\n",
       "    {'text': 'I', 'start': 195.58, 'end': 195.92, 'confidence': 0.912},\n",
       "    {'text': 'think', 'start': 195.92, 'end': 196.08, 'confidence': 0.923},\n",
       "    {'text': \"it's\", 'start': 196.08, 'end': 196.24, 'confidence': 0.999},\n",
       "    {'text': 'a', 'start': 196.24, 'end': 196.36, 'confidence': 0.998},\n",
       "    {'text': \"fool's\", 'start': 196.36, 'end': 196.64, 'confidence': 0.967},\n",
       "    {'text': 'errand.', 'start': 196.64, 'end': 197.02, 'confidence': 0.995}]},\n",
       "  {'id': 29,\n",
       "   'seek': 19900,\n",
       "   'start': 199.0,\n",
       "   'end': 208.5,\n",
       "   'text': \" So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning.\",\n",
       "   'tokens': [50364,\n",
       "    407,\n",
       "    11,\n",
       "    437,\n",
       "    775,\n",
       "    9432,\n",
       "    7318,\n",
       "    767,\n",
       "    360,\n",
       "    731,\n",
       "    7476,\n",
       "    9608,\n",
       "    11,\n",
       "    382,\n",
       "    321,\n",
       "    600,\n",
       "    1612,\n",
       "    365,\n",
       "    264,\n",
       "    2698,\n",
       "    4840,\n",
       "    1032,\n",
       "    1365,\n",
       "    4090,\n",
       "    5201,\n",
       "    11,\n",
       "    2856,\n",
       "    9007,\n",
       "    293,\n",
       "    5038,\n",
       "    13,\n",
       "    50864],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10106727744959577,\n",
       "   'compression_ratio': 1.7227272727272727,\n",
       "   'no_speech_prob': 0.04462442547082901,\n",
       "   'confidence': 0.913,\n",
       "   'words': [{'text': 'So,',\n",
       "     'start': 199.0,\n",
       "     'end': 199.44,\n",
       "     'confidence': 0.663},\n",
       "    {'text': 'what', 'start': 200.08, 'end': 200.52, 'confidence': 0.967},\n",
       "    {'text': 'does', 'start': 200.52, 'end': 201.02, 'confidence': 0.994},\n",
       "    {'text': 'narrow', 'start': 201.02, 'end': 201.26, 'confidence': 0.417},\n",
       "    {'text': 'AI', 'start': 201.26, 'end': 201.5, 'confidence': 0.921},\n",
       "    {'text': 'actually', 'start': 201.5, 'end': 201.84, 'confidence': 0.966},\n",
       "    {'text': 'do', 'start': 201.84, 'end': 202.08, 'confidence': 0.998},\n",
       "    {'text': 'well', 'start': 202.08, 'end': 202.48, 'confidence': 0.72},\n",
       "    {'text': 'typical', 'start': 202.48, 'end': 202.86, 'confidence': 0.926},\n",
       "    {'text': 'tasks,', 'start': 202.86, 'end': 203.38, 'confidence': 0.995},\n",
       "    {'text': 'as', 'start': 203.56, 'end': 203.72, 'confidence': 0.998},\n",
       "    {'text': \"we've\", 'start': 203.72, 'end': 203.98, 'confidence': 0.999},\n",
       "    {'text': 'seen', 'start': 203.98, 'end': 204.12, 'confidence': 0.998},\n",
       "    {'text': 'with', 'start': 204.12, 'end': 204.28, 'confidence': 0.992},\n",
       "    {'text': 'the', 'start': 204.28, 'end': 204.38, 'confidence': 0.962},\n",
       "    {'text': 'self', 'start': 204.38, 'end': 204.54, 'confidence': 0.816},\n",
       "    {'text': 'driving', 'start': 204.54, 'end': 204.68, 'confidence': 0.877},\n",
       "    {'text': 'car', 'start': 204.68, 'end': 204.92, 'confidence': 0.992},\n",
       "    {'text': 'example', 'start': 204.92, 'end': 205.36, 'confidence': 0.995},\n",
       "    {'text': 'include', 'start': 205.36, 'end': 205.88, 'confidence': 0.964},\n",
       "    {'text': 'vision,', 'start': 205.88, 'end': 206.5, 'confidence': 0.965},\n",
       "    {'text': 'language', 'start': 206.98, 'end': 207.22, 'confidence': 0.992},\n",
       "    {'text': 'processing', 'start': 207.22, 'end': 207.7, 'confidence': 0.996},\n",
       "    {'text': 'and', 'start': 207.7, 'end': 208.12, 'confidence': 0.985},\n",
       "    {'text': 'planning.',\n",
       "     'start': 208.12,\n",
       "     'end': 208.5,\n",
       "     'confidence': 0.999}]},\n",
       "  {'id': 30,\n",
       "   'seek': 19900,\n",
       "   'start': 208.78,\n",
       "   'end': 221.88,\n",
       "   'text': \" These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning.\",\n",
       "   'tokens': [50864,\n",
       "    1981,\n",
       "    366,\n",
       "    445,\n",
       "    257,\n",
       "    1916,\n",
       "    295,\n",
       "    5110,\n",
       "    13,\n",
       "    407,\n",
       "    11,\n",
       "    5201,\n",
       "    307,\n",
       "    516,\n",
       "    281,\n",
       "    312,\n",
       "    3701,\n",
       "    420,\n",
       "    4084,\n",
       "    5267,\n",
       "    420,\n",
       "    960,\n",
       "    2856,\n",
       "    9007,\n",
       "    11,\n",
       "    3701,\n",
       "    420,\n",
       "    4084,\n",
       "    6218,\n",
       "    420,\n",
       "    2487,\n",
       "    300,\n",
       "    311,\n",
       "    516,\n",
       "    281,\n",
       "    312,\n",
       "    411,\n",
       "    33682,\n",
       "    420,\n",
       "    6795,\n",
       "    22595,\n",
       "    293,\n",
       "    5038,\n",
       "    13,\n",
       "    51564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10106727744959577,\n",
       "   'compression_ratio': 1.7227272727272727,\n",
       "   'no_speech_prob': 0.04462442547082901,\n",
       "   'confidence': 0.962,\n",
       "   'words': [{'text': 'These',\n",
       "     'start': 208.78,\n",
       "     'end': 209.06,\n",
       "     'confidence': 0.85},\n",
       "    {'text': 'are', 'start': 209.06, 'end': 209.12, 'confidence': 1.0},\n",
       "    {'text': 'just', 'start': 209.12, 'end': 209.28, 'confidence': 1.0},\n",
       "    {'text': 'a', 'start': 209.28, 'end': 209.42, 'confidence': 1.0},\n",
       "    {'text': 'couple', 'start': 209.42, 'end': 209.62, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 209.62, 'end': 209.82, 'confidence': 1.0},\n",
       "    {'text': 'examples.', 'start': 209.82, 'end': 210.24, 'confidence': 0.999},\n",
       "    {'text': 'So,', 'start': 210.42, 'end': 211.02, 'confidence': 0.989},\n",
       "    {'text': 'vision', 'start': 211.1, 'end': 211.58, 'confidence': 0.95},\n",
       "    {'text': 'is', 'start': 211.58, 'end': 211.94, 'confidence': 0.944},\n",
       "    {'text': 'going', 'start': 211.94, 'end': 212.04, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 212.04, 'end': 212.16, 'confidence': 1.0},\n",
       "    {'text': 'be', 'start': 212.16, 'end': 212.48, 'confidence': 1.0},\n",
       "    {'text': 'understanding',\n",
       "     'start': 212.48,\n",
       "     'end': 213.08,\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'or', 'start': 213.08, 'end': 213.36, 'confidence': 0.962},\n",
       "    {'text': 'creating', 'start': 213.36, 'end': 213.64, 'confidence': 0.998},\n",
       "    {'text': 'images', 'start': 213.64, 'end': 214.08, 'confidence': 0.999},\n",
       "    {'text': 'or', 'start': 214.08, 'end': 214.34, 'confidence': 0.995},\n",
       "    {'text': 'video', 'start': 214.34, 'end': 214.88, 'confidence': 0.996},\n",
       "    {'text': 'language', 'start': 214.88, 'end': 215.5, 'confidence': 0.858},\n",
       "    {'text': 'processing,', 'start': 215.5, 'end': 216.1, 'confidence': 0.998},\n",
       "    {'text': 'understanding',\n",
       "     'start': 216.44,\n",
       "     'end': 216.72,\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'or', 'start': 216.72, 'end': 217.06, 'confidence': 0.668},\n",
       "    {'text': 'creating', 'start': 217.06, 'end': 217.4, 'confidence': 0.998},\n",
       "    {'text': 'speech', 'start': 217.4, 'end': 217.92, 'confidence': 0.998},\n",
       "    {'text': 'or', 'start': 217.92, 'end': 218.18, 'confidence': 0.99},\n",
       "    {'text': 'text', 'start': 218.18, 'end': 218.52, 'confidence': 0.969},\n",
       "    {'text': \"that's\", 'start': 218.52, 'end': 218.8, 'confidence': 0.949},\n",
       "    {'text': 'going', 'start': 218.8, 'end': 218.94, 'confidence': 0.99},\n",
       "    {'text': 'to', 'start': 218.94, 'end': 218.98, 'confidence': 0.999},\n",
       "    {'text': 'be', 'start': 218.98, 'end': 219.1, 'confidence': 0.999},\n",
       "    {'text': 'like', 'start': 219.1, 'end': 219.32, 'confidence': 0.997},\n",
       "    {'text': 'Siri', 'start': 219.32, 'end': 219.58, 'confidence': 0.959},\n",
       "    {'text': 'or', 'start': 219.58, 'end': 219.84, 'confidence': 0.996},\n",
       "    {'text': 'Amazon', 'start': 219.84, 'end': 220.1, 'confidence': 0.988},\n",
       "    {'text': 'Alexa', 'start': 220.1, 'end': 220.5, 'confidence': 0.998},\n",
       "    {'text': 'and', 'start': 220.5, 'end': 221.38, 'confidence': 0.696},\n",
       "    {'text': 'planning.',\n",
       "     'start': 221.38,\n",
       "     'end': 221.88,\n",
       "     'confidence': 0.988}]},\n",
       "  {'id': 31,\n",
       "   'seek': 22300,\n",
       "   'start': 223.0,\n",
       "   'end': 227.26,\n",
       "   'text': \" So, there's a lot of different kinds of planning, you can do route planning motion planning task planning.\",\n",
       "   'tokens': [50364,\n",
       "    407,\n",
       "    11,\n",
       "    456,\n",
       "    311,\n",
       "    257,\n",
       "    688,\n",
       "    295,\n",
       "    819,\n",
       "    3685,\n",
       "    295,\n",
       "    5038,\n",
       "    11,\n",
       "    291,\n",
       "    393,\n",
       "    360,\n",
       "    7955,\n",
       "    5038,\n",
       "    5394,\n",
       "    5038,\n",
       "    5633,\n",
       "    5038,\n",
       "    13,\n",
       "    50664],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18343359715229757,\n",
       "   'compression_ratio': 1.6958762886597938,\n",
       "   'no_speech_prob': 0.4756874144077301,\n",
       "   'confidence': 0.649,\n",
       "   'words': [{'text': 'So,',\n",
       "     'start': 223.0,\n",
       "     'end': 223.02,\n",
       "     'confidence': 0.237},\n",
       "    {'text': \"there's\", 'start': 223.02, 'end': 223.04, 'confidence': 0.259},\n",
       "    {'text': 'a', 'start': 223.04, 'end': 223.06, 'confidence': 0.399},\n",
       "    {'text': 'lot', 'start': 223.06, 'end': 223.08, 'confidence': 0.519},\n",
       "    {'text': 'of', 'start': 223.08, 'end': 223.1, 'confidence': 0.916},\n",
       "    {'text': 'different', 'start': 223.1, 'end': 223.12, 'confidence': 0.562},\n",
       "    {'text': 'kinds', 'start': 223.12, 'end': 223.14, 'confidence': 0.486},\n",
       "    {'text': 'of', 'start': 223.14, 'end': 223.28, 'confidence': 0.998},\n",
       "    {'text': 'planning,', 'start': 223.28, 'end': 223.58, 'confidence': 0.894},\n",
       "    {'text': 'you', 'start': 224.0, 'end': 224.02, 'confidence': 0.984},\n",
       "    {'text': 'can', 'start': 224.02, 'end': 224.16, 'confidence': 0.998},\n",
       "    {'text': 'do', 'start': 224.16, 'end': 224.3, 'confidence': 0.997},\n",
       "    {'text': 'route', 'start': 224.3, 'end': 224.62, 'confidence': 0.982},\n",
       "    {'text': 'planning', 'start': 224.62, 'end': 225.04, 'confidence': 0.99},\n",
       "    {'text': 'motion', 'start': 225.04, 'end': 225.48, 'confidence': 0.54},\n",
       "    {'text': 'planning', 'start': 225.48, 'end': 226.08, 'confidence': 0.996},\n",
       "    {'text': 'task', 'start': 226.08, 'end': 226.72, 'confidence': 0.729},\n",
       "    {'text': 'planning.',\n",
       "     'start': 226.72,\n",
       "     'end': 227.26,\n",
       "     'confidence': 0.996}]},\n",
       "  {'id': 32,\n",
       "   'seek': 22300,\n",
       "   'start': 228.5,\n",
       "   'end': 233.82,\n",
       "   'text': ' All these things fall under the category of narrow AI tasks that you can train an algorithm to do.',\n",
       "   'tokens': [50664,\n",
       "    1057,\n",
       "    613,\n",
       "    721,\n",
       "    2100,\n",
       "    833,\n",
       "    264,\n",
       "    7719,\n",
       "    295,\n",
       "    9432,\n",
       "    7318,\n",
       "    9608,\n",
       "    300,\n",
       "    291,\n",
       "    393,\n",
       "    3847,\n",
       "    364,\n",
       "    9284,\n",
       "    281,\n",
       "    360,\n",
       "    13,\n",
       "    50964],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18343359715229757,\n",
       "   'compression_ratio': 1.6958762886597938,\n",
       "   'no_speech_prob': 0.4756874144077301,\n",
       "   'confidence': 0.986,\n",
       "   'words': [{'text': 'All',\n",
       "     'start': 228.5,\n",
       "     'end': 228.58,\n",
       "     'confidence': 0.948},\n",
       "    {'text': 'these', 'start': 228.58, 'end': 228.78, 'confidence': 0.991},\n",
       "    {'text': 'things', 'start': 228.78, 'end': 229.26, 'confidence': 0.998},\n",
       "    {'text': 'fall', 'start': 229.26, 'end': 229.64, 'confidence': 0.987},\n",
       "    {'text': 'under', 'start': 229.64, 'end': 229.84, 'confidence': 0.994},\n",
       "    {'text': 'the', 'start': 229.84, 'end': 230.04, 'confidence': 0.999},\n",
       "    {'text': 'category', 'start': 230.04, 'end': 230.34, 'confidence': 0.999},\n",
       "    {'text': 'of', 'start': 230.34, 'end': 230.74, 'confidence': 0.999},\n",
       "    {'text': 'narrow', 'start': 230.74, 'end': 231.08, 'confidence': 0.984},\n",
       "    {'text': 'AI', 'start': 231.08, 'end': 231.48, 'confidence': 0.937},\n",
       "    {'text': 'tasks', 'start': 231.48, 'end': 232.0, 'confidence': 0.996},\n",
       "    {'text': 'that', 'start': 232.0, 'end': 232.2, 'confidence': 0.994},\n",
       "    {'text': 'you', 'start': 232.2, 'end': 232.3, 'confidence': 1.0},\n",
       "    {'text': 'can', 'start': 232.3, 'end': 232.44, 'confidence': 0.997},\n",
       "    {'text': 'train', 'start': 232.44, 'end': 232.58, 'confidence': 0.996},\n",
       "    {'text': 'an', 'start': 232.58, 'end': 232.74, 'confidence': 0.932},\n",
       "    {'text': 'algorithm', 'start': 232.74, 'end': 232.96, 'confidence': 0.999},\n",
       "    {'text': 'to', 'start': 232.96, 'end': 233.14, 'confidence': 0.998},\n",
       "    {'text': 'do.', 'start': 233.14, 'end': 233.82, 'confidence': 0.998}]},\n",
       "  {'id': 33,\n",
       "   'seek': 22300,\n",
       "   'start': 234.5,\n",
       "   'end': 242.92,\n",
       "   'text': \" As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence.\",\n",
       "   'tokens': [50964,\n",
       "    1018,\n",
       "    1400,\n",
       "    382,\n",
       "    577,\n",
       "    321,\n",
       "    767,\n",
       "    1322,\n",
       "    7318,\n",
       "    13,\n",
       "    821,\n",
       "    311,\n",
       "    257,\n",
       "    688,\n",
       "    295,\n",
       "    819,\n",
       "    2098,\n",
       "    281,\n",
       "    13735,\n",
       "    2098,\n",
       "    281,\n",
       "    4445,\n",
       "    11677,\n",
       "    7599,\n",
       "    13,\n",
       "    51414],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18343359715229757,\n",
       "   'compression_ratio': 1.6958762886597938,\n",
       "   'no_speech_prob': 0.4756874144077301,\n",
       "   'confidence': 0.984,\n",
       "   'words': [{'text': 'As',\n",
       "     'start': 234.5,\n",
       "     'end': 235.02,\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'far', 'start': 235.02, 'end': 235.18, 'confidence': 0.999},\n",
       "    {'text': 'as', 'start': 235.18, 'end': 235.28, 'confidence': 1.0},\n",
       "    {'text': 'how', 'start': 235.28, 'end': 235.44, 'confidence': 0.999},\n",
       "    {'text': 'we', 'start': 235.44, 'end': 235.62, 'confidence': 1.0},\n",
       "    {'text': 'actually', 'start': 235.62, 'end': 235.98, 'confidence': 1.0},\n",
       "    {'text': 'build', 'start': 235.98, 'end': 236.38, 'confidence': 0.989},\n",
       "    {'text': 'AI.', 'start': 236.38, 'end': 236.8, 'confidence': 0.918},\n",
       "    {'text': \"There's\", 'start': 237.18, 'end': 237.28, 'confidence': 0.987},\n",
       "    {'text': 'a', 'start': 237.28, 'end': 237.38, 'confidence': 1.0},\n",
       "    {'text': 'lot', 'start': 237.38, 'end': 237.48, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 237.48, 'end': 237.6, 'confidence': 0.999},\n",
       "    {'text': 'different', 'start': 237.6, 'end': 237.72, 'confidence': 0.998},\n",
       "    {'text': 'ways', 'start': 237.72, 'end': 238.28, 'confidence': 0.959},\n",
       "    {'text': 'to', 'start': 238.28, 'end': 239.98, 'confidence': 0.933},\n",
       "    {'text': 'classical', 'start': 239.98, 'end': 241.04, 'confidence': 0.991},\n",
       "    {'text': 'ways', 'start': 241.04, 'end': 241.4, 'confidence': 0.996},\n",
       "    {'text': 'to', 'start': 241.4, 'end': 241.58, 'confidence': 0.997},\n",
       "    {'text': 'implement', 'start': 241.58, 'end': 241.82, 'confidence': 0.996},\n",
       "    {'text': 'artificial',\n",
       "     'start': 241.82,\n",
       "     'end': 242.26,\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'intelligence.',\n",
       "     'start': 242.26,\n",
       "     'end': 242.92,\n",
       "     'confidence': 0.999}]},\n",
       "  {'id': 34,\n",
       "   'seek': 24400,\n",
       "   'start': 244.0,\n",
       "   'end': 256.12,\n",
       "   'text': \" So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that.\",\n",
       "   'tokens': [50364,\n",
       "    407,\n",
       "    11,\n",
       "    264,\n",
       "    721,\n",
       "    300,\n",
       "    321,\n",
       "    434,\n",
       "    2539,\n",
       "    466,\n",
       "    341,\n",
       "    293,\n",
       "    885,\n",
       "    411,\n",
       "    6076,\n",
       "    341,\n",
       "    307,\n",
       "    406,\n",
       "    13232,\n",
       "    412,\n",
       "    439,\n",
       "    341,\n",
       "    307,\n",
       "    1687,\n",
       "    10316,\n",
       "    366,\n",
       "    5844,\n",
       "    3652,\n",
       "    293,\n",
       "    4230,\n",
       "    3164,\n",
       "    13,\n",
       "    407,\n",
       "    294,\n",
       "    364,\n",
       "    5844,\n",
       "    1185,\n",
       "    11,\n",
       "    309,\n",
       "    311,\n",
       "    445,\n",
       "    257,\n",
       "    954,\n",
       "    3579,\n",
       "    257,\n",
       "    1329,\n",
       "    295,\n",
       "    4474,\n",
       "    11,\n",
       "    498,\n",
       "    341,\n",
       "    813,\n",
       "    300,\n",
       "    11,\n",
       "    498,\n",
       "    341,\n",
       "    813,\n",
       "    300,\n",
       "    13,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.19118458462744645,\n",
       "   'compression_ratio': 1.7457627118644068,\n",
       "   'no_speech_prob': 0.5146414041519165,\n",
       "   'confidence': 0.789,\n",
       "   'words': [{'text': 'So,',\n",
       "     'start': 244.0,\n",
       "     'end': 244.02,\n",
       "     'confidence': 0.165},\n",
       "    {'text': 'the', 'start': 244.02, 'end': 244.04, 'confidence': 0.127},\n",
       "    {'text': 'things', 'start': 244.04, 'end': 244.06, 'confidence': 0.133},\n",
       "    {'text': 'that', 'start': 244.06, 'end': 244.08, 'confidence': 0.679},\n",
       "    {'text': \"we're\", 'start': 244.08, 'end': 244.1, 'confidence': 0.713},\n",
       "    {'text': 'learning', 'start': 244.1, 'end': 244.46, 'confidence': 0.936},\n",
       "    {'text': 'about', 'start': 244.46, 'end': 244.68, 'confidence': 0.996},\n",
       "    {'text': 'this', 'start': 244.68, 'end': 244.84, 'confidence': 0.987},\n",
       "    {'text': 'and', 'start': 244.84, 'end': 244.94, 'confidence': 0.989},\n",
       "    {'text': 'being', 'start': 244.94, 'end': 245.04, 'confidence': 0.992},\n",
       "    {'text': 'like', 'start': 245.04, 'end': 245.16, 'confidence': 0.999},\n",
       "    {'text': 'wow', 'start': 245.16, 'end': 245.34, 'confidence': 0.672},\n",
       "    {'text': 'this', 'start': 245.34, 'end': 245.5, 'confidence': 0.881},\n",
       "    {'text': 'is', 'start': 245.5, 'end': 245.64, 'confidence': 0.997},\n",
       "    {'text': 'not', 'start': 245.64, 'end': 245.78, 'confidence': 0.998},\n",
       "    {'text': 'intelligent',\n",
       "     'start': 245.78,\n",
       "     'end': 246.08,\n",
       "     'confidence': 0.78},\n",
       "    {'text': 'at', 'start': 246.08, 'end': 246.24, 'confidence': 0.97},\n",
       "    {'text': 'all', 'start': 246.24, 'end': 246.32, 'confidence': 0.999},\n",
       "    {'text': 'this', 'start': 246.32, 'end': 246.54, 'confidence': 0.807},\n",
       "    {'text': 'is', 'start': 246.54, 'end': 246.74, 'confidence': 0.711},\n",
       "    {'text': 'super', 'start': 246.74, 'end': 246.9, 'confidence': 0.996},\n",
       "    {'text': 'dumb', 'start': 246.9, 'end': 247.52, 'confidence': 0.987},\n",
       "    {'text': 'are', 'start': 247.52, 'end': 248.32, 'confidence': 0.478},\n",
       "    {'text': 'expert', 'start': 248.32, 'end': 248.8, 'confidence': 0.985},\n",
       "    {'text': 'systems', 'start': 248.8, 'end': 249.14, 'confidence': 0.998},\n",
       "    {'text': 'and', 'start': 249.14, 'end': 249.44, 'confidence': 0.995},\n",
       "    {'text': 'tree', 'start': 249.44, 'end': 249.64, 'confidence': 0.742},\n",
       "    {'text': 'search.', 'start': 249.64, 'end': 249.88, 'confidence': 0.996},\n",
       "    {'text': 'So', 'start': 250.26, 'end': 250.28, 'confidence': 0.806},\n",
       "    {'text': 'in', 'start': 250.28, 'end': 250.44, 'confidence': 0.82},\n",
       "    {'text': 'an', 'start': 250.44, 'end': 250.62, 'confidence': 0.998},\n",
       "    {'text': 'expert', 'start': 250.62, 'end': 250.9, 'confidence': 0.999},\n",
       "    {'text': 'system,', 'start': 250.9, 'end': 251.3, 'confidence': 0.999},\n",
       "    {'text': \"it's\", 'start': 251.62, 'end': 251.66, 'confidence': 0.986},\n",
       "    {'text': 'just', 'start': 251.66, 'end': 251.9, 'confidence': 0.999},\n",
       "    {'text': 'a', 'start': 251.9, 'end': 252.12, 'confidence': 0.999},\n",
       "    {'text': 'person', 'start': 252.12, 'end': 252.46, 'confidence': 0.999},\n",
       "    {'text': 'writing', 'start': 252.46, 'end': 252.74, 'confidence': 0.954},\n",
       "    {'text': 'a', 'start': 252.74, 'end': 252.88, 'confidence': 0.867},\n",
       "    {'text': 'list', 'start': 252.88, 'end': 253.02, 'confidence': 0.995},\n",
       "    {'text': 'of', 'start': 253.02, 'end': 253.14, 'confidence': 0.999},\n",
       "    {'text': 'rules,', 'start': 253.14, 'end': 253.42, 'confidence': 0.995},\n",
       "    {'text': 'if', 'start': 253.68, 'end': 253.86, 'confidence': 0.984},\n",
       "    {'text': 'this', 'start': 253.86, 'end': 254.06, 'confidence': 0.998},\n",
       "    {'text': 'than', 'start': 254.06, 'end': 254.32, 'confidence': 0.307},\n",
       "    {'text': 'that,', 'start': 254.32, 'end': 254.6, 'confidence': 0.99},\n",
       "    {'text': 'if', 'start': 254.82, 'end': 254.98, 'confidence': 0.98},\n",
       "    {'text': 'this', 'start': 254.98, 'end': 255.32, 'confidence': 0.994},\n",
       "    {'text': 'than', 'start': 255.32, 'end': 255.52, 'confidence': 0.384},\n",
       "    {'text': 'that.', 'start': 255.52, 'end': 256.12, 'confidence': 0.982}]},\n",
       "  {'id': 35,\n",
       "   'seek': 24400,\n",
       "   'start': 257.5,\n",
       "   'end': 260.66,\n",
       "   'text': ' This can be super useful for certain problems.',\n",
       "   'tokens': [51064, 639, 393, 312, 1687, 4420, 337, 1629, 2740, 13, 51314],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.19118458462744645,\n",
       "   'compression_ratio': 1.7457627118644068,\n",
       "   'no_speech_prob': 0.5146414041519165,\n",
       "   'confidence': 0.977,\n",
       "   'words': [{'text': 'This',\n",
       "     'start': 257.5,\n",
       "     'end': 257.52,\n",
       "     'confidence': 0.856},\n",
       "    {'text': 'can', 'start': 257.52, 'end': 257.54, 'confidence': 0.975},\n",
       "    {'text': 'be', 'start': 257.54, 'end': 257.66, 'confidence': 1.0},\n",
       "    {'text': 'super', 'start': 257.66, 'end': 257.88, 'confidence': 0.999},\n",
       "    {'text': 'useful', 'start': 257.88, 'end': 258.4, 'confidence': 0.999},\n",
       "    {'text': 'for', 'start': 258.4, 'end': 259.42, 'confidence': 0.997},\n",
       "    {'text': 'certain', 'start': 259.42, 'end': 260.04, 'confidence': 1.0},\n",
       "    {'text': 'problems.',\n",
       "     'start': 260.04,\n",
       "     'end': 260.66,\n",
       "     'confidence': 0.998}]},\n",
       "  {'id': 36,\n",
       "   'seek': 24400,\n",
       "   'start': 262.7,\n",
       "   'end': 267.82,\n",
       "   'text': ' But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult.',\n",
       "   'tokens': [51314,\n",
       "    583,\n",
       "    257,\n",
       "    688,\n",
       "    295,\n",
       "    264,\n",
       "    721,\n",
       "    300,\n",
       "    321,\n",
       "    767,\n",
       "    519,\n",
       "    295,\n",
       "    382,\n",
       "    534,\n",
       "    15325,\n",
       "    11,\n",
       "    1261,\n",
       "    484,\n",
       "    281,\n",
       "    312,\n",
       "    1596,\n",
       "    2252,\n",
       "    13,\n",
       "    51614],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.19118458462744645,\n",
       "   'compression_ratio': 1.7457627118644068,\n",
       "   'no_speech_prob': 0.5146414041519165,\n",
       "   'confidence': 0.938,\n",
       "   'words': [{'text': 'But',\n",
       "     'start': 262.7,\n",
       "     'end': 263.16,\n",
       "     'confidence': 0.585},\n",
       "    {'text': 'a', 'start': 263.16, 'end': 263.64, 'confidence': 0.883},\n",
       "    {'text': 'lot', 'start': 263.64, 'end': 263.82, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 263.82, 'end': 263.94, 'confidence': 1.0},\n",
       "    {'text': 'the', 'start': 263.94, 'end': 264.02, 'confidence': 0.996},\n",
       "    {'text': 'things', 'start': 264.02, 'end': 264.16, 'confidence': 1.0},\n",
       "    {'text': 'that', 'start': 264.16, 'end': 264.34, 'confidence': 1.0},\n",
       "    {'text': 'we', 'start': 264.34, 'end': 264.56, 'confidence': 1.0},\n",
       "    {'text': 'actually', 'start': 264.56, 'end': 264.76, 'confidence': 1.0},\n",
       "    {'text': 'think', 'start': 264.76, 'end': 264.96, 'confidence': 1.0},\n",
       "    {'text': 'of', 'start': 264.96, 'end': 265.1, 'confidence': 0.976},\n",
       "    {'text': 'as', 'start': 265.1, 'end': 265.24, 'confidence': 0.742},\n",
       "    {'text': 'really', 'start': 265.24, 'end': 265.62, 'confidence': 1.0},\n",
       "    {'text': 'straightforward,',\n",
       "     'start': 265.62,\n",
       "     'end': 266.42,\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'turn', 'start': 266.88, 'end': 266.96, 'confidence': 0.758},\n",
       "    {'text': 'out', 'start': 266.96, 'end': 267.04, 'confidence': 0.998},\n",
       "    {'text': 'to', 'start': 267.04, 'end': 267.12, 'confidence': 1.0},\n",
       "    {'text': 'be', 'start': 267.12, 'end': 267.2, 'confidence': 1.0},\n",
       "    {'text': 'quite', 'start': 267.2, 'end': 267.36, 'confidence': 0.999},\n",
       "    {'text': 'difficult.',\n",
       "     'start': 267.36,\n",
       "     'end': 267.82,\n",
       "     'confidence': 0.993}]},\n",
       "  {'id': 37,\n",
       "   'seek': 26900,\n",
       "   'start': 269.0,\n",
       "   'end': 269.64,\n",
       "   'text': ' So, for example,',\n",
       "   'tokens': [50364, 407, 11, 337, 1365, 11, 50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14944950309959618,\n",
       "   'compression_ratio': 1.4850299401197604,\n",
       "   'no_speech_prob': 0.5834770798683167,\n",
       "   'confidence': 0.543,\n",
       "   'words': [{'text': 'So,',\n",
       "     'start': 269.0,\n",
       "     'end': 269.02,\n",
       "     'confidence': 0.38},\n",
       "    {'text': 'for', 'start': 269.26, 'end': 269.28, 'confidence': 0.433},\n",
       "    {'text': 'example,',\n",
       "     'start': 269.28,\n",
       "     'end': 269.64,\n",
       "     'confidence': 0.975}]},\n",
       "  {'id': 38,\n",
       "   'seek': 26900,\n",
       "   'start': 272.5,\n",
       "   'end': 277.2,\n",
       "   'text': ' we can identify a table like that. Very, very easily. We know what a table is.',\n",
       "   'tokens': [50564,\n",
       "    321,\n",
       "    393,\n",
       "    5876,\n",
       "    257,\n",
       "    3199,\n",
       "    411,\n",
       "    300,\n",
       "    13,\n",
       "    4372,\n",
       "    11,\n",
       "    588,\n",
       "    3612,\n",
       "    13,\n",
       "    492,\n",
       "    458,\n",
       "    437,\n",
       "    257,\n",
       "    3199,\n",
       "    307,\n",
       "    13,\n",
       "    50814],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14944950309959618,\n",
       "   'compression_ratio': 1.4850299401197604,\n",
       "   'no_speech_prob': 0.5834770798683167,\n",
       "   'confidence': 0.914,\n",
       "   'words': [{'text': 'we',\n",
       "     'start': 272.5,\n",
       "     'end': 272.82,\n",
       "     'confidence': 0.744},\n",
       "    {'text': 'can', 'start': 272.82, 'end': 273.02, 'confidence': 0.912},\n",
       "    {'text': 'identify', 'start': 273.02, 'end': 273.28, 'confidence': 0.996},\n",
       "    {'text': 'a', 'start': 273.28, 'end': 273.92, 'confidence': 0.749},\n",
       "    {'text': 'table', 'start': 273.92, 'end': 273.94, 'confidence': 0.998},\n",
       "    {'text': 'like', 'start': 273.94, 'end': 274.66, 'confidence': 0.755},\n",
       "    {'text': 'that.', 'start': 274.66, 'end': 274.98, 'confidence': 0.999},\n",
       "    {'text': 'Very,', 'start': 275.24, 'end': 275.5, 'confidence': 0.93},\n",
       "    {'text': 'very', 'start': 275.5, 'end': 275.68, 'confidence': 0.998},\n",
       "    {'text': 'easily.', 'start': 275.68, 'end': 276.0, 'confidence': 0.991},\n",
       "    {'text': 'We', 'start': 276.32, 'end': 276.38, 'confidence': 0.95},\n",
       "    {'text': 'know', 'start': 276.38, 'end': 276.46, 'confidence': 0.957},\n",
       "    {'text': 'what', 'start': 276.46, 'end': 276.56, 'confidence': 0.921},\n",
       "    {'text': 'a', 'start': 276.56, 'end': 276.64, 'confidence': 0.822},\n",
       "    {'text': 'table', 'start': 276.64, 'end': 276.82, 'confidence': 0.997},\n",
       "    {'text': 'is.', 'start': 276.82, 'end': 277.2, 'confidence': 0.991}]},\n",
       "  {'id': 39,\n",
       "   'seek': 26900,\n",
       "   'start': 277.58,\n",
       "   'end': 282.16,\n",
       "   'text': ' But I challenge you to write a list of rules that can define a table.',\n",
       "   'tokens': [50814,\n",
       "    583,\n",
       "    286,\n",
       "    3430,\n",
       "    291,\n",
       "    281,\n",
       "    2464,\n",
       "    257,\n",
       "    1329,\n",
       "    295,\n",
       "    4474,\n",
       "    300,\n",
       "    393,\n",
       "    6964,\n",
       "    257,\n",
       "    3199,\n",
       "    13,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14944950309959618,\n",
       "   'compression_ratio': 1.4850299401197604,\n",
       "   'no_speech_prob': 0.5834770798683167,\n",
       "   'confidence': 0.976,\n",
       "   'words': [{'text': 'But',\n",
       "     'start': 277.58,\n",
       "     'end': 278.38,\n",
       "     'confidence': 0.983},\n",
       "    {'text': 'I', 'start': 278.38, 'end': 278.96, 'confidence': 0.924},\n",
       "    {'text': 'challenge', 'start': 278.96, 'end': 279.44, 'confidence': 0.961},\n",
       "    {'text': 'you', 'start': 279.44, 'end': 279.88, 'confidence': 0.993},\n",
       "    {'text': 'to', 'start': 279.88, 'end': 280.16, 'confidence': 0.995},\n",
       "    {'text': 'write', 'start': 280.16, 'end': 280.32, 'confidence': 0.999},\n",
       "    {'text': 'a', 'start': 280.32, 'end': 280.46, 'confidence': 0.998},\n",
       "    {'text': 'list', 'start': 280.46, 'end': 280.6, 'confidence': 0.999},\n",
       "    {'text': 'of', 'start': 280.6, 'end': 280.78, 'confidence': 1.0},\n",
       "    {'text': 'rules', 'start': 280.78, 'end': 281.06, 'confidence': 0.814},\n",
       "    {'text': 'that', 'start': 281.06, 'end': 281.28, 'confidence': 0.999},\n",
       "    {'text': 'can', 'start': 281.28, 'end': 281.44, 'confidence': 0.999},\n",
       "    {'text': 'define', 'start': 281.44, 'end': 281.68, 'confidence': 0.998},\n",
       "    {'text': 'a', 'start': 281.68, 'end': 281.86, 'confidence': 0.994},\n",
       "    {'text': 'table.', 'start': 281.86, 'end': 282.16, 'confidence': 0.999}]},\n",
       "  {'id': 40,\n",
       "   'seek': 26900,\n",
       "   'start': 282.5,\n",
       "   'end': 286.72,\n",
       "   'text': \" What color is it, what's it made of, how many legs does it have, what shape is it.\",\n",
       "   'tokens': [51064,\n",
       "    708,\n",
       "    2017,\n",
       "    307,\n",
       "    309,\n",
       "    11,\n",
       "    437,\n",
       "    311,\n",
       "    309,\n",
       "    1027,\n",
       "    295,\n",
       "    11,\n",
       "    577,\n",
       "    867,\n",
       "    5668,\n",
       "    775,\n",
       "    309,\n",
       "    362,\n",
       "    11,\n",
       "    437,\n",
       "    3909,\n",
       "    307,\n",
       "    309,\n",
       "    13,\n",
       "    51414],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14944950309959618,\n",
       "   'compression_ratio': 1.4850299401197604,\n",
       "   'no_speech_prob': 0.5834770798683167,\n",
       "   'confidence': 0.967,\n",
       "   'words': [{'text': 'What',\n",
       "     'start': 282.5,\n",
       "     'end': 283.2,\n",
       "     'confidence': 0.975},\n",
       "    {'text': 'color', 'start': 283.2, 'end': 283.42, 'confidence': 0.976},\n",
       "    {'text': 'is', 'start': 283.42, 'end': 283.6, 'confidence': 0.975},\n",
       "    {'text': 'it,', 'start': 283.6, 'end': 283.82, 'confidence': 0.997},\n",
       "    {'text': \"what's\", 'start': 283.92, 'end': 284.08, 'confidence': 0.97},\n",
       "    {'text': 'it', 'start': 284.08, 'end': 284.18, 'confidence': 0.993},\n",
       "    {'text': 'made', 'start': 284.18, 'end': 284.32, 'confidence': 0.999},\n",
       "    {'text': 'of,', 'start': 284.32, 'end': 284.52, 'confidence': 0.983},\n",
       "    {'text': 'how', 'start': 284.62, 'end': 284.74, 'confidence': 0.992},\n",
       "    {'text': 'many', 'start': 284.74, 'end': 284.86, 'confidence': 0.999},\n",
       "    {'text': 'legs', 'start': 284.86, 'end': 285.06, 'confidence': 0.861},\n",
       "    {'text': 'does', 'start': 285.06, 'end': 285.2, 'confidence': 0.84},\n",
       "    {'text': 'it', 'start': 285.2, 'end': 285.32, 'confidence': 0.988},\n",
       "    {'text': 'have,', 'start': 285.32, 'end': 285.54, 'confidence': 0.961},\n",
       "    {'text': 'what', 'start': 285.74, 'end': 285.8, 'confidence': 0.984},\n",
       "    {'text': 'shape', 'start': 285.8, 'end': 286.02, 'confidence': 0.996},\n",
       "    {'text': 'is', 'start': 286.02, 'end': 286.24, 'confidence': 0.959},\n",
       "    {'text': 'it.', 'start': 286.24, 'end': 286.72, 'confidence': 0.976}]},\n",
       "  {'id': 41,\n",
       "   'seek': 29000,\n",
       "   'start': 290.0,\n",
       "   'end': 300.38,\n",
       "   'text': ' And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.',\n",
       "   'tokens': [50364,\n",
       "    400,\n",
       "    754,\n",
       "    746,\n",
       "    411,\n",
       "    437,\n",
       "    307,\n",
       "    257,\n",
       "    3199,\n",
       "    3643,\n",
       "    534,\n",
       "    11,\n",
       "    534,\n",
       "    7595,\n",
       "    281,\n",
       "    1867,\n",
       "    1228,\n",
       "    364,\n",
       "    5844,\n",
       "    1185,\n",
       "    13,\n",
       "    407,\n",
       "    613,\n",
       "    393,\n",
       "    312,\n",
       "    534,\n",
       "    4961,\n",
       "    293,\n",
       "    456,\n",
       "    366,\n",
       "    512,\n",
       "    2199,\n",
       "    2098,\n",
       "    11,\n",
       "    420,\n",
       "    2831,\n",
       "    11,\n",
       "    456,\n",
       "    366,\n",
       "    512,\n",
       "    2740,\n",
       "    300,\n",
       "    321,\n",
       "    393,\n",
       "    360,\n",
       "    281,\n",
       "    5039,\n",
       "    613,\n",
       "    2740,\n",
       "    13,\n",
       "    50864],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3960122328538161,\n",
       "   'compression_ratio': 1.5870967741935484,\n",
       "   'no_speech_prob': 0.8920807242393494,\n",
       "   'confidence': 0.685,\n",
       "   'words': [{'text': 'And',\n",
       "     'start': 290.0,\n",
       "     'end': 290.06,\n",
       "     'confidence': 0.215},\n",
       "    {'text': 'even', 'start': 290.06, 'end': 290.32, 'confidence': 0.349},\n",
       "    {'text': 'something', 'start': 290.32, 'end': 290.68, 'confidence': 0.976},\n",
       "    {'text': 'like', 'start': 290.68, 'end': 291.04, 'confidence': 0.992},\n",
       "    {'text': 'what', 'start': 291.04, 'end': 291.3, 'confidence': 0.786},\n",
       "    {'text': 'is', 'start': 291.3, 'end': 291.46, 'confidence': 0.937},\n",
       "    {'text': 'a', 'start': 291.46, 'end': 291.54, 'confidence': 0.949},\n",
       "    {'text': 'table', 'start': 291.54, 'end': 291.84, 'confidence': 0.998},\n",
       "    {'text': 'becomes', 'start': 291.84, 'end': 292.18, 'confidence': 0.914},\n",
       "    {'text': 'really,', 'start': 292.18, 'end': 292.58, 'confidence': 0.945},\n",
       "    {'text': 'really', 'start': 292.58, 'end': 292.82, 'confidence': 0.991},\n",
       "    {'text': 'challenging',\n",
       "     'start': 292.82,\n",
       "     'end': 293.34,\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'to', 'start': 293.34, 'end': 294.02, 'confidence': 0.978},\n",
       "    {'text': 'answer', 'start': 294.02, 'end': 294.46, 'confidence': 0.997},\n",
       "    {'text': 'using', 'start': 294.46, 'end': 294.82, 'confidence': 0.88},\n",
       "    {'text': 'an', 'start': 294.82, 'end': 294.98, 'confidence': 0.958},\n",
       "    {'text': 'expert', 'start': 294.98, 'end': 295.18, 'confidence': 0.996},\n",
       "    {'text': 'system.', 'start': 295.18, 'end': 295.54, 'confidence': 0.997},\n",
       "    {'text': 'So', 'start': 295.86, 'end': 296.02, 'confidence': 0.689},\n",
       "    {'text': 'these', 'start': 296.02, 'end': 296.16, 'confidence': 0.873},\n",
       "    {'text': 'can', 'start': 296.16, 'end': 296.3, 'confidence': 0.988},\n",
       "    {'text': 'be', 'start': 296.3, 'end': 296.42, 'confidence': 0.998},\n",
       "    {'text': 'really', 'start': 296.42, 'end': 296.6, 'confidence': 0.995},\n",
       "    {'text': 'helpful', 'start': 296.6, 'end': 296.88, 'confidence': 0.998},\n",
       "    {'text': 'and', 'start': 296.88, 'end': 297.06, 'confidence': 0.827},\n",
       "    {'text': 'there', 'start': 297.06, 'end': 297.18, 'confidence': 0.995},\n",
       "    {'text': 'are', 'start': 297.18, 'end': 297.36, 'confidence': 0.997},\n",
       "    {'text': 'some', 'start': 297.36, 'end': 297.64, 'confidence': 0.997},\n",
       "    {'text': 'simple', 'start': 297.64, 'end': 298.2, 'confidence': 0.985},\n",
       "    {'text': 'ways,', 'start': 298.2, 'end': 298.74, 'confidence': 0.994},\n",
       "    {'text': 'or', 'start': 298.92, 'end': 298.96, 'confidence': 0.556},\n",
       "    {'text': 'rather,', 'start': 298.96, 'end': 299.14, 'confidence': 0.781},\n",
       "    {'text': 'there', 'start': 299.28, 'end': 299.46, 'confidence': 0.984},\n",
       "    {'text': 'are', 'start': 299.46, 'end': 299.64, 'confidence': 0.998},\n",
       "    {'text': 'some', 'start': 299.64, 'end': 299.86, 'confidence': 0.997},\n",
       "    {'text': 'problems', 'start': 299.86, 'end': 300.22, 'confidence': 0.823},\n",
       "    {'text': 'that', 'start': 300.22, 'end': 300.24, 'confidence': 0.341},\n",
       "    {'text': 'we', 'start': 300.24, 'end': 300.26, 'confidence': 0.305},\n",
       "    {'text': 'can', 'start': 300.26, 'end': 300.28, 'confidence': 0.432},\n",
       "    {'text': 'do', 'start': 300.28, 'end': 300.3, 'confidence': 0.122},\n",
       "    {'text': 'to', 'start': 300.3, 'end': 300.32, 'confidence': 0.253},\n",
       "    {'text': 'solve', 'start': 300.32, 'end': 300.34, 'confidence': 0.112},\n",
       "    {'text': 'these', 'start': 300.34, 'end': 300.36, 'confidence': 0.22},\n",
       "    {'text': 'problems.',\n",
       "     'start': 300.36,\n",
       "     'end': 300.38,\n",
       "     'confidence': 0.301}]}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway. So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time. All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI. Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI. So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far. Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand. So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do. As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate summary and sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "class LlamaCPP():\n",
    "  def __init__(self, model_dir: str, **kwargs):\n",
    "    print(f\"Loading model: {model_dir}...\")\n",
    "    self.model_dir = model_dir\n",
    "    self.llm = Llama(\n",
    "      model_path=self.model_dir,\n",
    "      n_gpu_layers=-1,\n",
    "      seed=1234,\n",
    "      n_ctx=4096,\n",
    "    )\n",
    "\n",
    "    defaults = {\n",
    "      \"temperature\": 1.0,\n",
    "      \"repeat_penalty\": 1.025,\n",
    "      \"min_p\": 0.5,\n",
    "      \"top_p\": 1.0,\n",
    "      \"top_k\": 0,\n",
    "      \"max_tokens\": 4096,\n",
    "    }\n",
    "    defaults.update(kwargs)\n",
    "    self.args = defaults\n",
    "\n",
    "      \n",
    "  def generate(self, prompt: str, **kwargs):\n",
    "    llm_args = self.args\n",
    "    llm_args.update(kwargs)\n",
    "    print(\"Prompt: \", prompt)\n",
    "    print(\"Args: \", llm_args)\n",
    "    output = self.llm(\n",
    "      prompt,\n",
    "      echo=False,\n",
    "      **llm_args\n",
    "    )\n",
    "    print(f\"output: {output}\")\n",
    "    response = output[\"choices\"][0][\"text\"]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 291 tensors from ../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  22:                      quantize.imatrix.file str              = /models/Meta-Llama-3-8B-Instruct-GGUF...\n",
      "llama_model_loader: - kv  23:                   quantize.imatrix.dataset str              = /training_data/groups_merged.txt\n",
      "llama_model_loader: - kv  24:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  25:              quantize.imatrix.chunks_count i32              = 88\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: ../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3070, compute capability 8.6, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   281.81 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  4403.49 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   296.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    16.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Meta-Llama-3-8B-Instruct', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.context_length': '8192', 'tokenizer.ggml.eos_token_id': '128001', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '500000.000000', 'quantize.imatrix.entries_count': '224', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'quantize.imatrix.chunks_count': '88', 'quantize.imatrix.file': '/models/Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct.imatrix', 'quantize.imatrix.dataset': '/training_data/groups_merged.txt'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCPP(model_dir=f\"../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"<|start_header_id|>user<|end_header_id|>\n",
    "   \n",
    "<instruction>Summarise the following transcript: <transcript>{text}</transcript></instruction><|eot_id|> \n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "<summary>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript> the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway. So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time. All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI. Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI. So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far. Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand. So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do. As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     953.83 ms /   138 runs   (    6.91 ms per token,   144.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1088.99 ms /  1045 tokens (    1.04 ms per token,   959.61 tokens per second)\n",
      "llama_print_timings:        eval time =    3849.43 ms /   137 runs   (   28.10 ms per token,    35.59 tokens per second)\n",
      "llama_print_timings:       total time =    6055.55 ms /  1182 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-41bd90db-1755-4b29-96ff-ead0c397318b', 'object': 'text_completion', 'created': 1720274340, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' The main takeaway from the workshop is that artificial intelligence (AI) can solve many problems, but choosing the right problem, finding the right data, and training the right model can be difficult. The speaker emphasizes that most AI today is narrow AI, which means it can only perform a specific task, such as self-driving cars or language processing. Narrow AI is not general AI, which would allow machines to learn any task that humans can perform. The speaker also discusses the basics of AI, including machine learning, deep learning, and expert systems. They highlight the challenges of defining rules for complex problems, such as identifying a table, and suggest that there are many different ways to implement AI.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 1045, 'completion_tokens': 137, 'total_tokens': 1182}}\n"
     ]
    }
   ],
   "source": [
    "summary = llm.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main takeaway from the workshop is that artificial intelligence (AI) can solve many problems, but choosing the right problem, finding the right data, and training the right model can be difficult. The speaker emphasizes that most AI today is narrow AI, which means it can only perform a specific task, such as self-driving cars or language processing. Narrow AI is not general AI, which would allow machines to learn any task that humans can perform. The speaker also discusses the basics of AI, including machine learning, deep learning, and expert systems. They highlight the challenges of defining rules for complex problems, such as identifying a table, and suggest that there are many different ways to implement AI.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"<|start_header_id|>user<|end_header_id|>\n",
    "   \n",
    "<instruction>Split the following transcript into suitable sections verbatim with this: <section></section>\"\"\n",
    "Text: <transcript>{text}</transcript></instruction><|eot_id|> \n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "<section>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Split the following transcript into suitable sections verbatim with this: <section></section>\"\"\n",
      "Text: <transcript> the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway. So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time. All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI. Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI. So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far. Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand. So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do. As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<section>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =    7092.34 ms /  1042 runs   (    6.81 ms per token,   146.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     913.15 ms /  1049 tokens (    0.87 ms per token,  1148.76 tokens per second)\n",
      "llama_print_timings:        eval time =   26748.73 ms /  1041 runs   (   25.70 ms per token,    38.92 tokens per second)\n",
      "llama_print_timings:       total time =   36560.32 ms /  2090 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-005b32ef-cab9-4da1-b97b-f901cab4775a', 'object': 'text_completion', 'created': 1720274346, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': \"the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway.</section>\\n\\n<section>So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.</section>\\n\\n<section>All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI.</section>\\n\\n<section>Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI.</section>\\n\\n<section>So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far?</section>\\n\\n<section>Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand.</section>\\n\\n<section>So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do.</section>\\n\\n<section>As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.</section>\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 1057, 'completion_tokens': 1041, 'total_tokens': 2098}}\n"
     ]
    }
   ],
   "source": [
    "sections_str = llm.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway.</section>\n",
      "\n",
      "<section>So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.</section>\n",
      "\n",
      "<section>All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI.</section>\n",
      "\n",
      "<section>Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI.</section>\n",
      "\n",
      "<section>So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far?</section>\n",
      "\n",
      "<section>Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand.</section>\n",
      "\n",
      "<section>So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do.</section>\n",
      "\n",
      "<section>As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.</section>\n"
     ]
    }
   ],
   "source": [
    "print(sections_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = sections_str.split(\"</section>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [section.replace(\"<section>\", \"\") for section in sections]\n",
    "sections = [section.replace(\"\\n\", \"\") for section in sections]\n",
    "sections = [section for section in sections if not section.isspace() and not section == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway.\", \"So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.\", \"All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI.\", \"Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI.\", \"So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far?\", \"Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand.\", \"So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do.\", \"As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.\"]\n"
     ]
    }
   ],
   "source": [
    "print(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'segments', 'language'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'seek': 0,\n",
       "  'start': 0.0,\n",
       "  'end': 13.14,\n",
       "  'text': ' the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult.',\n",
       "  'tokens': [50364,\n",
       "   264,\n",
       "   2135,\n",
       "   30681,\n",
       "   11,\n",
       "   597,\n",
       "   307,\n",
       "   365,\n",
       "   264,\n",
       "   558,\n",
       "   1412,\n",
       "   293,\n",
       "   264,\n",
       "   558,\n",
       "   2316,\n",
       "   11,\n",
       "   11677,\n",
       "   7599,\n",
       "   393,\n",
       "   5039,\n",
       "   867,\n",
       "   2740,\n",
       "   11,\n",
       "   457,\n",
       "   10875,\n",
       "   264,\n",
       "   558,\n",
       "   1154,\n",
       "   11,\n",
       "   5006,\n",
       "   264,\n",
       "   558,\n",
       "   1412,\n",
       "   293,\n",
       "   3097,\n",
       "   264,\n",
       "   558,\n",
       "   2316,\n",
       "   393,\n",
       "   312,\n",
       "   2252,\n",
       "   13,\n",
       "   51064],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.11746751240321568,\n",
       "  'compression_ratio': 1.6772486772486772,\n",
       "  'no_speech_prob': 0.027983587235212326,\n",
       "  'confidence': 0.871,\n",
       "  'words': [{'text': 'the', 'start': 0.0, 'end': 0.06, 'confidence': 0.097},\n",
       "   {'text': 'main', 'start': 0.06, 'end': 0.32, 'confidence': 0.9},\n",
       "   {'text': 'takeaway,', 'start': 0.32, 'end': 0.78, 'confidence': 0.972},\n",
       "   {'text': 'which', 'start': 1.3, 'end': 1.38, 'confidence': 0.965},\n",
       "   {'text': 'is', 'start': 1.38, 'end': 1.82, 'confidence': 0.996},\n",
       "   {'text': 'with', 'start': 1.82, 'end': 2.16, 'confidence': 0.712},\n",
       "   {'text': 'the', 'start': 2.16, 'end': 2.34, 'confidence': 0.969},\n",
       "   {'text': 'right', 'start': 2.34, 'end': 2.52, 'confidence': 0.995},\n",
       "   {'text': 'data', 'start': 2.52, 'end': 2.88, 'confidence': 0.991},\n",
       "   {'text': 'and', 'start': 2.88, 'end': 3.18, 'confidence': 0.716},\n",
       "   {'text': 'the', 'start': 3.18, 'end': 3.28, 'confidence': 0.986},\n",
       "   {'text': 'right', 'start': 3.28, 'end': 3.42, 'confidence': 0.982},\n",
       "   {'text': 'model,', 'start': 3.42, 'end': 3.9, 'confidence': 0.93},\n",
       "   {'text': 'artificial', 'start': 4.02, 'end': 4.58, 'confidence': 0.723},\n",
       "   {'text': 'intelligence', 'start': 4.58, 'end': 5.06, 'confidence': 0.961},\n",
       "   {'text': 'can', 'start': 5.06, 'end': 5.28, 'confidence': 0.533},\n",
       "   {'text': 'solve', 'start': 5.28, 'end': 5.56, 'confidence': 0.991},\n",
       "   {'text': 'many', 'start': 5.56, 'end': 5.78, 'confidence': 0.968},\n",
       "   {'text': 'problems,', 'start': 5.78, 'end': 6.38, 'confidence': 0.987},\n",
       "   {'text': 'but', 'start': 6.76, 'end': 7.56, 'confidence': 0.897},\n",
       "   {'text': 'choosing', 'start': 7.56, 'end': 8.38, 'confidence': 0.971},\n",
       "   {'text': 'the', 'start': 8.38, 'end': 8.52, 'confidence': 0.99},\n",
       "   {'text': 'right', 'start': 8.52, 'end': 8.68, 'confidence': 0.991},\n",
       "   {'text': 'problem,', 'start': 8.68, 'end': 9.34, 'confidence': 0.975},\n",
       "   {'text': 'finding', 'start': 10.0, 'end': 10.1, 'confidence': 0.916},\n",
       "   {'text': 'the', 'start': 10.1, 'end': 10.28, 'confidence': 0.996},\n",
       "   {'text': 'right', 'start': 10.28, 'end': 10.46, 'confidence': 0.997},\n",
       "   {'text': 'data', 'start': 10.46, 'end': 10.78, 'confidence': 0.995},\n",
       "   {'text': 'and', 'start': 10.78, 'end': 11.04, 'confidence': 0.922},\n",
       "   {'text': 'training', 'start': 11.04, 'end': 11.28, 'confidence': 0.963},\n",
       "   {'text': 'the', 'start': 11.28, 'end': 11.44, 'confidence': 0.974},\n",
       "   {'text': 'right', 'start': 11.44, 'end': 11.6, 'confidence': 0.996},\n",
       "   {'text': 'model', 'start': 11.6, 'end': 11.98, 'confidence': 0.994},\n",
       "   {'text': 'can', 'start': 11.98, 'end': 12.4, 'confidence': 0.847},\n",
       "   {'text': 'be', 'start': 12.4, 'end': 12.76, 'confidence': 0.996},\n",
       "   {'text': 'difficult.', 'start': 12.76, 'end': 13.14, 'confidence': 0.99}]},\n",
       " {'id': 1,\n",
       "  'seek': 0,\n",
       "  'start': 13.5,\n",
       "  'end': 16.04,\n",
       "  'text': \" So, there's nothing else that you remember from today's workshop.\",\n",
       "  'tokens': [51064,\n",
       "   407,\n",
       "   11,\n",
       "   456,\n",
       "   311,\n",
       "   1825,\n",
       "   1646,\n",
       "   300,\n",
       "   291,\n",
       "   1604,\n",
       "   490,\n",
       "   965,\n",
       "   311,\n",
       "   13541,\n",
       "   13,\n",
       "   51214],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.11746751240321568,\n",
       "  'compression_ratio': 1.6772486772486772,\n",
       "  'no_speech_prob': 0.027983587235212326,\n",
       "  'confidence': 0.993,\n",
       "  'words': [{'text': 'So,', 'start': 13.5, 'end': 13.9, 'confidence': 0.985},\n",
       "   {'text': \"there's\", 'start': 14.16, 'end': 14.34, 'confidence': 0.993},\n",
       "   {'text': 'nothing', 'start': 14.34, 'end': 14.56, 'confidence': 1.0},\n",
       "   {'text': 'else', 'start': 14.56, 'end': 14.76, 'confidence': 0.999},\n",
       "   {'text': 'that', 'start': 14.76, 'end': 14.88, 'confidence': 0.961},\n",
       "   {'text': 'you', 'start': 14.88, 'end': 14.98, 'confidence': 0.999},\n",
       "   {'text': 'remember', 'start': 14.98, 'end': 15.18, 'confidence': 0.991},\n",
       "   {'text': 'from', 'start': 15.18, 'end': 15.36, 'confidence': 0.999},\n",
       "   {'text': \"today's\", 'start': 15.36, 'end': 15.68, 'confidence': 0.999},\n",
       "   {'text': 'workshop.', 'start': 15.68, 'end': 16.04, 'confidence': 0.998}]},\n",
       " {'id': 2,\n",
       "  'seek': 0,\n",
       "  'start': 16.5,\n",
       "  'end': 18.42,\n",
       "  'text': ' This slide is the key takeaway.',\n",
       "  'tokens': [51214, 639, 4137, 307, 264, 2141, 30681, 13, 51414],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.11746751240321568,\n",
       "  'compression_ratio': 1.6772486772486772,\n",
       "  'no_speech_prob': 0.027983587235212326,\n",
       "  'confidence': 0.994,\n",
       "  'words': [{'text': 'This', 'start': 16.5, 'end': 17.24, 'confidence': 0.977},\n",
       "   {'text': 'slide', 'start': 17.24, 'end': 17.52, 'confidence': 0.999},\n",
       "   {'text': 'is', 'start': 17.52, 'end': 17.7, 'confidence': 0.999},\n",
       "   {'text': 'the', 'start': 17.7, 'end': 17.82, 'confidence': 0.999},\n",
       "   {'text': 'key', 'start': 17.82, 'end': 18.02, 'confidence': 0.998},\n",
       "   {'text': 'takeaway.', 'start': 18.02, 'end': 18.42, 'confidence': 0.993}]},\n",
       " {'id': 3,\n",
       "  'seek': 2100,\n",
       "  'start': 21.0,\n",
       "  'end': 30.18,\n",
       "  'text': \" So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning.\",\n",
       "  'tokens': [50364,\n",
       "   407,\n",
       "   11,\n",
       "   411,\n",
       "   286,\n",
       "   848,\n",
       "   11,\n",
       "   321,\n",
       "   603,\n",
       "   2060,\n",
       "   11677,\n",
       "   7599,\n",
       "   11,\n",
       "   321,\n",
       "   486,\n",
       "   536,\n",
       "   257,\n",
       "   1326,\n",
       "   819,\n",
       "   5110,\n",
       "   295,\n",
       "   3873,\n",
       "   300,\n",
       "   393,\n",
       "   312,\n",
       "   1143,\n",
       "   281,\n",
       "   4445,\n",
       "   11677,\n",
       "   7599,\n",
       "   3009,\n",
       "   746,\n",
       "   1219,\n",
       "   3479,\n",
       "   2539,\n",
       "   13,\n",
       "   50864],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.0935305186680385,\n",
       "  'compression_ratio': 1.9715447154471544,\n",
       "  'no_speech_prob': 0.4981095492839813,\n",
       "  'confidence': 0.925,\n",
       "  'words': [{'text': 'So,', 'start': 21.0, 'end': 21.02, 'confidence': 0.381},\n",
       "   {'text': 'like', 'start': 21.02, 'end': 21.06, 'confidence': 0.537},\n",
       "   {'text': 'I', 'start': 21.06, 'end': 21.18, 'confidence': 0.994},\n",
       "   {'text': 'said,', 'start': 21.18, 'end': 21.56, 'confidence': 0.999},\n",
       "   {'text': \"we'll\", 'start': 21.8, 'end': 21.92, 'confidence': 0.969},\n",
       "   {'text': 'cover', 'start': 21.92, 'end': 22.1, 'confidence': 0.995},\n",
       "   {'text': 'artificial', 'start': 22.1, 'end': 22.54, 'confidence': 0.943},\n",
       "   {'text': 'intelligence,', 'start': 22.54, 'end': 23.1, 'confidence': 0.999},\n",
       "   {'text': 'we', 'start': 23.5, 'end': 23.52, 'confidence': 0.995},\n",
       "   {'text': 'will', 'start': 23.52, 'end': 23.88, 'confidence': 0.998},\n",
       "   {'text': 'see', 'start': 23.88, 'end': 24.6, 'confidence': 0.999},\n",
       "   {'text': 'a', 'start': 24.6, 'end': 24.76, 'confidence': 0.987},\n",
       "   {'text': 'few', 'start': 24.76, 'end': 24.82, 'confidence': 1.0},\n",
       "   {'text': 'different', 'start': 24.82, 'end': 25.1, 'confidence': 0.999},\n",
       "   {'text': 'examples', 'start': 25.1, 'end': 25.54, 'confidence': 0.998},\n",
       "   {'text': 'of', 'start': 25.54, 'end': 25.78, 'confidence': 0.999},\n",
       "   {'text': 'tools', 'start': 25.78, 'end': 26.24, 'confidence': 0.999},\n",
       "   {'text': 'that', 'start': 26.24, 'end': 26.52, 'confidence': 0.996},\n",
       "   {'text': 'can', 'start': 26.52, 'end': 26.7, 'confidence': 1.0},\n",
       "   {'text': 'be', 'start': 26.7, 'end': 26.84, 'confidence': 1.0},\n",
       "   {'text': 'used', 'start': 26.84, 'end': 27.02, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 27.02, 'end': 27.22, 'confidence': 0.982},\n",
       "   {'text': 'implement', 'start': 27.22, 'end': 27.5, 'confidence': 0.996},\n",
       "   {'text': 'artificial', 'start': 27.5, 'end': 28.04, 'confidence': 0.964},\n",
       "   {'text': 'intelligence', 'start': 28.04, 'end': 28.56, 'confidence': 0.999},\n",
       "   {'text': 'including', 'start': 28.56, 'end': 28.98, 'confidence': 0.579},\n",
       "   {'text': 'something', 'start': 28.98, 'end': 29.26, 'confidence': 0.999},\n",
       "   {'text': 'called', 'start': 29.26, 'end': 29.52, 'confidence': 0.999},\n",
       "   {'text': 'machine', 'start': 29.52, 'end': 29.76, 'confidence': 0.963},\n",
       "   {'text': 'learning.', 'start': 29.76, 'end': 30.18, 'confidence': 0.996}]},\n",
       " {'id': 4,\n",
       "  'seek': 2100,\n",
       "  'start': 30.58,\n",
       "  'end': 42.57,\n",
       "  'text': \" We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a\",\n",
       "  'tokens': [50864,\n",
       "   492,\n",
       "   603,\n",
       "   751,\n",
       "   466,\n",
       "   819,\n",
       "   3685,\n",
       "   295,\n",
       "   3479,\n",
       "   2539,\n",
       "   293,\n",
       "   819,\n",
       "   2740,\n",
       "   300,\n",
       "   393,\n",
       "   312,\n",
       "   13041,\n",
       "   538,\n",
       "   3479,\n",
       "   2539,\n",
       "   13,\n",
       "   400,\n",
       "   718,\n",
       "   385,\n",
       "   445,\n",
       "   584,\n",
       "   1670,\n",
       "   1391,\n",
       "   257,\n",
       "   688,\n",
       "   295,\n",
       "   291,\n",
       "   366,\n",
       "   1217,\n",
       "   6359,\n",
       "   11,\n",
       "   437,\n",
       "   307,\n",
       "   2452,\n",
       "   2539,\n",
       "   2452,\n",
       "   2539,\n",
       "   307,\n",
       "   2139,\n",
       "   257,\n",
       "   25993,\n",
       "   420,\n",
       "   257,\n",
       "   25993,\n",
       "   295,\n",
       "   257,\n",
       "   51464],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.0935305186680385,\n",
       "  'compression_ratio': 1.9715447154471544,\n",
       "  'no_speech_prob': 0.4981095492839813,\n",
       "  'confidence': 0.931,\n",
       "  'words': [{'text': \"We'll\",\n",
       "    'start': 30.58,\n",
       "    'end': 30.84,\n",
       "    'confidence': 0.898},\n",
       "   {'text': 'talk', 'start': 30.84, 'end': 30.96, 'confidence': 0.999},\n",
       "   {'text': 'about', 'start': 30.96, 'end': 31.22, 'confidence': 1.0},\n",
       "   {'text': 'different', 'start': 31.22, 'end': 31.54, 'confidence': 0.999},\n",
       "   {'text': 'kinds', 'start': 31.54, 'end': 31.88, 'confidence': 0.999},\n",
       "   {'text': 'of', 'start': 31.88, 'end': 32.04, 'confidence': 1.0},\n",
       "   {'text': 'machine', 'start': 32.04, 'end': 32.24, 'confidence': 0.991},\n",
       "   {'text': 'learning', 'start': 32.24, 'end': 32.52, 'confidence': 0.999},\n",
       "   {'text': 'and', 'start': 32.52, 'end': 32.68, 'confidence': 0.94},\n",
       "   {'text': 'different', 'start': 32.68, 'end': 32.88, 'confidence': 0.997},\n",
       "   {'text': 'problems', 'start': 32.88, 'end': 33.24, 'confidence': 0.999},\n",
       "   {'text': 'that', 'start': 33.24, 'end': 33.42, 'confidence': 0.999},\n",
       "   {'text': 'can', 'start': 33.42, 'end': 33.56, 'confidence': 1.0},\n",
       "   {'text': 'be', 'start': 33.56, 'end': 33.68, 'confidence': 1.0},\n",
       "   {'text': 'solved', 'start': 33.68, 'end': 34.2, 'confidence': 0.999},\n",
       "   {'text': 'by', 'start': 34.2, 'end': 34.58, 'confidence': 0.991},\n",
       "   {'text': 'machine', 'start': 34.58, 'end': 34.84, 'confidence': 0.995},\n",
       "   {'text': 'learning.', 'start': 34.84, 'end': 35.2, 'confidence': 0.999},\n",
       "   {'text': 'And', 'start': 35.44, 'end': 35.92, 'confidence': 0.966},\n",
       "   {'text': 'let', 'start': 35.92, 'end': 36.14, 'confidence': 0.952},\n",
       "   {'text': 'me', 'start': 36.14, 'end': 36.28, 'confidence': 1.0},\n",
       "   {'text': 'just', 'start': 36.28, 'end': 36.48, 'confidence': 1.0},\n",
       "   {'text': 'say', 'start': 36.48, 'end': 36.66, 'confidence': 0.999},\n",
       "   {'text': 'since', 'start': 36.66, 'end': 36.86, 'confidence': 0.94},\n",
       "   {'text': 'probably', 'start': 36.86, 'end': 37.2, 'confidence': 0.998},\n",
       "   {'text': 'a', 'start': 37.2, 'end': 37.32, 'confidence': 0.999},\n",
       "   {'text': 'lot', 'start': 37.32, 'end': 37.42, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 37.42, 'end': 37.5, 'confidence': 1.0},\n",
       "   {'text': 'you', 'start': 37.5, 'end': 37.66, 'confidence': 0.999},\n",
       "   {'text': 'are', 'start': 37.66, 'end': 37.86, 'confidence': 0.997},\n",
       "   {'text': 'already', 'start': 37.86, 'end': 38.12, 'confidence': 0.999},\n",
       "   {'text': 'wondering,', 'start': 38.12, 'end': 38.5, 'confidence': 0.999},\n",
       "   {'text': 'what', 'start': 38.84, 'end': 38.9, 'confidence': 0.916},\n",
       "   {'text': 'is', 'start': 38.9, 'end': 39.04, 'confidence': 0.765},\n",
       "   {'text': 'deep', 'start': 39.04, 'end': 39.18, 'confidence': 0.965},\n",
       "   {'text': 'learning', 'start': 39.18, 'end': 39.54, 'confidence': 0.995},\n",
       "   {'text': 'deep', 'start': 39.54, 'end': 39.94, 'confidence': 0.533},\n",
       "   {'text': 'learning', 'start': 39.94, 'end': 40.22, 'confidence': 0.989},\n",
       "   {'text': 'is', 'start': 40.22, 'end': 40.52, 'confidence': 0.971},\n",
       "   {'text': 'either', 'start': 40.52, 'end': 40.78, 'confidence': 0.969},\n",
       "   {'text': 'a', 'start': 40.78, 'end': 41.08, 'confidence': 0.888},\n",
       "   {'text': 'subset', 'start': 41.08, 'end': 41.44, 'confidence': 0.98},\n",
       "   {'text': 'or', 'start': 41.44, 'end': 41.8, 'confidence': 0.665},\n",
       "   {'text': 'a', 'start': 41.8, 'end': 42.0, 'confidence': 0.851},\n",
       "   {'text': 'subset', 'start': 42.0, 'end': 42.34, 'confidence': 0.726},\n",
       "   {'text': 'of', 'start': 42.34, 'end': 42.52, 'confidence': 0.629},\n",
       "   {'text': 'a', 'start': 42.52, 'end': 42.57, 'confidence': 0.683}]},\n",
       " {'id': 5,\n",
       "  'seek': 2100,\n",
       "  'start': 42.57,\n",
       "  'end': 44.4,\n",
       "  'text': ' subset of machine learning.',\n",
       "  'tokens': [51464, 25993, 295, 3479, 2539, 13, 51564],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.0935305186680385,\n",
       "  'compression_ratio': 1.9715447154471544,\n",
       "  'no_speech_prob': 0.4981095492839813,\n",
       "  'confidence': 0.871,\n",
       "  'words': [{'text': 'subset',\n",
       "    'start': 42.57,\n",
       "    'end': 43.02,\n",
       "    'confidence': 0.586},\n",
       "   {'text': 'of', 'start': 43.02, 'end': 43.74, 'confidence': 0.994},\n",
       "   {'text': 'machine', 'start': 43.74, 'end': 44.02, 'confidence': 0.99},\n",
       "   {'text': 'learning.', 'start': 44.02, 'end': 44.4, 'confidence': 0.995}]},\n",
       " {'id': 6,\n",
       "  'seek': 4500,\n",
       "  'start': 45.0,\n",
       "  'end': 57.54,\n",
       "  'text': \" So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals\",\n",
       "  'tokens': [50364,\n",
       "   407,\n",
       "   337,\n",
       "   729,\n",
       "   295,\n",
       "   291,\n",
       "   567,\n",
       "   366,\n",
       "   4963,\n",
       "   365,\n",
       "   18161,\n",
       "   9590,\n",
       "   420,\n",
       "   2452,\n",
       "   2539,\n",
       "   300,\n",
       "   307,\n",
       "   257,\n",
       "   2290,\n",
       "   300,\n",
       "   1062,\n",
       "   312,\n",
       "   1143,\n",
       "   294,\n",
       "   3479,\n",
       "   2539,\n",
       "   2740,\n",
       "   11,\n",
       "   321,\n",
       "   1582,\n",
       "   380,\n",
       "   751,\n",
       "   466,\n",
       "   300,\n",
       "   294,\n",
       "   604,\n",
       "   7161,\n",
       "   412,\n",
       "   439,\n",
       "   965,\n",
       "   457,\n",
       "   286,\n",
       "   1454,\n",
       "   300,\n",
       "   538,\n",
       "   264,\n",
       "   917,\n",
       "   295,\n",
       "   264,\n",
       "   13541,\n",
       "   11,\n",
       "   291,\n",
       "   1074,\n",
       "   486,\n",
       "   362,\n",
       "   264,\n",
       "   29505,\n",
       "   51014],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.08318398215553978,\n",
       "  'compression_ratio': 1.6496062992125984,\n",
       "  'no_speech_prob': 0.19128207862377167,\n",
       "  'confidence': 0.946,\n",
       "  'words': [{'text': 'So', 'start': 45.0, 'end': 45.16, 'confidence': 0.904},\n",
       "   {'text': 'for', 'start': 45.16, 'end': 45.4, 'confidence': 0.808},\n",
       "   {'text': 'those', 'start': 45.4, 'end': 45.56, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 45.56, 'end': 45.68, 'confidence': 0.999},\n",
       "   {'text': 'you', 'start': 45.68, 'end': 45.8, 'confidence': 0.998},\n",
       "   {'text': 'who', 'start': 45.8, 'end': 46.44, 'confidence': 0.856},\n",
       "   {'text': 'are', 'start': 46.44, 'end': 46.62, 'confidence': 0.998},\n",
       "   {'text': 'familiar', 'start': 46.62, 'end': 46.88, 'confidence': 0.871},\n",
       "   {'text': 'with', 'start': 46.88, 'end': 47.1, 'confidence': 0.999},\n",
       "   {'text': 'neural', 'start': 47.1, 'end': 47.32, 'confidence': 0.968},\n",
       "   {'text': 'networks', 'start': 47.32, 'end': 47.68, 'confidence': 0.999},\n",
       "   {'text': 'or', 'start': 47.68, 'end': 47.84, 'confidence': 0.885},\n",
       "   {'text': 'deep', 'start': 47.84, 'end': 47.98, 'confidence': 0.994},\n",
       "   {'text': 'learning', 'start': 47.98, 'end': 48.2, 'confidence': 0.999},\n",
       "   {'text': 'that', 'start': 48.2, 'end': 48.46, 'confidence': 0.836},\n",
       "   {'text': 'is', 'start': 48.46, 'end': 49.2, 'confidence': 0.999},\n",
       "   {'text': 'a', 'start': 49.2, 'end': 49.84, 'confidence': 0.994},\n",
       "   {'text': 'tool', 'start': 49.84, 'end': 50.14, 'confidence': 0.999},\n",
       "   {'text': 'that', 'start': 50.14, 'end': 50.28, 'confidence': 1.0},\n",
       "   {'text': 'might', 'start': 50.28, 'end': 50.46, 'confidence': 0.999},\n",
       "   {'text': 'be', 'start': 50.46, 'end': 50.58, 'confidence': 1.0},\n",
       "   {'text': 'used', 'start': 50.58, 'end': 50.84, 'confidence': 0.999},\n",
       "   {'text': 'in', 'start': 50.84, 'end': 51.16, 'confidence': 0.999},\n",
       "   {'text': 'machine', 'start': 51.16, 'end': 51.4, 'confidence': 0.992},\n",
       "   {'text': 'learning', 'start': 51.4, 'end': 51.62, 'confidence': 1.0},\n",
       "   {'text': 'problems,', 'start': 51.62, 'end': 51.96, 'confidence': 0.996},\n",
       "   {'text': 'we', 'start': 52.28, 'end': 52.32, 'confidence': 0.997},\n",
       "   {'text': \"won't\", 'start': 52.32, 'end': 52.56, 'confidence': 0.959},\n",
       "   {'text': 'talk', 'start': 52.56, 'end': 52.8, 'confidence': 0.99},\n",
       "   {'text': 'about', 'start': 52.8, 'end': 53.04, 'confidence': 1.0},\n",
       "   {'text': 'that', 'start': 53.04, 'end': 53.28, 'confidence': 0.999},\n",
       "   {'text': 'in', 'start': 53.28, 'end': 53.44, 'confidence': 0.955},\n",
       "   {'text': 'any', 'start': 53.44, 'end': 53.6, 'confidence': 0.997},\n",
       "   {'text': 'depth', 'start': 53.6, 'end': 53.78, 'confidence': 0.999},\n",
       "   {'text': 'at', 'start': 53.78, 'end': 53.94, 'confidence': 0.945},\n",
       "   {'text': 'all', 'start': 53.94, 'end': 54.1, 'confidence': 1.0},\n",
       "   {'text': 'today', 'start': 54.1, 'end': 54.4, 'confidence': 0.994},\n",
       "   {'text': 'but', 'start': 54.4, 'end': 54.6, 'confidence': 0.84},\n",
       "   {'text': 'I', 'start': 54.6, 'end': 54.74, 'confidence': 0.989},\n",
       "   {'text': 'hope', 'start': 54.74, 'end': 54.94, 'confidence': 1.0},\n",
       "   {'text': 'that', 'start': 54.94, 'end': 55.06, 'confidence': 0.999},\n",
       "   {'text': 'by', 'start': 55.06, 'end': 55.16, 'confidence': 0.986},\n",
       "   {'text': 'the', 'start': 55.16, 'end': 55.26, 'confidence': 0.999},\n",
       "   {'text': 'end', 'start': 55.26, 'end': 55.36, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 55.36, 'end': 55.46, 'confidence': 0.999},\n",
       "   {'text': 'the', 'start': 55.46, 'end': 55.56, 'confidence': 0.998},\n",
       "   {'text': 'workshop,', 'start': 55.56, 'end': 55.96, 'confidence': 0.999},\n",
       "   {'text': 'you', 'start': 56.24, 'end': 56.36, 'confidence': 0.843},\n",
       "   {'text': 'guys', 'start': 56.36, 'end': 56.5, 'confidence': 0.941},\n",
       "   {'text': 'will', 'start': 56.5, 'end': 56.7, 'confidence': 0.913},\n",
       "   {'text': 'have', 'start': 56.7, 'end': 56.9, 'confidence': 0.844},\n",
       "   {'text': 'the', 'start': 56.9, 'end': 57.06, 'confidence': 0.559},\n",
       "   {'text': 'fundamentals',\n",
       "    'start': 57.06,\n",
       "    'end': 57.54,\n",
       "    'confidence': 0.597}]},\n",
       " {'id': 7,\n",
       "  'seek': 4500,\n",
       "  'start': 57.54,\n",
       "  'end': 65.28,\n",
       "  'text': ' necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.',\n",
       "  'tokens': [51014,\n",
       "   4818,\n",
       "   281,\n",
       "   2528,\n",
       "   666,\n",
       "   2452,\n",
       "   2539,\n",
       "   412,\n",
       "   257,\n",
       "   24106,\n",
       "   1496,\n",
       "   13,\n",
       "   759,\n",
       "   291,\n",
       "   528,\n",
       "   281,\n",
       "   360,\n",
       "   300,\n",
       "   13,\n",
       "   2188,\n",
       "   661,\n",
       "   565,\n",
       "   13,\n",
       "   51464],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.08318398215553978,\n",
       "  'compression_ratio': 1.6496062992125984,\n",
       "  'no_speech_prob': 0.19128207862377167,\n",
       "  'confidence': 0.943,\n",
       "  'words': [{'text': 'necessary',\n",
       "    'start': 57.54,\n",
       "    'end': 58.18,\n",
       "    'confidence': 0.937},\n",
       "   {'text': 'to', 'start': 58.18, 'end': 59.08, 'confidence': 0.998},\n",
       "   {'text': 'dig', 'start': 59.08, 'end': 59.42, 'confidence': 0.998},\n",
       "   {'text': 'into', 'start': 59.42, 'end': 59.62, 'confidence': 0.991},\n",
       "   {'text': 'deep', 'start': 59.62, 'end': 59.84, 'confidence': 0.996},\n",
       "   {'text': 'learning', 'start': 59.84, 'end': 60.26, 'confidence': 0.999},\n",
       "   {'text': 'at', 'start': 60.26, 'end': 60.78, 'confidence': 0.894},\n",
       "   {'text': 'a', 'start': 60.78, 'end': 60.94, 'confidence': 0.998},\n",
       "   {'text': 'conceptual', 'start': 60.94, 'end': 61.34, 'confidence': 0.999},\n",
       "   {'text': 'level.', 'start': 61.34, 'end': 61.84, 'confidence': 0.999},\n",
       "   {'text': 'If', 'start': 61.98, 'end': 62.48, 'confidence': 0.774},\n",
       "   {'text': 'you', 'start': 62.48, 'end': 62.6, 'confidence': 1.0},\n",
       "   {'text': 'want', 'start': 62.6, 'end': 62.7, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 62.7, 'end': 62.78, 'confidence': 1.0},\n",
       "   {'text': 'do', 'start': 62.78, 'end': 62.92, 'confidence': 0.999},\n",
       "   {'text': 'that.', 'start': 62.92, 'end': 63.66, 'confidence': 0.998},\n",
       "   {'text': 'Some', 'start': 63.84, 'end': 63.86, 'confidence': 0.537},\n",
       "   {'text': 'other', 'start': 63.86, 'end': 64.02, 'confidence': 0.985},\n",
       "   {'text': 'time.', 'start': 64.02, 'end': 65.28, 'confidence': 0.975}]},\n",
       " {'id': 8,\n",
       "  'seek': 4500,\n",
       "  'start': 66.5,\n",
       "  'end': 69.64,\n",
       "  'text': \" All that being said, let's get into basics of AI.\",\n",
       "  'tokens': [51464,\n",
       "   1057,\n",
       "   300,\n",
       "   885,\n",
       "   848,\n",
       "   11,\n",
       "   718,\n",
       "   311,\n",
       "   483,\n",
       "   666,\n",
       "   14688,\n",
       "   295,\n",
       "   7318,\n",
       "   13,\n",
       "   51664],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.08318398215553978,\n",
       "  'compression_ratio': 1.6496062992125984,\n",
       "  'no_speech_prob': 0.19128207862377167,\n",
       "  'confidence': 0.918,\n",
       "  'words': [{'text': 'All', 'start': 66.5, 'end': 66.7, 'confidence': 0.55},\n",
       "   {'text': 'that', 'start': 66.7, 'end': 66.84, 'confidence': 0.814},\n",
       "   {'text': 'being', 'start': 66.84, 'end': 67.04, 'confidence': 0.998},\n",
       "   {'text': 'said,', 'start': 67.04, 'end': 67.42, 'confidence': 1.0},\n",
       "   {'text': \"let's\", 'start': 67.76, 'end': 67.98, 'confidence': 0.99},\n",
       "   {'text': 'get', 'start': 67.98, 'end': 68.16, 'confidence': 0.999},\n",
       "   {'text': 'into', 'start': 68.16, 'end': 68.32, 'confidence': 0.999},\n",
       "   {'text': 'basics', 'start': 68.32, 'end': 68.82, 'confidence': 0.963},\n",
       "   {'text': 'of', 'start': 68.82, 'end': 69.22, 'confidence': 0.971},\n",
       "   {'text': 'AI.', 'start': 69.22, 'end': 69.64, 'confidence': 0.961}]},\n",
       " {'id': 9,\n",
       "  'seek': 7100,\n",
       "  'start': 71.0,\n",
       "  'end': 73.66,\n",
       "  'text': ' So, AI can be general, or it can be narrow.',\n",
       "  'tokens': [50364,\n",
       "   407,\n",
       "   11,\n",
       "   7318,\n",
       "   393,\n",
       "   312,\n",
       "   2674,\n",
       "   11,\n",
       "   420,\n",
       "   309,\n",
       "   393,\n",
       "   312,\n",
       "   9432,\n",
       "   13,\n",
       "   50564],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.15347844583016854,\n",
       "  'compression_ratio': 1.7132075471698114,\n",
       "  'no_speech_prob': 0.6496715545654297,\n",
       "  'confidence': 0.708,\n",
       "  'words': [{'text': 'So,', 'start': 71.0, 'end': 71.02, 'confidence': 0.309},\n",
       "   {'text': 'AI', 'start': 71.02, 'end': 71.04, 'confidence': 0.186},\n",
       "   {'text': 'can', 'start': 71.04, 'end': 71.06, 'confidence': 0.752},\n",
       "   {'text': 'be', 'start': 71.06, 'end': 71.14, 'confidence': 0.982},\n",
       "   {'text': 'general,', 'start': 71.14, 'end': 71.68, 'confidence': 0.855},\n",
       "   {'text': 'or', 'start': 72.64, 'end': 72.84, 'confidence': 0.979},\n",
       "   {'text': 'it', 'start': 72.84, 'end': 73.14, 'confidence': 0.929},\n",
       "   {'text': 'can', 'start': 73.14, 'end': 73.28, 'confidence': 0.999},\n",
       "   {'text': 'be', 'start': 73.28, 'end': 73.38, 'confidence': 0.999},\n",
       "   {'text': 'narrow.', 'start': 73.38, 'end': 73.66, 'confidence': 0.962}]},\n",
       " {'id': 10,\n",
       "  'seek': 7100,\n",
       "  'start': 74.5,\n",
       "  'end': 83.08,\n",
       "  'text': \" When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots.\",\n",
       "  'tokens': [50564,\n",
       "   1133,\n",
       "   321,\n",
       "   751,\n",
       "   466,\n",
       "   2674,\n",
       "   11677,\n",
       "   7599,\n",
       "   11,\n",
       "   309,\n",
       "   311,\n",
       "   562,\n",
       "   257,\n",
       "   3479,\n",
       "   393,\n",
       "   1466,\n",
       "   604,\n",
       "   9608,\n",
       "   300,\n",
       "   257,\n",
       "   1952,\n",
       "   393,\n",
       "   2042,\n",
       "   13,\n",
       "   639,\n",
       "   775,\n",
       "   406,\n",
       "   2514,\n",
       "   456,\n",
       "   366,\n",
       "   572,\n",
       "   19835,\n",
       "   31927,\n",
       "   14733,\n",
       "   13,\n",
       "   51014],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.15347844583016854,\n",
       "  'compression_ratio': 1.7132075471698114,\n",
       "  'no_speech_prob': 0.6496715545654297,\n",
       "  'confidence': 0.914,\n",
       "  'words': [{'text': 'When', 'start': 74.5, 'end': 74.82, 'confidence': 0.949},\n",
       "   {'text': 'we', 'start': 74.82, 'end': 74.94, 'confidence': 0.999},\n",
       "   {'text': 'talk', 'start': 74.94, 'end': 75.08, 'confidence': 0.983},\n",
       "   {'text': 'about', 'start': 75.08, 'end': 75.34, 'confidence': 1.0},\n",
       "   {'text': 'general', 'start': 75.34, 'end': 75.74, 'confidence': 0.987},\n",
       "   {'text': 'artificial', 'start': 75.74, 'end': 76.16, 'confidence': 0.993},\n",
       "   {'text': 'intelligence,',\n",
       "    'start': 76.16,\n",
       "    'end': 76.72,\n",
       "    'confidence': 0.999},\n",
       "   {'text': \"it's\", 'start': 76.96, 'end': 77.06, 'confidence': 0.993},\n",
       "   {'text': 'when', 'start': 77.06, 'end': 77.18, 'confidence': 0.644},\n",
       "   {'text': 'a', 'start': 77.18, 'end': 77.36, 'confidence': 0.949},\n",
       "   {'text': 'machine', 'start': 77.36, 'end': 77.66, 'confidence': 1.0},\n",
       "   {'text': 'can', 'start': 77.66, 'end': 77.9, 'confidence': 0.999},\n",
       "   {'text': 'learn', 'start': 77.9, 'end': 78.12, 'confidence': 0.955},\n",
       "   {'text': 'any', 'start': 78.12, 'end': 78.38, 'confidence': 0.974},\n",
       "   {'text': 'tasks', 'start': 78.38, 'end': 78.74, 'confidence': 0.666},\n",
       "   {'text': 'that', 'start': 78.74, 'end': 78.92, 'confidence': 0.996},\n",
       "   {'text': 'a', 'start': 78.92, 'end': 79.06, 'confidence': 0.982},\n",
       "   {'text': 'human', 'start': 79.06, 'end': 79.2, 'confidence': 0.999},\n",
       "   {'text': 'can', 'start': 79.2, 'end': 79.4, 'confidence': 0.999},\n",
       "   {'text': 'perform.', 'start': 79.4, 'end': 79.74, 'confidence': 0.996},\n",
       "   {'text': 'This', 'start': 79.96, 'end': 80.44, 'confidence': 0.988},\n",
       "   {'text': 'does', 'start': 80.44, 'end': 80.92, 'confidence': 0.999},\n",
       "   {'text': 'not', 'start': 80.92, 'end': 81.2, 'confidence': 1.0},\n",
       "   {'text': 'exist', 'start': 81.2, 'end': 81.58, 'confidence': 0.979},\n",
       "   {'text': 'there', 'start': 81.58, 'end': 81.84, 'confidence': 0.429},\n",
       "   {'text': 'are', 'start': 81.84, 'end': 82.02, 'confidence': 0.997},\n",
       "   {'text': 'no', 'start': 82.02, 'end': 82.22, 'confidence': 0.998},\n",
       "   {'text': 'Terminator', 'start': 82.22, 'end': 82.6, 'confidence': 0.678},\n",
       "   {'text': 'robots.', 'start': 82.6, 'end': 83.08, 'confidence': 0.98}]},\n",
       " {'id': 11,\n",
       "  'seek': 7100,\n",
       "  'start': 83.5,\n",
       "  'end': 98.74,\n",
       "  'text': \" There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our\",\n",
       "  'tokens': [51014,\n",
       "   821,\n",
       "   366,\n",
       "   572,\n",
       "   11,\n",
       "   456,\n",
       "   366,\n",
       "   456,\n",
       "   307,\n",
       "   572,\n",
       "   1270,\n",
       "   551,\n",
       "   382,\n",
       "   2674,\n",
       "   7318,\n",
       "   293,\n",
       "   8572,\n",
       "   11,\n",
       "   588,\n",
       "   13371,\n",
       "   294,\n",
       "   2115,\n",
       "   295,\n",
       "   641,\n",
       "   21264,\n",
       "   322,\n",
       "   562,\n",
       "   341,\n",
       "   815,\n",
       "   767,\n",
       "   1051,\n",
       "   370,\n",
       "   456,\n",
       "   366,\n",
       "   512,\n",
       "   561,\n",
       "   567,\n",
       "   584,\n",
       "   1954,\n",
       "   1266,\n",
       "   2009,\n",
       "   924,\n",
       "   11,\n",
       "   293,\n",
       "   456,\n",
       "   311,\n",
       "   512,\n",
       "   561,\n",
       "   567,\n",
       "   584,\n",
       "   11,\n",
       "   406,\n",
       "   294,\n",
       "   527,\n",
       "   51764],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.15347844583016854,\n",
       "  'compression_ratio': 1.7132075471698114,\n",
       "  'no_speech_prob': 0.6496715545654297,\n",
       "  'confidence': 0.909,\n",
       "  'words': [{'text': 'There', 'start': 83.5, 'end': 84.1, 'confidence': 0.634},\n",
       "   {'text': 'are', 'start': 84.1, 'end': 84.34, 'confidence': 0.997},\n",
       "   {'text': 'no,', 'start': 84.34, 'end': 84.74, 'confidence': 0.996},\n",
       "   {'text': 'there', 'start': 85.24, 'end': 85.38, 'confidence': 0.995},\n",
       "   {'text': 'are', 'start': 85.38, 'end': 85.6, 'confidence': 0.993},\n",
       "   {'text': 'there', 'start': 85.6, 'end': 85.88, 'confidence': 0.779},\n",
       "   {'text': 'is', 'start': 85.88, 'end': 86.24, 'confidence': 0.919},\n",
       "   {'text': 'no', 'start': 86.24, 'end': 86.44, 'confidence': 0.998},\n",
       "   {'text': 'such', 'start': 86.44, 'end': 86.6, 'confidence': 0.999},\n",
       "   {'text': 'thing', 'start': 86.6, 'end': 86.78, 'confidence': 0.983},\n",
       "   {'text': 'as', 'start': 86.78, 'end': 86.94, 'confidence': 0.997},\n",
       "   {'text': 'general', 'start': 86.94, 'end': 87.28, 'confidence': 0.965},\n",
       "   {'text': 'AI', 'start': 87.28, 'end': 87.64, 'confidence': 0.963},\n",
       "   {'text': 'and', 'start': 87.64, 'end': 87.92, 'confidence': 0.997},\n",
       "   {'text': 'experts,', 'start': 87.92, 'end': 88.34, 'confidence': 0.998},\n",
       "   {'text': 'very', 'start': 88.88, 'end': 89.0, 'confidence': 0.978},\n",
       "   {'text': 'widely', 'start': 89.0, 'end': 89.54, 'confidence': 0.996},\n",
       "   {'text': 'in', 'start': 89.54, 'end': 90.08, 'confidence': 0.464},\n",
       "   {'text': 'terms', 'start': 90.08, 'end': 90.22, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 90.22, 'end': 90.3, 'confidence': 1.0},\n",
       "   {'text': 'their', 'start': 90.3, 'end': 90.5, 'confidence': 0.998},\n",
       "   {'text': 'predictions', 'start': 90.5, 'end': 90.92, 'confidence': 0.998},\n",
       "   {'text': 'on', 'start': 90.92, 'end': 91.14, 'confidence': 0.992},\n",
       "   {'text': 'when', 'start': 91.14, 'end': 91.48, 'confidence': 0.998},\n",
       "   {'text': 'this', 'start': 91.48, 'end': 92.12, 'confidence': 0.998},\n",
       "   {'text': 'may', 'start': 92.12, 'end': 92.54, 'confidence': 1.0},\n",
       "   {'text': 'actually', 'start': 92.54, 'end': 92.94, 'confidence': 1.0},\n",
       "   {'text': 'happen', 'start': 92.94, 'end': 93.32, 'confidence': 0.936},\n",
       "   {'text': 'so', 'start': 93.32, 'end': 93.94, 'confidence': 0.726},\n",
       "   {'text': 'there', 'start': 93.94, 'end': 94.54, 'confidence': 0.978},\n",
       "   {'text': 'are', 'start': 94.54, 'end': 94.76, 'confidence': 1.0},\n",
       "   {'text': 'some', 'start': 94.76, 'end': 94.96, 'confidence': 1.0},\n",
       "   {'text': 'people', 'start': 94.96, 'end': 95.14, 'confidence': 1.0},\n",
       "   {'text': 'who', 'start': 95.14, 'end': 95.34, 'confidence': 0.999},\n",
       "   {'text': 'say', 'start': 95.34, 'end': 95.54, 'confidence': 0.999},\n",
       "   {'text': 'oh', 'start': 95.54, 'end': 95.86, 'confidence': 0.696},\n",
       "   {'text': '1020', 'start': 95.86, 'end': 96.64, 'confidence': 0.665},\n",
       "   {'text': 'years,', 'start': 96.64, 'end': 97.02, 'confidence': 0.997},\n",
       "   {'text': 'and', 'start': 97.28, 'end': 97.34, 'confidence': 0.629},\n",
       "   {'text': \"there's\", 'start': 97.34, 'end': 97.46, 'confidence': 0.879},\n",
       "   {'text': 'some', 'start': 97.46, 'end': 97.58, 'confidence': 0.959},\n",
       "   {'text': 'people', 'start': 97.58, 'end': 97.78, 'confidence': 0.996},\n",
       "   {'text': 'who', 'start': 97.78, 'end': 97.94, 'confidence': 0.973},\n",
       "   {'text': 'say,', 'start': 97.94, 'end': 98.18, 'confidence': 0.984},\n",
       "   {'text': 'not', 'start': 98.46, 'end': 98.52, 'confidence': 0.932},\n",
       "   {'text': 'in', 'start': 98.52, 'end': 98.62, 'confidence': 0.929},\n",
       "   {'text': 'our', 'start': 98.62, 'end': 98.74, 'confidence': 0.68}]},\n",
       " {'id': 12,\n",
       "  'seek': 9900,\n",
       "  'start': 99.0,\n",
       "  'end': 116.16,\n",
       "  'text': ' times and some people who say, not ever. So, really really broad range of guesses in any case, most AI. Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer',\n",
       "  'tokens': [50364,\n",
       "   1413,\n",
       "   293,\n",
       "   512,\n",
       "   561,\n",
       "   567,\n",
       "   584,\n",
       "   11,\n",
       "   406,\n",
       "   1562,\n",
       "   13,\n",
       "   407,\n",
       "   11,\n",
       "   534,\n",
       "   534,\n",
       "   4152,\n",
       "   3613,\n",
       "   295,\n",
       "   42703,\n",
       "   294,\n",
       "   604,\n",
       "   1389,\n",
       "   11,\n",
       "   881,\n",
       "   7318,\n",
       "   13,\n",
       "   4919,\n",
       "   11,\n",
       "   439,\n",
       "   295,\n",
       "   264,\n",
       "   7318,\n",
       "   300,\n",
       "   8198,\n",
       "   965,\n",
       "   11,\n",
       "   293,\n",
       "   881,\n",
       "   295,\n",
       "   264,\n",
       "   7318,\n",
       "   300,\n",
       "   291,\n",
       "   1568,\n",
       "   561,\n",
       "   1417,\n",
       "   466,\n",
       "   307,\n",
       "   9432,\n",
       "   293,\n",
       "   9432,\n",
       "   7318,\n",
       "   307,\n",
       "   562,\n",
       "   257,\n",
       "   3820,\n",
       "   51214],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.15250057960624125,\n",
       "  'compression_ratio': 1.5625,\n",
       "  'no_speech_prob': 0.664045512676239,\n",
       "  'confidence': 0.881,\n",
       "  'words': [{'text': 'times',\n",
       "    'start': 99.0,\n",
       "    'end': 99.16,\n",
       "    'confidence': 0.086},\n",
       "   {'text': 'and', 'start': 99.16, 'end': 99.7, 'confidence': 0.749},\n",
       "   {'text': 'some', 'start': 99.7, 'end': 99.88, 'confidence': 0.956},\n",
       "   {'text': 'people', 'start': 99.88, 'end': 100.06, 'confidence': 0.999},\n",
       "   {'text': 'who', 'start': 100.06, 'end': 100.22, 'confidence': 0.964},\n",
       "   {'text': 'say,', 'start': 100.22, 'end': 100.42, 'confidence': 0.998},\n",
       "   {'text': 'not', 'start': 100.64, 'end': 100.78, 'confidence': 0.971},\n",
       "   {'text': 'ever.', 'start': 100.78, 'end': 101.1, 'confidence': 0.994},\n",
       "   {'text': 'So,', 'start': 101.7, 'end': 101.78, 'confidence': 0.964},\n",
       "   {'text': 'really', 'start': 101.98, 'end': 102.24, 'confidence': 0.994},\n",
       "   {'text': 'really', 'start': 102.24, 'end': 102.78, 'confidence': 0.605},\n",
       "   {'text': 'broad', 'start': 102.78, 'end': 103.3, 'confidence': 0.997},\n",
       "   {'text': 'range', 'start': 103.3, 'end': 103.8, 'confidence': 0.992},\n",
       "   {'text': 'of', 'start': 103.8, 'end': 103.9, 'confidence': 0.999},\n",
       "   {'text': 'guesses', 'start': 103.9, 'end': 104.26, 'confidence': 0.896},\n",
       "   {'text': 'in', 'start': 104.26, 'end': 104.5, 'confidence': 0.49},\n",
       "   {'text': 'any', 'start': 104.5, 'end': 104.64, 'confidence': 0.996},\n",
       "   {'text': 'case,', 'start': 104.64, 'end': 105.06, 'confidence': 0.994},\n",
       "   {'text': 'most', 'start': 106.52, 'end': 106.78, 'confidence': 0.879},\n",
       "   {'text': 'AI.', 'start': 106.78, 'end': 107.42, 'confidence': 0.931},\n",
       "   {'text': 'Sorry,', 'start': 107.54, 'end': 108.06, 'confidence': 0.962},\n",
       "   {'text': 'all', 'start': 108.42, 'end': 108.64, 'confidence': 0.997},\n",
       "   {'text': 'of', 'start': 108.64, 'end': 108.72, 'confidence': 0.718},\n",
       "   {'text': 'the', 'start': 108.72, 'end': 108.86, 'confidence': 0.999},\n",
       "   {'text': 'AI', 'start': 108.86, 'end': 109.0, 'confidence': 0.995},\n",
       "   {'text': 'that', 'start': 109.0, 'end': 109.2, 'confidence': 0.999},\n",
       "   {'text': 'exists', 'start': 109.2, 'end': 109.46, 'confidence': 0.993},\n",
       "   {'text': 'today,', 'start': 109.46, 'end': 109.86, 'confidence': 0.999},\n",
       "   {'text': 'and', 'start': 110.14, 'end': 110.32, 'confidence': 0.999},\n",
       "   {'text': 'most', 'start': 110.32, 'end': 110.54, 'confidence': 0.999},\n",
       "   {'text': 'of', 'start': 110.54, 'end': 110.66, 'confidence': 0.998},\n",
       "   {'text': 'the', 'start': 110.66, 'end': 110.8, 'confidence': 0.999},\n",
       "   {'text': 'AI', 'start': 110.8, 'end': 110.98, 'confidence': 0.987},\n",
       "   {'text': 'that', 'start': 110.98, 'end': 111.12, 'confidence': 0.995},\n",
       "   {'text': 'you', 'start': 111.12, 'end': 111.16, 'confidence': 0.999},\n",
       "   {'text': 'hear', 'start': 111.16, 'end': 111.32, 'confidence': 0.942},\n",
       "   {'text': 'people', 'start': 111.32, 'end': 111.46, 'confidence': 0.996},\n",
       "   {'text': 'talking', 'start': 111.46, 'end': 111.76, 'confidence': 0.997},\n",
       "   {'text': 'about', 'start': 111.76, 'end': 112.5, 'confidence': 1.0},\n",
       "   {'text': 'is', 'start': 112.5, 'end': 113.72, 'confidence': 0.822},\n",
       "   {'text': 'narrow', 'start': 113.72, 'end': 114.18, 'confidence': 0.991},\n",
       "   {'text': 'and', 'start': 114.18, 'end': 115.0, 'confidence': 0.732},\n",
       "   {'text': 'narrow', 'start': 115.0, 'end': 115.28, 'confidence': 0.979},\n",
       "   {'text': 'AI', 'start': 115.28, 'end': 115.6, 'confidence': 0.85},\n",
       "   {'text': 'is', 'start': 115.6, 'end': 115.76, 'confidence': 0.963},\n",
       "   {'text': 'when', 'start': 115.76, 'end': 115.9, 'confidence': 0.968},\n",
       "   {'text': 'a', 'start': 115.9, 'end': 116.06, 'confidence': 0.868},\n",
       "   {'text': 'computer', 'start': 116.06, 'end': 116.16, 'confidence': 0.794}]},\n",
       " {'id': 13,\n",
       "  'seek': 9900,\n",
       "  'start': 116.16,\n",
       "  'end': 118.54,\n",
       "  'text': ' exhibits intelligence at one task.',\n",
       "  'tokens': [51214, 39205, 7599, 412, 472, 5633, 13, 51414],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.15250057960624125,\n",
       "  'compression_ratio': 1.5625,\n",
       "  'no_speech_prob': 0.664045512676239,\n",
       "  'confidence': 0.961,\n",
       "  'words': [{'text': 'exhibits',\n",
       "    'start': 116.16,\n",
       "    'end': 116.76,\n",
       "    'confidence': 0.911},\n",
       "   {'text': 'intelligence',\n",
       "    'start': 116.76,\n",
       "    'end': 117.34,\n",
       "    'confidence': 0.982},\n",
       "   {'text': 'at', 'start': 117.34, 'end': 117.72, 'confidence': 0.937},\n",
       "   {'text': 'one', 'start': 117.72, 'end': 117.92, 'confidence': 0.997},\n",
       "   {'text': 'task.', 'start': 117.92, 'end': 118.54, 'confidence': 0.982}]},\n",
       " {'id': 14,\n",
       "  'seek': 12000,\n",
       "  'start': 120.0,\n",
       "  'end': 122.8,\n",
       "  'text': ' To be clear, you can do pretty impressive things with narrow AI.',\n",
       "  'tokens': [50364,\n",
       "   1407,\n",
       "   312,\n",
       "   1850,\n",
       "   11,\n",
       "   291,\n",
       "   393,\n",
       "   360,\n",
       "   1238,\n",
       "   8992,\n",
       "   721,\n",
       "   365,\n",
       "   9432,\n",
       "   7318,\n",
       "   13,\n",
       "   50564],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.125052547454834,\n",
       "  'compression_ratio': 1.8235294117647058,\n",
       "  'no_speech_prob': 0.5140997767448425,\n",
       "  'confidence': 0.866,\n",
       "  'words': [{'text': 'To', 'start': 120.0, 'end': 120.08, 'confidence': 0.295},\n",
       "   {'text': 'be', 'start': 120.08, 'end': 120.24, 'confidence': 0.987},\n",
       "   {'text': 'clear,', 'start': 120.24, 'end': 120.54, 'confidence': 0.975},\n",
       "   {'text': 'you', 'start': 120.9, 'end': 120.92, 'confidence': 0.987},\n",
       "   {'text': 'can', 'start': 120.92, 'end': 121.06, 'confidence': 0.999},\n",
       "   {'text': 'do', 'start': 121.06, 'end': 121.16, 'confidence': 0.994},\n",
       "   {'text': 'pretty', 'start': 121.16, 'end': 121.36, 'confidence': 0.995},\n",
       "   {'text': 'impressive', 'start': 121.36, 'end': 121.66, 'confidence': 0.998},\n",
       "   {'text': 'things', 'start': 121.66, 'end': 121.94, 'confidence': 0.997},\n",
       "   {'text': 'with', 'start': 121.94, 'end': 122.12, 'confidence': 0.868},\n",
       "   {'text': 'narrow', 'start': 122.12, 'end': 122.32, 'confidence': 0.787},\n",
       "   {'text': 'AI.', 'start': 122.32, 'end': 122.8, 'confidence': 0.942}]},\n",
       " {'id': 15,\n",
       "  'seek': 12000,\n",
       "  'start': 123.5,\n",
       "  'end': 134.02,\n",
       "  'text': \" A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car.\",\n",
       "  'tokens': [50564,\n",
       "   316,\n",
       "   2698,\n",
       "   4840,\n",
       "   1032,\n",
       "   337,\n",
       "   1365,\n",
       "   11,\n",
       "   575,\n",
       "   472,\n",
       "   9432,\n",
       "   7318,\n",
       "   1185,\n",
       "   300,\n",
       "   775,\n",
       "   5201,\n",
       "   11,\n",
       "   1542,\n",
       "   412,\n",
       "   264,\n",
       "   3060,\n",
       "   293,\n",
       "   17489,\n",
       "   1373,\n",
       "   721,\n",
       "   13,\n",
       "   821,\n",
       "   311,\n",
       "   1071,\n",
       "   7318,\n",
       "   1185,\n",
       "   300,\n",
       "   775,\n",
       "   14823,\n",
       "   300,\n",
       "   9003,\n",
       "   264,\n",
       "   1032,\n",
       "   13,\n",
       "   51114],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.125052547454834,\n",
       "  'compression_ratio': 1.8235294117647058,\n",
       "  'no_speech_prob': 0.5140997767448425,\n",
       "  'confidence': 0.945,\n",
       "  'words': [{'text': 'A', 'start': 123.5, 'end': 123.52, 'confidence': 0.858},\n",
       "   {'text': 'self', 'start': 123.52, 'end': 123.64, 'confidence': 0.994},\n",
       "   {'text': 'driving', 'start': 123.64, 'end': 123.9, 'confidence': 0.978},\n",
       "   {'text': 'car', 'start': 123.9, 'end': 124.2, 'confidence': 0.998},\n",
       "   {'text': 'for', 'start': 124.2, 'end': 124.44, 'confidence': 0.671},\n",
       "   {'text': 'example,', 'start': 124.44, 'end': 124.88, 'confidence': 1.0},\n",
       "   {'text': 'has', 'start': 125.18, 'end': 125.46, 'confidence': 0.997},\n",
       "   {'text': 'one', 'start': 125.46, 'end': 126.08, 'confidence': 0.994},\n",
       "   {'text': 'narrow', 'start': 126.08, 'end': 126.52, 'confidence': 0.971},\n",
       "   {'text': 'AI', 'start': 126.52, 'end': 126.76, 'confidence': 0.936},\n",
       "   {'text': 'system', 'start': 126.76, 'end': 127.26, 'confidence': 0.997},\n",
       "   {'text': 'that', 'start': 127.26, 'end': 128.0, 'confidence': 0.985},\n",
       "   {'text': 'does', 'start': 128.0, 'end': 128.64, 'confidence': 0.998},\n",
       "   {'text': 'vision,', 'start': 128.64, 'end': 129.02, 'confidence': 0.974},\n",
       "   {'text': 'looks', 'start': 129.24, 'end': 129.4, 'confidence': 0.607},\n",
       "   {'text': 'at', 'start': 129.4, 'end': 129.52, 'confidence': 0.999},\n",
       "   {'text': 'the', 'start': 129.52, 'end': 129.64, 'confidence': 1.0},\n",
       "   {'text': 'road', 'start': 129.64, 'end': 129.78, 'confidence': 0.997},\n",
       "   {'text': 'and', 'start': 129.78, 'end': 129.96, 'confidence': 0.957},\n",
       "   {'text': 'interprets', 'start': 129.96, 'end': 130.22, 'confidence': 0.862},\n",
       "   {'text': 'things.', 'start': 130.22, 'end': 130.5, 'confidence': 0.996},\n",
       "   {'text': \"There's\", 'start': 130.86, 'end': 130.94, 'confidence': 0.991},\n",
       "   {'text': 'another', 'start': 130.94, 'end': 131.26, 'confidence': 0.998},\n",
       "   {'text': 'AI', 'start': 131.26, 'end': 131.56, 'confidence': 0.991},\n",
       "   {'text': 'system', 'start': 131.56, 'end': 131.9, 'confidence': 0.998},\n",
       "   {'text': 'that', 'start': 131.9, 'end': 132.1, 'confidence': 0.999},\n",
       "   {'text': 'does', 'start': 132.1, 'end': 132.4, 'confidence': 0.998},\n",
       "   {'text': 'steering', 'start': 132.4, 'end': 132.72, 'confidence': 0.942},\n",
       "   {'text': 'that', 'start': 132.72, 'end': 133.14, 'confidence': 0.769},\n",
       "   {'text': 'controls', 'start': 133.14, 'end': 133.52, 'confidence': 0.999},\n",
       "   {'text': 'the', 'start': 133.52, 'end': 133.76, 'confidence': 0.999},\n",
       "   {'text': 'car.', 'start': 133.76, 'end': 134.02, 'confidence': 0.999}]},\n",
       " {'id': 16,\n",
       "  'seek': 12000,\n",
       "  'start': 134.5,\n",
       "  'end': 141.28,\n",
       "  'text': \" There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together.\",\n",
       "  'tokens': [51114,\n",
       "   821,\n",
       "   311,\n",
       "   1071,\n",
       "   7318,\n",
       "   1185,\n",
       "   300,\n",
       "   775,\n",
       "   7955,\n",
       "   5038,\n",
       "   300,\n",
       "   1619,\n",
       "   322,\n",
       "   257,\n",
       "   4152,\n",
       "   1496,\n",
       "   437,\n",
       "   366,\n",
       "   321,\n",
       "   1382,\n",
       "   281,\n",
       "   291,\n",
       "   458,\n",
       "   689,\n",
       "   321,\n",
       "   516,\n",
       "   11,\n",
       "   577,\n",
       "   360,\n",
       "   321,\n",
       "   483,\n",
       "   456,\n",
       "   13,\n",
       "   400,\n",
       "   562,\n",
       "   291,\n",
       "   5635,\n",
       "   439,\n",
       "   729,\n",
       "   1214,\n",
       "   13,\n",
       "   51514],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.125052547454834,\n",
       "  'compression_ratio': 1.8235294117647058,\n",
       "  'no_speech_prob': 0.5140997767448425,\n",
       "  'confidence': 0.903,\n",
       "  'words': [{'text': \"There's\",\n",
       "    'start': 134.5,\n",
       "    'end': 134.52,\n",
       "    'confidence': 0.953},\n",
       "   {'text': 'another', 'start': 134.52, 'end': 134.72, 'confidence': 0.998},\n",
       "   {'text': 'AI', 'start': 134.72, 'end': 134.92, 'confidence': 0.982},\n",
       "   {'text': 'system', 'start': 134.92, 'end': 135.22, 'confidence': 0.999},\n",
       "   {'text': 'that', 'start': 135.22, 'end': 135.34, 'confidence': 0.999},\n",
       "   {'text': 'does', 'start': 135.34, 'end': 135.56, 'confidence': 0.992},\n",
       "   {'text': 'route', 'start': 135.56, 'end': 135.82, 'confidence': 0.993},\n",
       "   {'text': 'planning', 'start': 135.82, 'end': 136.08, 'confidence': 0.998},\n",
       "   {'text': 'that', 'start': 136.08, 'end': 136.28, 'confidence': 0.962},\n",
       "   {'text': 'says', 'start': 136.28, 'end': 136.5, 'confidence': 0.997},\n",
       "   {'text': 'on', 'start': 136.5, 'end': 136.84, 'confidence': 0.628},\n",
       "   {'text': 'a', 'start': 136.84, 'end': 137.04, 'confidence': 0.981},\n",
       "   {'text': 'broad', 'start': 137.04, 'end': 137.24, 'confidence': 1.0},\n",
       "   {'text': 'level', 'start': 137.24, 'end': 137.52, 'confidence': 0.999},\n",
       "   {'text': 'what', 'start': 137.52, 'end': 137.64, 'confidence': 0.62},\n",
       "   {'text': 'are', 'start': 137.64, 'end': 137.74, 'confidence': 0.965},\n",
       "   {'text': 'we', 'start': 137.74, 'end': 137.84, 'confidence': 0.998},\n",
       "   {'text': 'trying', 'start': 137.84, 'end': 138.0, 'confidence': 0.939},\n",
       "   {'text': 'to', 'start': 138.0, 'end': 138.02, 'confidence': 0.663},\n",
       "   {'text': 'you', 'start': 138.02, 'end': 138.14, 'confidence': 0.714},\n",
       "   {'text': 'know', 'start': 138.14, 'end': 138.24, 'confidence': 0.995},\n",
       "   {'text': 'where', 'start': 138.24, 'end': 138.38, 'confidence': 0.971},\n",
       "   {'text': 'we', 'start': 138.38, 'end': 138.54, 'confidence': 0.787},\n",
       "   {'text': 'going,', 'start': 138.54, 'end': 138.68, 'confidence': 0.652},\n",
       "   {'text': 'how', 'start': 138.78, 'end': 138.88, 'confidence': 0.979},\n",
       "   {'text': 'do', 'start': 138.88, 'end': 139.0, 'confidence': 0.984},\n",
       "   {'text': 'we', 'start': 139.0, 'end': 139.04, 'confidence': 1.0},\n",
       "   {'text': 'get', 'start': 139.04, 'end': 139.22, 'confidence': 1.0},\n",
       "   {'text': 'there.', 'start': 139.22, 'end': 139.5, 'confidence': 0.604},\n",
       "   {'text': 'And', 'start': 139.6, 'end': 140.0, 'confidence': 0.775},\n",
       "   {'text': 'when', 'start': 140.0, 'end': 140.12, 'confidence': 0.999},\n",
       "   {'text': 'you', 'start': 140.12, 'end': 140.22, 'confidence': 1.0},\n",
       "   {'text': 'stitch', 'start': 140.22, 'end': 140.44, 'confidence': 0.814},\n",
       "   {'text': 'all', 'start': 140.44, 'end': 140.58, 'confidence': 0.994},\n",
       "   {'text': 'those', 'start': 140.58, 'end': 140.72, 'confidence': 0.949},\n",
       "   {'text': 'together.',\n",
       "    'start': 140.72,\n",
       "    'end': 141.28,\n",
       "    'confidence': 0.996}]},\n",
       " {'id': 17,\n",
       "  'seek': 14300,\n",
       "  'start': 143.0,\n",
       "  'end': 147.16,\n",
       "  'text': \" So, it's a very impressive system but you cannot sit this card down and play chess with it.\",\n",
       "  'tokens': [50364,\n",
       "   407,\n",
       "   11,\n",
       "   309,\n",
       "   311,\n",
       "   257,\n",
       "   588,\n",
       "   8992,\n",
       "   1185,\n",
       "   457,\n",
       "   291,\n",
       "   2644,\n",
       "   1394,\n",
       "   341,\n",
       "   2920,\n",
       "   760,\n",
       "   293,\n",
       "   862,\n",
       "   24122,\n",
       "   365,\n",
       "   309,\n",
       "   13,\n",
       "   50614],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.755,\n",
       "  'words': [{'text': 'So,',\n",
       "    'start': 143.0,\n",
       "    'end': 143.02,\n",
       "    'confidence': 0.166},\n",
       "   {'text': \"it's\", 'start': 143.02, 'end': 143.04, 'confidence': 0.498},\n",
       "   {'text': 'a', 'start': 143.04, 'end': 143.06, 'confidence': 0.699},\n",
       "   {'text': 'very', 'start': 143.06, 'end': 143.16, 'confidence': 0.912},\n",
       "   {'text': 'impressive', 'start': 143.16, 'end': 143.52, 'confidence': 0.816},\n",
       "   {'text': 'system', 'start': 143.52, 'end': 143.84, 'confidence': 0.995},\n",
       "   {'text': 'but', 'start': 143.84, 'end': 144.26, 'confidence': 0.729},\n",
       "   {'text': 'you', 'start': 144.26, 'end': 144.66, 'confidence': 0.993},\n",
       "   {'text': 'cannot', 'start': 144.66, 'end': 145.0, 'confidence': 0.83},\n",
       "   {'text': 'sit', 'start': 145.0, 'end': 145.24, 'confidence': 0.946},\n",
       "   {'text': 'this', 'start': 145.24, 'end': 145.48, 'confidence': 0.985},\n",
       "   {'text': 'card', 'start': 145.48, 'end': 145.64, 'confidence': 0.596},\n",
       "   {'text': 'down', 'start': 145.64, 'end': 145.82, 'confidence': 0.69},\n",
       "   {'text': 'and', 'start': 145.82, 'end': 145.94, 'confidence': 0.996},\n",
       "   {'text': 'play', 'start': 145.94, 'end': 146.08, 'confidence': 0.996},\n",
       "   {'text': 'chess', 'start': 146.08, 'end': 146.28, 'confidence': 0.999},\n",
       "   {'text': 'with', 'start': 146.28, 'end': 146.44, 'confidence': 0.998},\n",
       "   {'text': 'it.', 'start': 146.44, 'end': 147.16, 'confidence': 0.996}]},\n",
       " {'id': 18,\n",
       "  'seek': 14300,\n",
       "  'start': 147.5,\n",
       "  'end': 148.46,\n",
       "  'text': ' This car will not learn how to paint.',\n",
       "  'tokens': [50614, 639, 1032, 486, 406, 1466, 577, 281, 4225, 13, 50714],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.972,\n",
       "  'words': [{'text': 'This',\n",
       "    'start': 147.5,\n",
       "    'end': 147.52,\n",
       "    'confidence': 0.98},\n",
       "   {'text': 'car', 'start': 147.52, 'end': 147.58, 'confidence': 0.824},\n",
       "   {'text': 'will', 'start': 147.58, 'end': 147.74, 'confidence': 0.992},\n",
       "   {'text': 'not', 'start': 147.74, 'end': 147.86, 'confidence': 0.999},\n",
       "   {'text': 'learn', 'start': 147.86, 'end': 148.0, 'confidence': 0.999},\n",
       "   {'text': 'how', 'start': 148.0, 'end': 148.12, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 148.12, 'end': 148.18, 'confidence': 1.0},\n",
       "   {'text': 'paint.', 'start': 148.18, 'end': 148.46, 'confidence': 0.996}]},\n",
       " {'id': 19,\n",
       "  'seek': 14300,\n",
       "  'start': 149.5,\n",
       "  'end': 152.8,\n",
       "  'text': ' This car will not learn how to speak Russian.',\n",
       "  'tokens': [50714,\n",
       "   639,\n",
       "   1032,\n",
       "   486,\n",
       "   406,\n",
       "   1466,\n",
       "   577,\n",
       "   281,\n",
       "   1710,\n",
       "   7220,\n",
       "   13,\n",
       "   50914],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.992,\n",
       "  'words': [{'text': 'This',\n",
       "    'start': 149.5,\n",
       "    'end': 149.56,\n",
       "    'confidence': 0.987},\n",
       "   {'text': 'car', 'start': 149.56, 'end': 149.68, 'confidence': 0.977},\n",
       "   {'text': 'will', 'start': 149.68, 'end': 149.84, 'confidence': 0.999},\n",
       "   {'text': 'not', 'start': 149.84, 'end': 150.4, 'confidence': 1.0},\n",
       "   {'text': 'learn', 'start': 150.4, 'end': 151.22, 'confidence': 0.983},\n",
       "   {'text': 'how', 'start': 151.22, 'end': 151.52, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 151.52, 'end': 152.0, 'confidence': 1.0},\n",
       "   {'text': 'speak', 'start': 152.0, 'end': 152.36, 'confidence': 0.999},\n",
       "   {'text': 'Russian.', 'start': 152.36, 'end': 152.8, 'confidence': 0.988}]},\n",
       " {'id': 20,\n",
       "  'seek': 14300,\n",
       "  'start': 153.72,\n",
       "  'end': 158.64,\n",
       "  'text': \" Right, it's doing a specific set of tasks, each of which has been trained separately.\",\n",
       "  'tokens': [50914,\n",
       "   1779,\n",
       "   11,\n",
       "   309,\n",
       "   311,\n",
       "   884,\n",
       "   257,\n",
       "   2685,\n",
       "   992,\n",
       "   295,\n",
       "   9608,\n",
       "   11,\n",
       "   1184,\n",
       "   295,\n",
       "   597,\n",
       "   575,\n",
       "   668,\n",
       "   8895,\n",
       "   14759,\n",
       "   13,\n",
       "   51214],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.984,\n",
       "  'words': [{'text': 'Right,',\n",
       "    'start': 153.72,\n",
       "    'end': 153.92,\n",
       "    'confidence': 0.904},\n",
       "   {'text': \"it's\", 'start': 154.04, 'end': 154.14, 'confidence': 0.997},\n",
       "   {'text': 'doing', 'start': 154.14, 'end': 154.54, 'confidence': 1.0},\n",
       "   {'text': 'a', 'start': 154.54, 'end': 155.04, 'confidence': 0.996},\n",
       "   {'text': 'specific', 'start': 155.04, 'end': 155.6, 'confidence': 1.0},\n",
       "   {'text': 'set', 'start': 155.6, 'end': 155.98, 'confidence': 0.999},\n",
       "   {'text': 'of', 'start': 155.98, 'end': 156.12, 'confidence': 1.0},\n",
       "   {'text': 'tasks,', 'start': 156.12, 'end': 156.6, 'confidence': 0.999},\n",
       "   {'text': 'each', 'start': 157.08, 'end': 157.24, 'confidence': 0.998},\n",
       "   {'text': 'of', 'start': 157.24, 'end': 157.36, 'confidence': 0.999},\n",
       "   {'text': 'which', 'start': 157.36, 'end': 157.6, 'confidence': 1.0},\n",
       "   {'text': 'has', 'start': 157.6, 'end': 157.84, 'confidence': 0.873},\n",
       "   {'text': 'been', 'start': 157.84, 'end': 157.98, 'confidence': 1.0},\n",
       "   {'text': 'trained', 'start': 157.98, 'end': 158.18, 'confidence': 0.988},\n",
       "   {'text': 'separately.',\n",
       "    'start': 158.18,\n",
       "    'end': 158.64,\n",
       "    'confidence': 0.999}]},\n",
       " {'id': 21,\n",
       "  'seek': 14300,\n",
       "  'start': 159.5,\n",
       "  'end': 161.28,\n",
       "  'text': ' And that is narrow AI.',\n",
       "  'tokens': [51214, 400, 300, 307, 9432, 7318, 13, 51314],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.948,\n",
       "  'words': [{'text': 'And',\n",
       "    'start': 159.5,\n",
       "    'end': 160.04,\n",
       "    'confidence': 0.967},\n",
       "   {'text': 'that', 'start': 160.04, 'end': 160.38, 'confidence': 0.99},\n",
       "   {'text': 'is', 'start': 160.38, 'end': 160.56, 'confidence': 0.998},\n",
       "   {'text': 'narrow', 'start': 160.56, 'end': 160.82, 'confidence': 0.898},\n",
       "   {'text': 'AI.', 'start': 160.82, 'end': 161.28, 'confidence': 0.893}]},\n",
       " {'id': 22,\n",
       "  'seek': 14300,\n",
       "  'start': 161.74,\n",
       "  'end': 165.96,\n",
       "  'text': \" So, now on when I say AI I'm talking about narrow artificial intelligence.\",\n",
       "  'tokens': [51314,\n",
       "   407,\n",
       "   11,\n",
       "   586,\n",
       "   322,\n",
       "   562,\n",
       "   286,\n",
       "   584,\n",
       "   7318,\n",
       "   286,\n",
       "   478,\n",
       "   1417,\n",
       "   466,\n",
       "   9432,\n",
       "   11677,\n",
       "   7599,\n",
       "   13,\n",
       "   51564],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.873,\n",
       "  'words': [{'text': 'So,',\n",
       "    'start': 161.74,\n",
       "    'end': 162.18,\n",
       "    'confidence': 0.98},\n",
       "   {'text': 'now', 'start': 162.36, 'end': 162.48, 'confidence': 0.578},\n",
       "   {'text': 'on', 'start': 162.48, 'end': 162.64, 'confidence': 0.442},\n",
       "   {'text': 'when', 'start': 162.64, 'end': 162.76, 'confidence': 0.977},\n",
       "   {'text': 'I', 'start': 162.76, 'end': 162.9, 'confidence': 0.999},\n",
       "   {'text': 'say', 'start': 162.9, 'end': 163.12, 'confidence': 0.998},\n",
       "   {'text': 'AI', 'start': 163.12, 'end': 163.48, 'confidence': 0.904},\n",
       "   {'text': \"I'm\", 'start': 163.48, 'end': 163.78, 'confidence': 0.842},\n",
       "   {'text': 'talking', 'start': 163.78, 'end': 164.0, 'confidence': 1.0},\n",
       "   {'text': 'about', 'start': 164.0, 'end': 164.42, 'confidence': 1.0},\n",
       "   {'text': 'narrow', 'start': 164.42, 'end': 164.94, 'confidence': 0.979},\n",
       "   {'text': 'artificial', 'start': 164.94, 'end': 165.4, 'confidence': 0.974},\n",
       "   {'text': 'intelligence.',\n",
       "    'start': 165.4,\n",
       "    'end': 165.96,\n",
       "    'confidence': 0.999}]},\n",
       " {'id': 23,\n",
       "  'seek': 14300,\n",
       "  'start': 166.6,\n",
       "  'end': 168.26,\n",
       "  'text': ' Any questions so far.',\n",
       "  'tokens': [51564, 2639, 1651, 370, 1400, 13, 51664],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.985,\n",
       "  'words': [{'text': 'Any', 'start': 166.6, 'end': 166.8, 'confidence': 0.965},\n",
       "   {'text': 'questions', 'start': 166.8, 'end': 167.04, 'confidence': 0.99},\n",
       "   {'text': 'so', 'start': 167.04, 'end': 167.26, 'confidence': 0.989},\n",
       "   {'text': 'far.', 'start': 167.26, 'end': 168.26, 'confidence': 0.996}]},\n",
       " {'id': 24,\n",
       "  'seek': 14300,\n",
       "  'start': 168.5,\n",
       "  'end': 169.8,\n",
       "  'text': ' Question from participant.',\n",
       "  'tokens': [51664, 14464, 490, 24950, 13, 51814],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1291509645956534,\n",
       "  'compression_ratio': 1.6518218623481782,\n",
       "  'no_speech_prob': 0.30686819553375244,\n",
       "  'confidence': 0.907,\n",
       "  'words': [{'text': 'Question',\n",
       "    'start': 168.5,\n",
       "    'end': 168.92,\n",
       "    'confidence': 0.781},\n",
       "   {'text': 'from', 'start': 168.92, 'end': 169.2, 'confidence': 0.995},\n",
       "   {'text': 'participant.',\n",
       "    'start': 169.2,\n",
       "    'end': 169.8,\n",
       "    'confidence': 0.96}]},\n",
       " {'id': 25,\n",
       "  'seek': 17200,\n",
       "  'start': 172.0,\n",
       "  'end': 176.76,\n",
       "  'text': ' In January, do you fall in with regard to general AI. When do you think it will be possible.',\n",
       "  'tokens': [50364,\n",
       "   682,\n",
       "   7061,\n",
       "   11,\n",
       "   360,\n",
       "   291,\n",
       "   2100,\n",
       "   294,\n",
       "   365,\n",
       "   3843,\n",
       "   281,\n",
       "   2674,\n",
       "   7318,\n",
       "   13,\n",
       "   1133,\n",
       "   360,\n",
       "   291,\n",
       "   519,\n",
       "   309,\n",
       "   486,\n",
       "   312,\n",
       "   1944,\n",
       "   13,\n",
       "   50714],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.10477360258711145,\n",
       "  'compression_ratio': 1.672811059907834,\n",
       "  'no_speech_prob': 0.03844000771641731,\n",
       "  'confidence': 0.869,\n",
       "  'words': [{'text': 'In', 'start': 172.0, 'end': 172.02, 'confidence': 0.461},\n",
       "   {'text': 'January,', 'start': 172.02, 'end': 172.26, 'confidence': 0.288},\n",
       "   {'text': 'do', 'start': 172.28, 'end': 172.54, 'confidence': 0.862},\n",
       "   {'text': 'you', 'start': 172.54, 'end': 172.74, 'confidence': 0.999},\n",
       "   {'text': 'fall', 'start': 172.74, 'end': 172.94, 'confidence': 0.967},\n",
       "   {'text': 'in', 'start': 172.94, 'end': 173.12, 'confidence': 0.994},\n",
       "   {'text': 'with', 'start': 173.12, 'end': 173.32, 'confidence': 0.981},\n",
       "   {'text': 'regard', 'start': 173.32, 'end': 173.66, 'confidence': 0.993},\n",
       "   {'text': 'to', 'start': 173.66, 'end': 173.8, 'confidence': 1.0},\n",
       "   {'text': 'general', 'start': 173.8, 'end': 174.26, 'confidence': 0.933},\n",
       "   {'text': 'AI.', 'start': 174.26, 'end': 174.68, 'confidence': 0.919},\n",
       "   {'text': 'When', 'start': 174.92, 'end': 175.4, 'confidence': 0.771},\n",
       "   {'text': 'do', 'start': 175.4, 'end': 175.52, 'confidence': 0.986},\n",
       "   {'text': 'you', 'start': 175.52, 'end': 175.56, 'confidence': 1.0},\n",
       "   {'text': 'think', 'start': 175.56, 'end': 175.72, 'confidence': 1.0},\n",
       "   {'text': 'it', 'start': 175.72, 'end': 175.82, 'confidence': 0.998},\n",
       "   {'text': 'will', 'start': 175.82, 'end': 175.94, 'confidence': 0.995},\n",
       "   {'text': 'be', 'start': 175.94, 'end': 176.06, 'confidence': 1.0},\n",
       "   {'text': 'possible.',\n",
       "    'start': 176.06,\n",
       "    'end': 176.76,\n",
       "    'confidence': 0.998}]},\n",
       " {'id': 26,\n",
       "  'seek': 17200,\n",
       "  'start': 178.5,\n",
       "  'end': 186.96,\n",
       "  'text': \" I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point.\",\n",
       "  'tokens': [50714,\n",
       "   286,\n",
       "   500,\n",
       "   380,\n",
       "   519,\n",
       "   309,\n",
       "   311,\n",
       "   516,\n",
       "   281,\n",
       "   1051,\n",
       "   337,\n",
       "   257,\n",
       "   1339,\n",
       "   13,\n",
       "   1743,\n",
       "   867,\n",
       "   867,\n",
       "   7878,\n",
       "   11,\n",
       "   457,\n",
       "   286,\n",
       "   611,\n",
       "   519,\n",
       "   300,\n",
       "   309,\n",
       "   311,\n",
       "   2138,\n",
       "   516,\n",
       "   281,\n",
       "   1051,\n",
       "   412,\n",
       "   512,\n",
       "   935,\n",
       "   13,\n",
       "   51264],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.10477360258711145,\n",
       "  'compression_ratio': 1.672811059907834,\n",
       "  'no_speech_prob': 0.03844000771641731,\n",
       "  'confidence': 0.955,\n",
       "  'words': [{'text': 'I', 'start': 178.5, 'end': 179.06, 'confidence': 0.972},\n",
       "   {'text': \"don't\", 'start': 179.06, 'end': 179.2, 'confidence': 1.0},\n",
       "   {'text': 'think', 'start': 179.2, 'end': 179.32, 'confidence': 1.0},\n",
       "   {'text': \"it's\", 'start': 179.32, 'end': 179.44, 'confidence': 0.999},\n",
       "   {'text': 'going', 'start': 179.44, 'end': 179.52, 'confidence': 0.807},\n",
       "   {'text': 'to', 'start': 179.52, 'end': 179.6, 'confidence': 1.0},\n",
       "   {'text': 'happen', 'start': 179.6, 'end': 179.76, 'confidence': 0.999},\n",
       "   {'text': 'for', 'start': 179.76, 'end': 179.94, 'confidence': 0.999},\n",
       "   {'text': 'a', 'start': 179.94, 'end': 180.1, 'confidence': 0.981},\n",
       "   {'text': 'while.', 'start': 180.1, 'end': 180.52, 'confidence': 1.0},\n",
       "   {'text': 'Like', 'start': 180.92, 'end': 181.04, 'confidence': 0.692},\n",
       "   {'text': 'many', 'start': 181.04, 'end': 181.3, 'confidence': 0.93},\n",
       "   {'text': 'many', 'start': 181.3, 'end': 181.52, 'confidence': 0.755},\n",
       "   {'text': 'decades,', 'start': 181.52, 'end': 181.96, 'confidence': 1.0},\n",
       "   {'text': 'but', 'start': 182.34, 'end': 182.44, 'confidence': 0.998},\n",
       "   {'text': 'I', 'start': 182.44, 'end': 182.58, 'confidence': 0.999},\n",
       "   {'text': 'also', 'start': 182.58, 'end': 182.8, 'confidence': 0.999},\n",
       "   {'text': 'think', 'start': 182.8, 'end': 183.06, 'confidence': 1.0},\n",
       "   {'text': 'that', 'start': 183.06, 'end': 183.22, 'confidence': 1.0},\n",
       "   {'text': \"it's\", 'start': 183.22, 'end': 183.38, 'confidence': 0.998},\n",
       "   {'text': 'definitely', 'start': 183.38, 'end': 184.06, 'confidence': 1.0},\n",
       "   {'text': 'going', 'start': 184.06, 'end': 185.2, 'confidence': 0.791},\n",
       "   {'text': 'to', 'start': 185.2, 'end': 185.32, 'confidence': 0.999},\n",
       "   {'text': 'happen', 'start': 185.32, 'end': 185.5, 'confidence': 0.998},\n",
       "   {'text': 'at', 'start': 185.5, 'end': 185.64, 'confidence': 0.948},\n",
       "   {'text': 'some', 'start': 185.64, 'end': 185.76, 'confidence': 0.934},\n",
       "   {'text': 'point.', 'start': 185.76, 'end': 186.96, 'confidence': 0.969}]},\n",
       " {'id': 27,\n",
       "  'seek': 17200,\n",
       "  'start': 190.04,\n",
       "  'end': 192.98,\n",
       "  'text': \" Many decades to maybe centuries I don't know.\",\n",
       "  'tokens': [51264,\n",
       "   5126,\n",
       "   7878,\n",
       "   281,\n",
       "   1310,\n",
       "   13926,\n",
       "   286,\n",
       "   500,\n",
       "   380,\n",
       "   458,\n",
       "   13,\n",
       "   51464],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.10477360258711145,\n",
       "  'compression_ratio': 1.672811059907834,\n",
       "  'no_speech_prob': 0.03844000771641731,\n",
       "  'confidence': 0.915,\n",
       "  'words': [{'text': 'Many',\n",
       "    'start': 190.04,\n",
       "    'end': 190.34,\n",
       "    'confidence': 0.831},\n",
       "   {'text': 'decades', 'start': 190.34, 'end': 190.74, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 190.74, 'end': 191.04, 'confidence': 0.959},\n",
       "   {'text': 'maybe', 'start': 191.04, 'end': 191.36, 'confidence': 0.958},\n",
       "   {'text': 'centuries', 'start': 191.36, 'end': 191.86, 'confidence': 0.966},\n",
       "   {'text': 'I', 'start': 191.86, 'end': 192.04, 'confidence': 0.615},\n",
       "   {'text': \"don't\", 'start': 192.04, 'end': 192.2, 'confidence': 0.997},\n",
       "   {'text': 'know.', 'start': 192.2, 'end': 192.98, 'confidence': 0.996}]},\n",
       " {'id': 28,\n",
       "  'seek': 17200,\n",
       "  'start': 193.5,\n",
       "  'end': 197.02,\n",
       "  'text': \" I think technological progress is hard to guess at so I think it's a fool's errand.\",\n",
       "  'tokens': [51464,\n",
       "   286,\n",
       "   519,\n",
       "   18439,\n",
       "   4205,\n",
       "   307,\n",
       "   1152,\n",
       "   281,\n",
       "   2041,\n",
       "   412,\n",
       "   370,\n",
       "   286,\n",
       "   519,\n",
       "   309,\n",
       "   311,\n",
       "   257,\n",
       "   7979,\n",
       "   311,\n",
       "   45810,\n",
       "   13,\n",
       "   51714],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.10477360258711145,\n",
       "  'compression_ratio': 1.672811059907834,\n",
       "  'no_speech_prob': 0.03844000771641731,\n",
       "  'confidence': 0.903,\n",
       "  'words': [{'text': 'I', 'start': 193.5, 'end': 193.68, 'confidence': 0.847},\n",
       "   {'text': 'think', 'start': 193.68, 'end': 193.88, 'confidence': 0.999},\n",
       "   {'text': 'technological',\n",
       "    'start': 193.88,\n",
       "    'end': 194.3,\n",
       "    'confidence': 0.833},\n",
       "   {'text': 'progress', 'start': 194.3, 'end': 194.62, 'confidence': 0.993},\n",
       "   {'text': 'is', 'start': 194.62, 'end': 194.74, 'confidence': 0.987},\n",
       "   {'text': 'hard', 'start': 194.74, 'end': 194.86, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 194.86, 'end': 194.96, 'confidence': 1.0},\n",
       "   {'text': 'guess', 'start': 194.96, 'end': 195.16, 'confidence': 0.924},\n",
       "   {'text': 'at', 'start': 195.16, 'end': 195.36, 'confidence': 0.529},\n",
       "   {'text': 'so', 'start': 195.36, 'end': 195.58, 'confidence': 0.607},\n",
       "   {'text': 'I', 'start': 195.58, 'end': 195.92, 'confidence': 0.912},\n",
       "   {'text': 'think', 'start': 195.92, 'end': 196.08, 'confidence': 0.923},\n",
       "   {'text': \"it's\", 'start': 196.08, 'end': 196.24, 'confidence': 0.999},\n",
       "   {'text': 'a', 'start': 196.24, 'end': 196.36, 'confidence': 0.998},\n",
       "   {'text': \"fool's\", 'start': 196.36, 'end': 196.64, 'confidence': 0.967},\n",
       "   {'text': 'errand.', 'start': 196.64, 'end': 197.02, 'confidence': 0.995}]},\n",
       " {'id': 29,\n",
       "  'seek': 19900,\n",
       "  'start': 199.0,\n",
       "  'end': 208.5,\n",
       "  'text': \" So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning.\",\n",
       "  'tokens': [50364,\n",
       "   407,\n",
       "   11,\n",
       "   437,\n",
       "   775,\n",
       "   9432,\n",
       "   7318,\n",
       "   767,\n",
       "   360,\n",
       "   731,\n",
       "   7476,\n",
       "   9608,\n",
       "   11,\n",
       "   382,\n",
       "   321,\n",
       "   600,\n",
       "   1612,\n",
       "   365,\n",
       "   264,\n",
       "   2698,\n",
       "   4840,\n",
       "   1032,\n",
       "   1365,\n",
       "   4090,\n",
       "   5201,\n",
       "   11,\n",
       "   2856,\n",
       "   9007,\n",
       "   293,\n",
       "   5038,\n",
       "   13,\n",
       "   50864],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.10106727744959577,\n",
       "  'compression_ratio': 1.7227272727272727,\n",
       "  'no_speech_prob': 0.04462442547082901,\n",
       "  'confidence': 0.913,\n",
       "  'words': [{'text': 'So,',\n",
       "    'start': 199.0,\n",
       "    'end': 199.44,\n",
       "    'confidence': 0.663},\n",
       "   {'text': 'what', 'start': 200.08, 'end': 200.52, 'confidence': 0.967},\n",
       "   {'text': 'does', 'start': 200.52, 'end': 201.02, 'confidence': 0.994},\n",
       "   {'text': 'narrow', 'start': 201.02, 'end': 201.26, 'confidence': 0.417},\n",
       "   {'text': 'AI', 'start': 201.26, 'end': 201.5, 'confidence': 0.921},\n",
       "   {'text': 'actually', 'start': 201.5, 'end': 201.84, 'confidence': 0.966},\n",
       "   {'text': 'do', 'start': 201.84, 'end': 202.08, 'confidence': 0.998},\n",
       "   {'text': 'well', 'start': 202.08, 'end': 202.48, 'confidence': 0.72},\n",
       "   {'text': 'typical', 'start': 202.48, 'end': 202.86, 'confidence': 0.926},\n",
       "   {'text': 'tasks,', 'start': 202.86, 'end': 203.38, 'confidence': 0.995},\n",
       "   {'text': 'as', 'start': 203.56, 'end': 203.72, 'confidence': 0.998},\n",
       "   {'text': \"we've\", 'start': 203.72, 'end': 203.98, 'confidence': 0.999},\n",
       "   {'text': 'seen', 'start': 203.98, 'end': 204.12, 'confidence': 0.998},\n",
       "   {'text': 'with', 'start': 204.12, 'end': 204.28, 'confidence': 0.992},\n",
       "   {'text': 'the', 'start': 204.28, 'end': 204.38, 'confidence': 0.962},\n",
       "   {'text': 'self', 'start': 204.38, 'end': 204.54, 'confidence': 0.816},\n",
       "   {'text': 'driving', 'start': 204.54, 'end': 204.68, 'confidence': 0.877},\n",
       "   {'text': 'car', 'start': 204.68, 'end': 204.92, 'confidence': 0.992},\n",
       "   {'text': 'example', 'start': 204.92, 'end': 205.36, 'confidence': 0.995},\n",
       "   {'text': 'include', 'start': 205.36, 'end': 205.88, 'confidence': 0.964},\n",
       "   {'text': 'vision,', 'start': 205.88, 'end': 206.5, 'confidence': 0.965},\n",
       "   {'text': 'language', 'start': 206.98, 'end': 207.22, 'confidence': 0.992},\n",
       "   {'text': 'processing', 'start': 207.22, 'end': 207.7, 'confidence': 0.996},\n",
       "   {'text': 'and', 'start': 207.7, 'end': 208.12, 'confidence': 0.985},\n",
       "   {'text': 'planning.', 'start': 208.12, 'end': 208.5, 'confidence': 0.999}]},\n",
       " {'id': 30,\n",
       "  'seek': 19900,\n",
       "  'start': 208.78,\n",
       "  'end': 221.88,\n",
       "  'text': \" These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning.\",\n",
       "  'tokens': [50864,\n",
       "   1981,\n",
       "   366,\n",
       "   445,\n",
       "   257,\n",
       "   1916,\n",
       "   295,\n",
       "   5110,\n",
       "   13,\n",
       "   407,\n",
       "   11,\n",
       "   5201,\n",
       "   307,\n",
       "   516,\n",
       "   281,\n",
       "   312,\n",
       "   3701,\n",
       "   420,\n",
       "   4084,\n",
       "   5267,\n",
       "   420,\n",
       "   960,\n",
       "   2856,\n",
       "   9007,\n",
       "   11,\n",
       "   3701,\n",
       "   420,\n",
       "   4084,\n",
       "   6218,\n",
       "   420,\n",
       "   2487,\n",
       "   300,\n",
       "   311,\n",
       "   516,\n",
       "   281,\n",
       "   312,\n",
       "   411,\n",
       "   33682,\n",
       "   420,\n",
       "   6795,\n",
       "   22595,\n",
       "   293,\n",
       "   5038,\n",
       "   13,\n",
       "   51564],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.10106727744959577,\n",
       "  'compression_ratio': 1.7227272727272727,\n",
       "  'no_speech_prob': 0.04462442547082901,\n",
       "  'confidence': 0.962,\n",
       "  'words': [{'text': 'These',\n",
       "    'start': 208.78,\n",
       "    'end': 209.06,\n",
       "    'confidence': 0.85},\n",
       "   {'text': 'are', 'start': 209.06, 'end': 209.12, 'confidence': 1.0},\n",
       "   {'text': 'just', 'start': 209.12, 'end': 209.28, 'confidence': 1.0},\n",
       "   {'text': 'a', 'start': 209.28, 'end': 209.42, 'confidence': 1.0},\n",
       "   {'text': 'couple', 'start': 209.42, 'end': 209.62, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 209.62, 'end': 209.82, 'confidence': 1.0},\n",
       "   {'text': 'examples.', 'start': 209.82, 'end': 210.24, 'confidence': 0.999},\n",
       "   {'text': 'So,', 'start': 210.42, 'end': 211.02, 'confidence': 0.989},\n",
       "   {'text': 'vision', 'start': 211.1, 'end': 211.58, 'confidence': 0.95},\n",
       "   {'text': 'is', 'start': 211.58, 'end': 211.94, 'confidence': 0.944},\n",
       "   {'text': 'going', 'start': 211.94, 'end': 212.04, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 212.04, 'end': 212.16, 'confidence': 1.0},\n",
       "   {'text': 'be', 'start': 212.16, 'end': 212.48, 'confidence': 1.0},\n",
       "   {'text': 'understanding',\n",
       "    'start': 212.48,\n",
       "    'end': 213.08,\n",
       "    'confidence': 0.992},\n",
       "   {'text': 'or', 'start': 213.08, 'end': 213.36, 'confidence': 0.962},\n",
       "   {'text': 'creating', 'start': 213.36, 'end': 213.64, 'confidence': 0.998},\n",
       "   {'text': 'images', 'start': 213.64, 'end': 214.08, 'confidence': 0.999},\n",
       "   {'text': 'or', 'start': 214.08, 'end': 214.34, 'confidence': 0.995},\n",
       "   {'text': 'video', 'start': 214.34, 'end': 214.88, 'confidence': 0.996},\n",
       "   {'text': 'language', 'start': 214.88, 'end': 215.5, 'confidence': 0.858},\n",
       "   {'text': 'processing,', 'start': 215.5, 'end': 216.1, 'confidence': 0.998},\n",
       "   {'text': 'understanding',\n",
       "    'start': 216.44,\n",
       "    'end': 216.72,\n",
       "    'confidence': 0.992},\n",
       "   {'text': 'or', 'start': 216.72, 'end': 217.06, 'confidence': 0.668},\n",
       "   {'text': 'creating', 'start': 217.06, 'end': 217.4, 'confidence': 0.998},\n",
       "   {'text': 'speech', 'start': 217.4, 'end': 217.92, 'confidence': 0.998},\n",
       "   {'text': 'or', 'start': 217.92, 'end': 218.18, 'confidence': 0.99},\n",
       "   {'text': 'text', 'start': 218.18, 'end': 218.52, 'confidence': 0.969},\n",
       "   {'text': \"that's\", 'start': 218.52, 'end': 218.8, 'confidence': 0.949},\n",
       "   {'text': 'going', 'start': 218.8, 'end': 218.94, 'confidence': 0.99},\n",
       "   {'text': 'to', 'start': 218.94, 'end': 218.98, 'confidence': 0.999},\n",
       "   {'text': 'be', 'start': 218.98, 'end': 219.1, 'confidence': 0.999},\n",
       "   {'text': 'like', 'start': 219.1, 'end': 219.32, 'confidence': 0.997},\n",
       "   {'text': 'Siri', 'start': 219.32, 'end': 219.58, 'confidence': 0.959},\n",
       "   {'text': 'or', 'start': 219.58, 'end': 219.84, 'confidence': 0.996},\n",
       "   {'text': 'Amazon', 'start': 219.84, 'end': 220.1, 'confidence': 0.988},\n",
       "   {'text': 'Alexa', 'start': 220.1, 'end': 220.5, 'confidence': 0.998},\n",
       "   {'text': 'and', 'start': 220.5, 'end': 221.38, 'confidence': 0.696},\n",
       "   {'text': 'planning.',\n",
       "    'start': 221.38,\n",
       "    'end': 221.88,\n",
       "    'confidence': 0.988}]},\n",
       " {'id': 31,\n",
       "  'seek': 22300,\n",
       "  'start': 223.0,\n",
       "  'end': 227.26,\n",
       "  'text': \" So, there's a lot of different kinds of planning, you can do route planning motion planning task planning.\",\n",
       "  'tokens': [50364,\n",
       "   407,\n",
       "   11,\n",
       "   456,\n",
       "   311,\n",
       "   257,\n",
       "   688,\n",
       "   295,\n",
       "   819,\n",
       "   3685,\n",
       "   295,\n",
       "   5038,\n",
       "   11,\n",
       "   291,\n",
       "   393,\n",
       "   360,\n",
       "   7955,\n",
       "   5038,\n",
       "   5394,\n",
       "   5038,\n",
       "   5633,\n",
       "   5038,\n",
       "   13,\n",
       "   50664],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.18343359715229757,\n",
       "  'compression_ratio': 1.6958762886597938,\n",
       "  'no_speech_prob': 0.4756874144077301,\n",
       "  'confidence': 0.649,\n",
       "  'words': [{'text': 'So,',\n",
       "    'start': 223.0,\n",
       "    'end': 223.02,\n",
       "    'confidence': 0.237},\n",
       "   {'text': \"there's\", 'start': 223.02, 'end': 223.04, 'confidence': 0.259},\n",
       "   {'text': 'a', 'start': 223.04, 'end': 223.06, 'confidence': 0.399},\n",
       "   {'text': 'lot', 'start': 223.06, 'end': 223.08, 'confidence': 0.519},\n",
       "   {'text': 'of', 'start': 223.08, 'end': 223.1, 'confidence': 0.916},\n",
       "   {'text': 'different', 'start': 223.1, 'end': 223.12, 'confidence': 0.562},\n",
       "   {'text': 'kinds', 'start': 223.12, 'end': 223.14, 'confidence': 0.486},\n",
       "   {'text': 'of', 'start': 223.14, 'end': 223.28, 'confidence': 0.998},\n",
       "   {'text': 'planning,', 'start': 223.28, 'end': 223.58, 'confidence': 0.894},\n",
       "   {'text': 'you', 'start': 224.0, 'end': 224.02, 'confidence': 0.984},\n",
       "   {'text': 'can', 'start': 224.02, 'end': 224.16, 'confidence': 0.998},\n",
       "   {'text': 'do', 'start': 224.16, 'end': 224.3, 'confidence': 0.997},\n",
       "   {'text': 'route', 'start': 224.3, 'end': 224.62, 'confidence': 0.982},\n",
       "   {'text': 'planning', 'start': 224.62, 'end': 225.04, 'confidence': 0.99},\n",
       "   {'text': 'motion', 'start': 225.04, 'end': 225.48, 'confidence': 0.54},\n",
       "   {'text': 'planning', 'start': 225.48, 'end': 226.08, 'confidence': 0.996},\n",
       "   {'text': 'task', 'start': 226.08, 'end': 226.72, 'confidence': 0.729},\n",
       "   {'text': 'planning.',\n",
       "    'start': 226.72,\n",
       "    'end': 227.26,\n",
       "    'confidence': 0.996}]},\n",
       " {'id': 32,\n",
       "  'seek': 22300,\n",
       "  'start': 228.5,\n",
       "  'end': 233.82,\n",
       "  'text': ' All these things fall under the category of narrow AI tasks that you can train an algorithm to do.',\n",
       "  'tokens': [50664,\n",
       "   1057,\n",
       "   613,\n",
       "   721,\n",
       "   2100,\n",
       "   833,\n",
       "   264,\n",
       "   7719,\n",
       "   295,\n",
       "   9432,\n",
       "   7318,\n",
       "   9608,\n",
       "   300,\n",
       "   291,\n",
       "   393,\n",
       "   3847,\n",
       "   364,\n",
       "   9284,\n",
       "   281,\n",
       "   360,\n",
       "   13,\n",
       "   50964],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.18343359715229757,\n",
       "  'compression_ratio': 1.6958762886597938,\n",
       "  'no_speech_prob': 0.4756874144077301,\n",
       "  'confidence': 0.986,\n",
       "  'words': [{'text': 'All',\n",
       "    'start': 228.5,\n",
       "    'end': 228.58,\n",
       "    'confidence': 0.948},\n",
       "   {'text': 'these', 'start': 228.58, 'end': 228.78, 'confidence': 0.991},\n",
       "   {'text': 'things', 'start': 228.78, 'end': 229.26, 'confidence': 0.998},\n",
       "   {'text': 'fall', 'start': 229.26, 'end': 229.64, 'confidence': 0.987},\n",
       "   {'text': 'under', 'start': 229.64, 'end': 229.84, 'confidence': 0.994},\n",
       "   {'text': 'the', 'start': 229.84, 'end': 230.04, 'confidence': 0.999},\n",
       "   {'text': 'category', 'start': 230.04, 'end': 230.34, 'confidence': 0.999},\n",
       "   {'text': 'of', 'start': 230.34, 'end': 230.74, 'confidence': 0.999},\n",
       "   {'text': 'narrow', 'start': 230.74, 'end': 231.08, 'confidence': 0.984},\n",
       "   {'text': 'AI', 'start': 231.08, 'end': 231.48, 'confidence': 0.937},\n",
       "   {'text': 'tasks', 'start': 231.48, 'end': 232.0, 'confidence': 0.996},\n",
       "   {'text': 'that', 'start': 232.0, 'end': 232.2, 'confidence': 0.994},\n",
       "   {'text': 'you', 'start': 232.2, 'end': 232.3, 'confidence': 1.0},\n",
       "   {'text': 'can', 'start': 232.3, 'end': 232.44, 'confidence': 0.997},\n",
       "   {'text': 'train', 'start': 232.44, 'end': 232.58, 'confidence': 0.996},\n",
       "   {'text': 'an', 'start': 232.58, 'end': 232.74, 'confidence': 0.932},\n",
       "   {'text': 'algorithm', 'start': 232.74, 'end': 232.96, 'confidence': 0.999},\n",
       "   {'text': 'to', 'start': 232.96, 'end': 233.14, 'confidence': 0.998},\n",
       "   {'text': 'do.', 'start': 233.14, 'end': 233.82, 'confidence': 0.998}]},\n",
       " {'id': 33,\n",
       "  'seek': 22300,\n",
       "  'start': 234.5,\n",
       "  'end': 242.92,\n",
       "  'text': \" As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence.\",\n",
       "  'tokens': [50964,\n",
       "   1018,\n",
       "   1400,\n",
       "   382,\n",
       "   577,\n",
       "   321,\n",
       "   767,\n",
       "   1322,\n",
       "   7318,\n",
       "   13,\n",
       "   821,\n",
       "   311,\n",
       "   257,\n",
       "   688,\n",
       "   295,\n",
       "   819,\n",
       "   2098,\n",
       "   281,\n",
       "   13735,\n",
       "   2098,\n",
       "   281,\n",
       "   4445,\n",
       "   11677,\n",
       "   7599,\n",
       "   13,\n",
       "   51414],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.18343359715229757,\n",
       "  'compression_ratio': 1.6958762886597938,\n",
       "  'no_speech_prob': 0.4756874144077301,\n",
       "  'confidence': 0.984,\n",
       "  'words': [{'text': 'As', 'start': 234.5, 'end': 235.02, 'confidence': 0.924},\n",
       "   {'text': 'far', 'start': 235.02, 'end': 235.18, 'confidence': 0.999},\n",
       "   {'text': 'as', 'start': 235.18, 'end': 235.28, 'confidence': 1.0},\n",
       "   {'text': 'how', 'start': 235.28, 'end': 235.44, 'confidence': 0.999},\n",
       "   {'text': 'we', 'start': 235.44, 'end': 235.62, 'confidence': 1.0},\n",
       "   {'text': 'actually', 'start': 235.62, 'end': 235.98, 'confidence': 1.0},\n",
       "   {'text': 'build', 'start': 235.98, 'end': 236.38, 'confidence': 0.989},\n",
       "   {'text': 'AI.', 'start': 236.38, 'end': 236.8, 'confidence': 0.918},\n",
       "   {'text': \"There's\", 'start': 237.18, 'end': 237.28, 'confidence': 0.987},\n",
       "   {'text': 'a', 'start': 237.28, 'end': 237.38, 'confidence': 1.0},\n",
       "   {'text': 'lot', 'start': 237.38, 'end': 237.48, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 237.48, 'end': 237.6, 'confidence': 0.999},\n",
       "   {'text': 'different', 'start': 237.6, 'end': 237.72, 'confidence': 0.998},\n",
       "   {'text': 'ways', 'start': 237.72, 'end': 238.28, 'confidence': 0.959},\n",
       "   {'text': 'to', 'start': 238.28, 'end': 239.98, 'confidence': 0.933},\n",
       "   {'text': 'classical', 'start': 239.98, 'end': 241.04, 'confidence': 0.991},\n",
       "   {'text': 'ways', 'start': 241.04, 'end': 241.4, 'confidence': 0.996},\n",
       "   {'text': 'to', 'start': 241.4, 'end': 241.58, 'confidence': 0.997},\n",
       "   {'text': 'implement', 'start': 241.58, 'end': 241.82, 'confidence': 0.996},\n",
       "   {'text': 'artificial', 'start': 241.82, 'end': 242.26, 'confidence': 0.984},\n",
       "   {'text': 'intelligence.',\n",
       "    'start': 242.26,\n",
       "    'end': 242.92,\n",
       "    'confidence': 0.999}]},\n",
       " {'id': 34,\n",
       "  'seek': 24400,\n",
       "  'start': 244.0,\n",
       "  'end': 256.12,\n",
       "  'text': \" So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that.\",\n",
       "  'tokens': [50364,\n",
       "   407,\n",
       "   11,\n",
       "   264,\n",
       "   721,\n",
       "   300,\n",
       "   321,\n",
       "   434,\n",
       "   2539,\n",
       "   466,\n",
       "   341,\n",
       "   293,\n",
       "   885,\n",
       "   411,\n",
       "   6076,\n",
       "   341,\n",
       "   307,\n",
       "   406,\n",
       "   13232,\n",
       "   412,\n",
       "   439,\n",
       "   341,\n",
       "   307,\n",
       "   1687,\n",
       "   10316,\n",
       "   366,\n",
       "   5844,\n",
       "   3652,\n",
       "   293,\n",
       "   4230,\n",
       "   3164,\n",
       "   13,\n",
       "   407,\n",
       "   294,\n",
       "   364,\n",
       "   5844,\n",
       "   1185,\n",
       "   11,\n",
       "   309,\n",
       "   311,\n",
       "   445,\n",
       "   257,\n",
       "   954,\n",
       "   3579,\n",
       "   257,\n",
       "   1329,\n",
       "   295,\n",
       "   4474,\n",
       "   11,\n",
       "   498,\n",
       "   341,\n",
       "   813,\n",
       "   300,\n",
       "   11,\n",
       "   498,\n",
       "   341,\n",
       "   813,\n",
       "   300,\n",
       "   13,\n",
       "   51064],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.19118458462744645,\n",
       "  'compression_ratio': 1.7457627118644068,\n",
       "  'no_speech_prob': 0.5146414041519165,\n",
       "  'confidence': 0.789,\n",
       "  'words': [{'text': 'So,',\n",
       "    'start': 244.0,\n",
       "    'end': 244.02,\n",
       "    'confidence': 0.165},\n",
       "   {'text': 'the', 'start': 244.02, 'end': 244.04, 'confidence': 0.127},\n",
       "   {'text': 'things', 'start': 244.04, 'end': 244.06, 'confidence': 0.133},\n",
       "   {'text': 'that', 'start': 244.06, 'end': 244.08, 'confidence': 0.679},\n",
       "   {'text': \"we're\", 'start': 244.08, 'end': 244.1, 'confidence': 0.713},\n",
       "   {'text': 'learning', 'start': 244.1, 'end': 244.46, 'confidence': 0.936},\n",
       "   {'text': 'about', 'start': 244.46, 'end': 244.68, 'confidence': 0.996},\n",
       "   {'text': 'this', 'start': 244.68, 'end': 244.84, 'confidence': 0.987},\n",
       "   {'text': 'and', 'start': 244.84, 'end': 244.94, 'confidence': 0.989},\n",
       "   {'text': 'being', 'start': 244.94, 'end': 245.04, 'confidence': 0.992},\n",
       "   {'text': 'like', 'start': 245.04, 'end': 245.16, 'confidence': 0.999},\n",
       "   {'text': 'wow', 'start': 245.16, 'end': 245.34, 'confidence': 0.672},\n",
       "   {'text': 'this', 'start': 245.34, 'end': 245.5, 'confidence': 0.881},\n",
       "   {'text': 'is', 'start': 245.5, 'end': 245.64, 'confidence': 0.997},\n",
       "   {'text': 'not', 'start': 245.64, 'end': 245.78, 'confidence': 0.998},\n",
       "   {'text': 'intelligent', 'start': 245.78, 'end': 246.08, 'confidence': 0.78},\n",
       "   {'text': 'at', 'start': 246.08, 'end': 246.24, 'confidence': 0.97},\n",
       "   {'text': 'all', 'start': 246.24, 'end': 246.32, 'confidence': 0.999},\n",
       "   {'text': 'this', 'start': 246.32, 'end': 246.54, 'confidence': 0.807},\n",
       "   {'text': 'is', 'start': 246.54, 'end': 246.74, 'confidence': 0.711},\n",
       "   {'text': 'super', 'start': 246.74, 'end': 246.9, 'confidence': 0.996},\n",
       "   {'text': 'dumb', 'start': 246.9, 'end': 247.52, 'confidence': 0.987},\n",
       "   {'text': 'are', 'start': 247.52, 'end': 248.32, 'confidence': 0.478},\n",
       "   {'text': 'expert', 'start': 248.32, 'end': 248.8, 'confidence': 0.985},\n",
       "   {'text': 'systems', 'start': 248.8, 'end': 249.14, 'confidence': 0.998},\n",
       "   {'text': 'and', 'start': 249.14, 'end': 249.44, 'confidence': 0.995},\n",
       "   {'text': 'tree', 'start': 249.44, 'end': 249.64, 'confidence': 0.742},\n",
       "   {'text': 'search.', 'start': 249.64, 'end': 249.88, 'confidence': 0.996},\n",
       "   {'text': 'So', 'start': 250.26, 'end': 250.28, 'confidence': 0.806},\n",
       "   {'text': 'in', 'start': 250.28, 'end': 250.44, 'confidence': 0.82},\n",
       "   {'text': 'an', 'start': 250.44, 'end': 250.62, 'confidence': 0.998},\n",
       "   {'text': 'expert', 'start': 250.62, 'end': 250.9, 'confidence': 0.999},\n",
       "   {'text': 'system,', 'start': 250.9, 'end': 251.3, 'confidence': 0.999},\n",
       "   {'text': \"it's\", 'start': 251.62, 'end': 251.66, 'confidence': 0.986},\n",
       "   {'text': 'just', 'start': 251.66, 'end': 251.9, 'confidence': 0.999},\n",
       "   {'text': 'a', 'start': 251.9, 'end': 252.12, 'confidence': 0.999},\n",
       "   {'text': 'person', 'start': 252.12, 'end': 252.46, 'confidence': 0.999},\n",
       "   {'text': 'writing', 'start': 252.46, 'end': 252.74, 'confidence': 0.954},\n",
       "   {'text': 'a', 'start': 252.74, 'end': 252.88, 'confidence': 0.867},\n",
       "   {'text': 'list', 'start': 252.88, 'end': 253.02, 'confidence': 0.995},\n",
       "   {'text': 'of', 'start': 253.02, 'end': 253.14, 'confidence': 0.999},\n",
       "   {'text': 'rules,', 'start': 253.14, 'end': 253.42, 'confidence': 0.995},\n",
       "   {'text': 'if', 'start': 253.68, 'end': 253.86, 'confidence': 0.984},\n",
       "   {'text': 'this', 'start': 253.86, 'end': 254.06, 'confidence': 0.998},\n",
       "   {'text': 'than', 'start': 254.06, 'end': 254.32, 'confidence': 0.307},\n",
       "   {'text': 'that,', 'start': 254.32, 'end': 254.6, 'confidence': 0.99},\n",
       "   {'text': 'if', 'start': 254.82, 'end': 254.98, 'confidence': 0.98},\n",
       "   {'text': 'this', 'start': 254.98, 'end': 255.32, 'confidence': 0.994},\n",
       "   {'text': 'than', 'start': 255.32, 'end': 255.52, 'confidence': 0.384},\n",
       "   {'text': 'that.', 'start': 255.52, 'end': 256.12, 'confidence': 0.982}]},\n",
       " {'id': 35,\n",
       "  'seek': 24400,\n",
       "  'start': 257.5,\n",
       "  'end': 260.66,\n",
       "  'text': ' This can be super useful for certain problems.',\n",
       "  'tokens': [51064, 639, 393, 312, 1687, 4420, 337, 1629, 2740, 13, 51314],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.19118458462744645,\n",
       "  'compression_ratio': 1.7457627118644068,\n",
       "  'no_speech_prob': 0.5146414041519165,\n",
       "  'confidence': 0.977,\n",
       "  'words': [{'text': 'This',\n",
       "    'start': 257.5,\n",
       "    'end': 257.52,\n",
       "    'confidence': 0.856},\n",
       "   {'text': 'can', 'start': 257.52, 'end': 257.54, 'confidence': 0.975},\n",
       "   {'text': 'be', 'start': 257.54, 'end': 257.66, 'confidence': 1.0},\n",
       "   {'text': 'super', 'start': 257.66, 'end': 257.88, 'confidence': 0.999},\n",
       "   {'text': 'useful', 'start': 257.88, 'end': 258.4, 'confidence': 0.999},\n",
       "   {'text': 'for', 'start': 258.4, 'end': 259.42, 'confidence': 0.997},\n",
       "   {'text': 'certain', 'start': 259.42, 'end': 260.04, 'confidence': 1.0},\n",
       "   {'text': 'problems.',\n",
       "    'start': 260.04,\n",
       "    'end': 260.66,\n",
       "    'confidence': 0.998}]},\n",
       " {'id': 36,\n",
       "  'seek': 24400,\n",
       "  'start': 262.7,\n",
       "  'end': 267.82,\n",
       "  'text': ' But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult.',\n",
       "  'tokens': [51314,\n",
       "   583,\n",
       "   257,\n",
       "   688,\n",
       "   295,\n",
       "   264,\n",
       "   721,\n",
       "   300,\n",
       "   321,\n",
       "   767,\n",
       "   519,\n",
       "   295,\n",
       "   382,\n",
       "   534,\n",
       "   15325,\n",
       "   11,\n",
       "   1261,\n",
       "   484,\n",
       "   281,\n",
       "   312,\n",
       "   1596,\n",
       "   2252,\n",
       "   13,\n",
       "   51614],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.19118458462744645,\n",
       "  'compression_ratio': 1.7457627118644068,\n",
       "  'no_speech_prob': 0.5146414041519165,\n",
       "  'confidence': 0.938,\n",
       "  'words': [{'text': 'But',\n",
       "    'start': 262.7,\n",
       "    'end': 263.16,\n",
       "    'confidence': 0.585},\n",
       "   {'text': 'a', 'start': 263.16, 'end': 263.64, 'confidence': 0.883},\n",
       "   {'text': 'lot', 'start': 263.64, 'end': 263.82, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 263.82, 'end': 263.94, 'confidence': 1.0},\n",
       "   {'text': 'the', 'start': 263.94, 'end': 264.02, 'confidence': 0.996},\n",
       "   {'text': 'things', 'start': 264.02, 'end': 264.16, 'confidence': 1.0},\n",
       "   {'text': 'that', 'start': 264.16, 'end': 264.34, 'confidence': 1.0},\n",
       "   {'text': 'we', 'start': 264.34, 'end': 264.56, 'confidence': 1.0},\n",
       "   {'text': 'actually', 'start': 264.56, 'end': 264.76, 'confidence': 1.0},\n",
       "   {'text': 'think', 'start': 264.76, 'end': 264.96, 'confidence': 1.0},\n",
       "   {'text': 'of', 'start': 264.96, 'end': 265.1, 'confidence': 0.976},\n",
       "   {'text': 'as', 'start': 265.1, 'end': 265.24, 'confidence': 0.742},\n",
       "   {'text': 'really', 'start': 265.24, 'end': 265.62, 'confidence': 1.0},\n",
       "   {'text': 'straightforward,',\n",
       "    'start': 265.62,\n",
       "    'end': 266.42,\n",
       "    'confidence': 0.988},\n",
       "   {'text': 'turn', 'start': 266.88, 'end': 266.96, 'confidence': 0.758},\n",
       "   {'text': 'out', 'start': 266.96, 'end': 267.04, 'confidence': 0.998},\n",
       "   {'text': 'to', 'start': 267.04, 'end': 267.12, 'confidence': 1.0},\n",
       "   {'text': 'be', 'start': 267.12, 'end': 267.2, 'confidence': 1.0},\n",
       "   {'text': 'quite', 'start': 267.2, 'end': 267.36, 'confidence': 0.999},\n",
       "   {'text': 'difficult.',\n",
       "    'start': 267.36,\n",
       "    'end': 267.82,\n",
       "    'confidence': 0.993}]},\n",
       " {'id': 37,\n",
       "  'seek': 26900,\n",
       "  'start': 269.0,\n",
       "  'end': 269.64,\n",
       "  'text': ' So, for example,',\n",
       "  'tokens': [50364, 407, 11, 337, 1365, 11, 50564],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.14944950309959618,\n",
       "  'compression_ratio': 1.4850299401197604,\n",
       "  'no_speech_prob': 0.5834770798683167,\n",
       "  'confidence': 0.543,\n",
       "  'words': [{'text': 'So,', 'start': 269.0, 'end': 269.02, 'confidence': 0.38},\n",
       "   {'text': 'for', 'start': 269.26, 'end': 269.28, 'confidence': 0.433},\n",
       "   {'text': 'example,', 'start': 269.28, 'end': 269.64, 'confidence': 0.975}]},\n",
       " {'id': 38,\n",
       "  'seek': 26900,\n",
       "  'start': 272.5,\n",
       "  'end': 277.2,\n",
       "  'text': ' we can identify a table like that. Very, very easily. We know what a table is.',\n",
       "  'tokens': [50564,\n",
       "   321,\n",
       "   393,\n",
       "   5876,\n",
       "   257,\n",
       "   3199,\n",
       "   411,\n",
       "   300,\n",
       "   13,\n",
       "   4372,\n",
       "   11,\n",
       "   588,\n",
       "   3612,\n",
       "   13,\n",
       "   492,\n",
       "   458,\n",
       "   437,\n",
       "   257,\n",
       "   3199,\n",
       "   307,\n",
       "   13,\n",
       "   50814],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.14944950309959618,\n",
       "  'compression_ratio': 1.4850299401197604,\n",
       "  'no_speech_prob': 0.5834770798683167,\n",
       "  'confidence': 0.914,\n",
       "  'words': [{'text': 'we', 'start': 272.5, 'end': 272.82, 'confidence': 0.744},\n",
       "   {'text': 'can', 'start': 272.82, 'end': 273.02, 'confidence': 0.912},\n",
       "   {'text': 'identify', 'start': 273.02, 'end': 273.28, 'confidence': 0.996},\n",
       "   {'text': 'a', 'start': 273.28, 'end': 273.92, 'confidence': 0.749},\n",
       "   {'text': 'table', 'start': 273.92, 'end': 273.94, 'confidence': 0.998},\n",
       "   {'text': 'like', 'start': 273.94, 'end': 274.66, 'confidence': 0.755},\n",
       "   {'text': 'that.', 'start': 274.66, 'end': 274.98, 'confidence': 0.999},\n",
       "   {'text': 'Very,', 'start': 275.24, 'end': 275.5, 'confidence': 0.93},\n",
       "   {'text': 'very', 'start': 275.5, 'end': 275.68, 'confidence': 0.998},\n",
       "   {'text': 'easily.', 'start': 275.68, 'end': 276.0, 'confidence': 0.991},\n",
       "   {'text': 'We', 'start': 276.32, 'end': 276.38, 'confidence': 0.95},\n",
       "   {'text': 'know', 'start': 276.38, 'end': 276.46, 'confidence': 0.957},\n",
       "   {'text': 'what', 'start': 276.46, 'end': 276.56, 'confidence': 0.921},\n",
       "   {'text': 'a', 'start': 276.56, 'end': 276.64, 'confidence': 0.822},\n",
       "   {'text': 'table', 'start': 276.64, 'end': 276.82, 'confidence': 0.997},\n",
       "   {'text': 'is.', 'start': 276.82, 'end': 277.2, 'confidence': 0.991}]},\n",
       " {'id': 39,\n",
       "  'seek': 26900,\n",
       "  'start': 277.58,\n",
       "  'end': 282.16,\n",
       "  'text': ' But I challenge you to write a list of rules that can define a table.',\n",
       "  'tokens': [50814,\n",
       "   583,\n",
       "   286,\n",
       "   3430,\n",
       "   291,\n",
       "   281,\n",
       "   2464,\n",
       "   257,\n",
       "   1329,\n",
       "   295,\n",
       "   4474,\n",
       "   300,\n",
       "   393,\n",
       "   6964,\n",
       "   257,\n",
       "   3199,\n",
       "   13,\n",
       "   51064],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.14944950309959618,\n",
       "  'compression_ratio': 1.4850299401197604,\n",
       "  'no_speech_prob': 0.5834770798683167,\n",
       "  'confidence': 0.976,\n",
       "  'words': [{'text': 'But',\n",
       "    'start': 277.58,\n",
       "    'end': 278.38,\n",
       "    'confidence': 0.983},\n",
       "   {'text': 'I', 'start': 278.38, 'end': 278.96, 'confidence': 0.924},\n",
       "   {'text': 'challenge', 'start': 278.96, 'end': 279.44, 'confidence': 0.961},\n",
       "   {'text': 'you', 'start': 279.44, 'end': 279.88, 'confidence': 0.993},\n",
       "   {'text': 'to', 'start': 279.88, 'end': 280.16, 'confidence': 0.995},\n",
       "   {'text': 'write', 'start': 280.16, 'end': 280.32, 'confidence': 0.999},\n",
       "   {'text': 'a', 'start': 280.32, 'end': 280.46, 'confidence': 0.998},\n",
       "   {'text': 'list', 'start': 280.46, 'end': 280.6, 'confidence': 0.999},\n",
       "   {'text': 'of', 'start': 280.6, 'end': 280.78, 'confidence': 1.0},\n",
       "   {'text': 'rules', 'start': 280.78, 'end': 281.06, 'confidence': 0.814},\n",
       "   {'text': 'that', 'start': 281.06, 'end': 281.28, 'confidence': 0.999},\n",
       "   {'text': 'can', 'start': 281.28, 'end': 281.44, 'confidence': 0.999},\n",
       "   {'text': 'define', 'start': 281.44, 'end': 281.68, 'confidence': 0.998},\n",
       "   {'text': 'a', 'start': 281.68, 'end': 281.86, 'confidence': 0.994},\n",
       "   {'text': 'table.', 'start': 281.86, 'end': 282.16, 'confidence': 0.999}]},\n",
       " {'id': 40,\n",
       "  'seek': 26900,\n",
       "  'start': 282.5,\n",
       "  'end': 286.72,\n",
       "  'text': \" What color is it, what's it made of, how many legs does it have, what shape is it.\",\n",
       "  'tokens': [51064,\n",
       "   708,\n",
       "   2017,\n",
       "   307,\n",
       "   309,\n",
       "   11,\n",
       "   437,\n",
       "   311,\n",
       "   309,\n",
       "   1027,\n",
       "   295,\n",
       "   11,\n",
       "   577,\n",
       "   867,\n",
       "   5668,\n",
       "   775,\n",
       "   309,\n",
       "   362,\n",
       "   11,\n",
       "   437,\n",
       "   3909,\n",
       "   307,\n",
       "   309,\n",
       "   13,\n",
       "   51414],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.14944950309959618,\n",
       "  'compression_ratio': 1.4850299401197604,\n",
       "  'no_speech_prob': 0.5834770798683167,\n",
       "  'confidence': 0.967,\n",
       "  'words': [{'text': 'What',\n",
       "    'start': 282.5,\n",
       "    'end': 283.2,\n",
       "    'confidence': 0.975},\n",
       "   {'text': 'color', 'start': 283.2, 'end': 283.42, 'confidence': 0.976},\n",
       "   {'text': 'is', 'start': 283.42, 'end': 283.6, 'confidence': 0.975},\n",
       "   {'text': 'it,', 'start': 283.6, 'end': 283.82, 'confidence': 0.997},\n",
       "   {'text': \"what's\", 'start': 283.92, 'end': 284.08, 'confidence': 0.97},\n",
       "   {'text': 'it', 'start': 284.08, 'end': 284.18, 'confidence': 0.993},\n",
       "   {'text': 'made', 'start': 284.18, 'end': 284.32, 'confidence': 0.999},\n",
       "   {'text': 'of,', 'start': 284.32, 'end': 284.52, 'confidence': 0.983},\n",
       "   {'text': 'how', 'start': 284.62, 'end': 284.74, 'confidence': 0.992},\n",
       "   {'text': 'many', 'start': 284.74, 'end': 284.86, 'confidence': 0.999},\n",
       "   {'text': 'legs', 'start': 284.86, 'end': 285.06, 'confidence': 0.861},\n",
       "   {'text': 'does', 'start': 285.06, 'end': 285.2, 'confidence': 0.84},\n",
       "   {'text': 'it', 'start': 285.2, 'end': 285.32, 'confidence': 0.988},\n",
       "   {'text': 'have,', 'start': 285.32, 'end': 285.54, 'confidence': 0.961},\n",
       "   {'text': 'what', 'start': 285.74, 'end': 285.8, 'confidence': 0.984},\n",
       "   {'text': 'shape', 'start': 285.8, 'end': 286.02, 'confidence': 0.996},\n",
       "   {'text': 'is', 'start': 286.02, 'end': 286.24, 'confidence': 0.959},\n",
       "   {'text': 'it.', 'start': 286.24, 'end': 286.72, 'confidence': 0.976}]},\n",
       " {'id': 41,\n",
       "  'seek': 29000,\n",
       "  'start': 290.0,\n",
       "  'end': 300.38,\n",
       "  'text': ' And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.',\n",
       "  'tokens': [50364,\n",
       "   400,\n",
       "   754,\n",
       "   746,\n",
       "   411,\n",
       "   437,\n",
       "   307,\n",
       "   257,\n",
       "   3199,\n",
       "   3643,\n",
       "   534,\n",
       "   11,\n",
       "   534,\n",
       "   7595,\n",
       "   281,\n",
       "   1867,\n",
       "   1228,\n",
       "   364,\n",
       "   5844,\n",
       "   1185,\n",
       "   13,\n",
       "   407,\n",
       "   613,\n",
       "   393,\n",
       "   312,\n",
       "   534,\n",
       "   4961,\n",
       "   293,\n",
       "   456,\n",
       "   366,\n",
       "   512,\n",
       "   2199,\n",
       "   2098,\n",
       "   11,\n",
       "   420,\n",
       "   2831,\n",
       "   11,\n",
       "   456,\n",
       "   366,\n",
       "   512,\n",
       "   2740,\n",
       "   300,\n",
       "   321,\n",
       "   393,\n",
       "   360,\n",
       "   281,\n",
       "   5039,\n",
       "   613,\n",
       "   2740,\n",
       "   13,\n",
       "   50864],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3960122328538161,\n",
       "  'compression_ratio': 1.5870967741935484,\n",
       "  'no_speech_prob': 0.8920807242393494,\n",
       "  'confidence': 0.685,\n",
       "  'words': [{'text': 'And',\n",
       "    'start': 290.0,\n",
       "    'end': 290.06,\n",
       "    'confidence': 0.215},\n",
       "   {'text': 'even', 'start': 290.06, 'end': 290.32, 'confidence': 0.349},\n",
       "   {'text': 'something', 'start': 290.32, 'end': 290.68, 'confidence': 0.976},\n",
       "   {'text': 'like', 'start': 290.68, 'end': 291.04, 'confidence': 0.992},\n",
       "   {'text': 'what', 'start': 291.04, 'end': 291.3, 'confidence': 0.786},\n",
       "   {'text': 'is', 'start': 291.3, 'end': 291.46, 'confidence': 0.937},\n",
       "   {'text': 'a', 'start': 291.46, 'end': 291.54, 'confidence': 0.949},\n",
       "   {'text': 'table', 'start': 291.54, 'end': 291.84, 'confidence': 0.998},\n",
       "   {'text': 'becomes', 'start': 291.84, 'end': 292.18, 'confidence': 0.914},\n",
       "   {'text': 'really,', 'start': 292.18, 'end': 292.58, 'confidence': 0.945},\n",
       "   {'text': 'really', 'start': 292.58, 'end': 292.82, 'confidence': 0.991},\n",
       "   {'text': 'challenging', 'start': 292.82, 'end': 293.34, 'confidence': 0.99},\n",
       "   {'text': 'to', 'start': 293.34, 'end': 294.02, 'confidence': 0.978},\n",
       "   {'text': 'answer', 'start': 294.02, 'end': 294.46, 'confidence': 0.997},\n",
       "   {'text': 'using', 'start': 294.46, 'end': 294.82, 'confidence': 0.88},\n",
       "   {'text': 'an', 'start': 294.82, 'end': 294.98, 'confidence': 0.958},\n",
       "   {'text': 'expert', 'start': 294.98, 'end': 295.18, 'confidence': 0.996},\n",
       "   {'text': 'system.', 'start': 295.18, 'end': 295.54, 'confidence': 0.997},\n",
       "   {'text': 'So', 'start': 295.86, 'end': 296.02, 'confidence': 0.689},\n",
       "   {'text': 'these', 'start': 296.02, 'end': 296.16, 'confidence': 0.873},\n",
       "   {'text': 'can', 'start': 296.16, 'end': 296.3, 'confidence': 0.988},\n",
       "   {'text': 'be', 'start': 296.3, 'end': 296.42, 'confidence': 0.998},\n",
       "   {'text': 'really', 'start': 296.42, 'end': 296.6, 'confidence': 0.995},\n",
       "   {'text': 'helpful', 'start': 296.6, 'end': 296.88, 'confidence': 0.998},\n",
       "   {'text': 'and', 'start': 296.88, 'end': 297.06, 'confidence': 0.827},\n",
       "   {'text': 'there', 'start': 297.06, 'end': 297.18, 'confidence': 0.995},\n",
       "   {'text': 'are', 'start': 297.18, 'end': 297.36, 'confidence': 0.997},\n",
       "   {'text': 'some', 'start': 297.36, 'end': 297.64, 'confidence': 0.997},\n",
       "   {'text': 'simple', 'start': 297.64, 'end': 298.2, 'confidence': 0.985},\n",
       "   {'text': 'ways,', 'start': 298.2, 'end': 298.74, 'confidence': 0.994},\n",
       "   {'text': 'or', 'start': 298.92, 'end': 298.96, 'confidence': 0.556},\n",
       "   {'text': 'rather,', 'start': 298.96, 'end': 299.14, 'confidence': 0.781},\n",
       "   {'text': 'there', 'start': 299.28, 'end': 299.46, 'confidence': 0.984},\n",
       "   {'text': 'are', 'start': 299.46, 'end': 299.64, 'confidence': 0.998},\n",
       "   {'text': 'some', 'start': 299.64, 'end': 299.86, 'confidence': 0.997},\n",
       "   {'text': 'problems', 'start': 299.86, 'end': 300.22, 'confidence': 0.823},\n",
       "   {'text': 'that', 'start': 300.22, 'end': 300.24, 'confidence': 0.341},\n",
       "   {'text': 'we', 'start': 300.24, 'end': 300.26, 'confidence': 0.305},\n",
       "   {'text': 'can', 'start': 300.26, 'end': 300.28, 'confidence': 0.432},\n",
       "   {'text': 'do', 'start': 300.28, 'end': 300.3, 'confidence': 0.122},\n",
       "   {'text': 'to', 'start': 300.3, 'end': 300.32, 'confidence': 0.253},\n",
       "   {'text': 'solve', 'start': 300.32, 'end': 300.34, 'confidence': 0.112},\n",
       "   {'text': 'these', 'start': 300.34, 'end': 300.36, 'confidence': 0.22},\n",
       "   {'text': 'problems.',\n",
       "    'start': 300.36,\n",
       "    'end': 300.38,\n",
       "    'confidence': 0.301}]}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"segments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def generate_timestamps(sections, word_data):\n",
    "    timestamps = []\n",
    "    word_index = 0\n",
    "    words_time = []\n",
    "    for segment in word_data[\"segments\"]:\n",
    "        words_time.extend(segment[\"words\"])\n",
    "    \n",
    "    for section in sections:\n",
    "        # Generate summaries for each section\n",
    "        summarize_short_prompt = f\"\"\"<|start_header_id|>user<|end_header_id|>\n",
    "   \n",
    "<instruction>Summarise the following transcript into a few words: <transcript>{section}</transcript></instruction><|eot_id|> \n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "<summary>\"\"\"\n",
    "        summary_short = llm.generate(summarize_short_prompt)\n",
    "        summary_short = summary_short.replace(\"</summary>\", \"\")\n",
    "\n",
    "        # Generate summaries for each section\n",
    "        summarize_full_prompt = f\"\"\"<|start_header_id|>user<|end_header_id|>\n",
    "   \n",
    "<instruction>Summarise the following transcript: <transcript>{section}</transcript></instruction><|eot_id|> \n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "<summary>\"\"\"\n",
    "        summary_full = llm.generate(summarize_full_prompt)\n",
    "        summary_full = summary_full.replace(\"</summary>\", \"\")\n",
    "\n",
    "        # Get start and end times for each section\n",
    "        words = section.split()\n",
    "        section_start = None\n",
    "        section_end = None\n",
    "        \n",
    "        for word in words:\n",
    "            while word_index < len(words_time):\n",
    "                current_word = words_time[word_index]\n",
    "                if current_word['text'].lower().strip(string.punctuation) == word.lower().strip(string.punctuation):\n",
    "                    if section_start is None:\n",
    "                        section_start = current_word['start']\n",
    "                    section_end = current_word['end']\n",
    "                    word_index += 1\n",
    "                    break\n",
    "                word_index += 1\n",
    "        \n",
    "        if section_start is not None and section_end is not None:\n",
    "            timestamps.append({\"timestamps\": (section_start, section_end), \"text\": section, \"summary_short\": summary_short, \"summary_full\": summary_full})\n",
    "        else:\n",
    "            timestamps.append({\"timestamps\": (None, None), \"text\": section, \"summary_short\": summary_short, \"summary_full\": summary_full})\n",
    "    \n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      70.27 ms /    11 runs   (    6.39 ms per token,   156.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     108.91 ms /    85 tokens (    1.28 ms per token,   780.48 tokens per second)\n",
      "llama_print_timings:        eval time =     162.01 ms /    10 runs   (   16.20 ms per token,    61.72 tokens per second)\n",
      "llama_print_timings:       total time =     349.19 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-0aef0ad5-ad2b-4ce3-903c-99d87ec3930d', 'object': 'text_completion', 'created': 1720275326, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'AI solves problems with right data/model</summary>', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 99, 'completion_tokens': 10, 'total_tokens': 109}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     270.13 ms /    41 runs   (    6.59 ms per token,   151.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     119.96 ms /    81 tokens (    1.48 ms per token,   675.22 tokens per second)\n",
      "llama_print_timings:        eval time =     729.70 ms /    40 runs   (   18.24 ms per token,    54.82 tokens per second)\n",
      "llama_print_timings:       total time =    1152.54 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-0e90d545-38d8-491e-b606-e77f5c73f7cf', 'object': 'text_completion', 'created': 1720275326, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' The main takeaway from the workshop is that artificial intelligence (AI) can solve many problems when given the right data and model. However, finding the right problem, data, and model can be challenging.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 95, 'completion_tokens': 40, 'total_tokens': 135}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      70.86 ms /    11 runs   (    6.44 ms per token,   155.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     151.09 ms /   191 tokens (    0.79 ms per token,  1264.12 tokens per second)\n",
      "llama_print_timings:        eval time =     187.95 ms /    10 runs   (   18.80 ms per token,    53.20 tokens per second)\n",
      "llama_print_timings:       total time =     417.17 ms /   201 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-e3a22a84-52ff-4b47-88de-5e8fd2b80ae7', 'object': 'text_completion', 'created': 1720275327, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'Artificial Intelligence, Machine Learning basics</summary>', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 205, 'completion_tokens': 10, 'total_tokens': 215}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     463.57 ms /    72 runs   (    6.44 ms per token,   155.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     149.08 ms /   187 tokens (    0.80 ms per token,  1254.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1364.67 ms /    71 runs   (   19.22 ms per token,    52.03 tokens per second)\n",
      "llama_print_timings:       total time =    2035.44 ms /   258 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-283162d7-5145-46d0-af32-c54fd818c99c', 'object': 'text_completion', 'created': 1720275328, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': \" The speaker will cover artificial intelligence and machine learning in the workshop. They will discuss different types of machine learning and problems that can be solved using it, including deep learning, which is a subset of machine learning. The speaker notes that they won't delve into deep learning in detail, but aim to provide the necessary fundamentals for those interested in exploring it further.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 201, 'completion_tokens': 71, 'total_tokens': 272}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      65.62 ms /    10 runs   (    6.56 ms per token,   152.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     151.58 ms /   160 tokens (    0.95 ms per token,  1055.58 tokens per second)\n",
      "llama_print_timings:        eval time =     180.11 ms /     9 runs   (   20.01 ms per token,    49.97 tokens per second)\n",
      "llama_print_timings:       total time =     405.70 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-7bc0bc84-f33a-4909-baf6-d3cafed70ec2', 'object': 'text_completion', 'created': 1720275330, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'AI: General vs. Narrow</summary>', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 9, 'total_tokens': 183}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     363.25 ms /    52 runs   (    6.99 ms per token,   143.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     149.78 ms /   156 tokens (    0.96 ms per token,  1041.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1037.98 ms /    51 runs   (   20.35 ms per token,    49.13 tokens per second)\n",
      "llama_print_timings:       total time =    1599.81 ms /   207 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-82a3a801-d376-4970-8571-63bcf50aee59', 'object': 'text_completion', 'created': 1720275330, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'AI can be either general or narrow. General AI refers to a machine that can learn any task a human can perform, but this does not currently exist and experts have varying predictions on when it might happen, ranging from 10-20 years to never.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 170, 'completion_tokens': 51, 'total_tokens': 221}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      53.35 ms /     8 runs   (    6.67 ms per token,   149.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     163.69 ms /   216 tokens (    0.76 ms per token,  1319.54 tokens per second)\n",
      "llama_print_timings:        eval time =     135.93 ms /     7 runs   (   19.42 ms per token,    51.50 tokens per second)\n",
      "llama_print_timings:       total time =     359.14 ms /   223 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-53c8b685-eb62-430e-9fa3-5e6ad861c370', 'object': 'text_completion', 'created': 1720275332, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' Narrow AI: Task-specific intelligence.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 230, 'completion_tokens': 7, 'total_tokens': 237}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     524.58 ms /    80 runs   (    6.56 ms per token,   152.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     162.10 ms /   212 tokens (    0.76 ms per token,  1307.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1607.43 ms /    79 runs   (   20.35 ms per token,    49.15 tokens per second)\n",
      "llama_print_timings:       total time =    2355.86 ms /   291 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-83ca9199-0e6b-4d35-a0cf-049151f0b322', 'object': 'text_completion', 'created': 1720275332, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' The transcript explains that most AI systems today are \"narrow\" or \"specialized\", meaning they excel at one specific task. The example given is a self-driving car, which has multiple AI systems working together to perform tasks such as vision, steering, and route planning. However, this system is not capable of performing tasks outside of its specific domain, such as playing chess or speaking Russian.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 226, 'completion_tokens': 79, 'total_tokens': 305}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far?</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      51.94 ms /     8 runs   (    6.49 ms per token,   154.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =      67.12 ms /    44 tokens (    1.53 ms per token,   655.55 tokens per second)\n",
      "llama_print_timings:        eval time =     137.29 ms /     7 runs   (   19.61 ms per token,    50.99 tokens per second)\n",
      "llama_print_timings:       total time =     261.47 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-5a1db0cf-2bce-4ed4-b7fb-b123be63e38c', 'object': 'text_completion', 'created': 1720275335, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'AI = Narrow AI</summary>', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 7, 'total_tokens': 65}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far?</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     155.84 ms /    24 runs   (    6.49 ms per token,   154.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =      59.96 ms /    40 tokens (    1.50 ms per token,   667.12 tokens per second)\n",
      "llama_print_timings:        eval time =     456.88 ms /    23 runs   (   19.86 ms per token,    50.34 tokens per second)\n",
      "llama_print_timings:       total time =     689.54 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-9935d930-78ce-4339-8092-259a4a28acf5', 'object': 'text_completion', 'created': 1720275335, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' The speaker is clarifying that when they mention \"AI\", they are specifically referring to \"narrow artificial intelligence\".', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 23, 'total_tokens': 77}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      52.77 ms /     8 runs   (    6.60 ms per token,   151.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     129.04 ms /   112 tokens (    1.15 ms per token,   867.94 tokens per second)\n",
      "llama_print_timings:        eval time =     141.69 ms /     7 runs   (   20.24 ms per token,    49.40 tokens per second)\n",
      "llama_print_timings:       total time =     328.34 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-30fb2aa9-c818-4b62-9d88-762de7ef7dcb', 'object': 'text_completion', 'created': 1720275336, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'AI development timeline uncertain</summary>', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 126, 'completion_tokens': 7, 'total_tokens': 133}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     284.55 ms /    44 runs   (    6.47 ms per token,   154.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.57 ms /   108 tokens (    1.19 ms per token,   840.00 tokens per second)\n",
      "llama_print_timings:        eval time =     865.39 ms /    43 runs   (   20.13 ms per token,    49.69 tokens per second)\n",
      "llama_print_timings:       total time =    1310.22 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-9ec56b91-7ea0-4012-907c-4e155a02c2a8', 'object': 'text_completion', 'created': 1720275336, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' The participant asks when they think general AI will be possible, considering it may take many decades or even centuries. They express uncertainty about technological progress, suggesting that predicting the timeline is a \"fool\\'s errand\".', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 122, 'completion_tokens': 43, 'total_tokens': 165}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      90.18 ms /    14 runs   (    6.44 ms per token,   155.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     146.51 ms /   138 tokens (    1.06 ms per token,   941.92 tokens per second)\n",
      "llama_print_timings:        eval time =     263.37 ms /    13 runs   (   20.26 ms per token,    49.36 tokens per second)\n",
      "llama_print_timings:       total time =     510.02 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-2cc3df1c-31df-481e-804f-a5f537f48aed', 'object': 'text_completion', 'created': 1720275337, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' Narrow AI excels at vision, language, and planning tasks.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 152, 'completion_tokens': 13, 'total_tokens': 165}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     540.26 ms /    83 runs   (    6.51 ms per token,   153.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     144.97 ms /   134 tokens (    1.08 ms per token,   924.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1623.39 ms /    82 runs   (   19.80 ms per token,    50.51 tokens per second)\n",
      "llama_print_timings:       total time =    2370.52 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-6d500ee6-cad5-4463-b1de-630c8472b074', 'object': 'text_completion', 'created': 1720275338, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' Narrow AI is particularly good at performing typical tasks that involve vision, language processing, and planning. Examples include:\\n\\n* Vision: understanding or creating images or videos\\n* Language processing: understanding or creating speech or text (e.g. Siri, Amazon Alexa)\\n* Planning: route planning, motion planning, task planning, and more\\n\\nThese tasks can be trained using algorithms, and are categorized as narrow AI tasks.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 148, 'completion_tokens': 82, 'total_tokens': 230}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript into a few words: <transcript>As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =      45.55 ms /     7 runs   (    6.51 ms per token,   153.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     155.35 ms /   249 tokens (    0.62 ms per token,  1602.86 tokens per second)\n",
      "llama_print_timings:        eval time =     106.20 ms /     6 runs   (   17.70 ms per token,    56.49 tokens per second)\n",
      "llama_print_timings:       total time =     311.43 ms /   255 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-5167d379-dca5-41be-8029-e2051666c738', 'object': 'text_completion', 'created': 1720275340, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'Expert systems limitations</summary>', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 263, 'completion_tokens': 6, 'total_tokens': 269}}\n",
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "   \n",
      "<instruction>Summarise the following transcript: <transcript>As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.</transcript></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     572.66 ms\n",
      "llama_print_timings:      sample time =     595.96 ms /    92 runs   (    6.48 ms per token,   154.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     155.94 ms /   245 tokens (    0.64 ms per token,  1571.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1563.89 ms /    91 runs   (   17.19 ms per token,    58.19 tokens per second)\n",
      "llama_print_timings:       total time =    2385.00 ms /   336 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-42e7e46f-359d-48bd-b5e2-35d250e7a3c7', 'object': 'text_completion', 'created': 1720275340, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': ' The speaker discusses the limitations of classical AI methods, such as expert systems and tree search. Expert systems rely on humans writing rules (if this, then that) to solve problems, but this approach can be challenging, especially for complex problems. For example, defining what a table is becomes difficult when trying to write a list of rules. The speaker suggests that these methods can still be useful for certain problems, but are not always effective for more complex tasks.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 259, 'completion_tokens': 91, 'total_tokens': 350}}\n"
     ]
    }
   ],
   "source": [
    "sections_timestamps = generate_timestamps(sections, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamps': (0.0, 18.42), 'text': \"the main takeaway, which is with the right data and the right model, artificial intelligence can solve many problems, but choosing the right problem, finding the right data and training the right model can be difficult. So, there's nothing else that you remember from today's workshop. This slide is the key takeaway.\", 'summary_short': 'AI solves problems with right data/model', 'summary_full': ' The main takeaway from the workshop is that artificial intelligence (AI) can solve many problems when given the right data and model. However, finding the right problem, data, and model can be challenging.'}, {'timestamps': (21.0, 65.28), 'text': \"So, like I said, we'll cover artificial intelligence, we will see a few different examples of tools that can be used to implement artificial intelligence including something called machine learning. We'll talk about different kinds of machine learning and different problems that can be solved by machine learning. And let me just say since probably a lot of you are already wondering, what is deep learning deep learning is either a subset or a subset of a subset of machine learning. So for those of you who are familiar with neural networks or deep learning that is a tool that might be used in machine learning problems, we won't talk about that in any depth at all today but I hope that by the end of the workshop, you guys will have the fundamentals necessary to dig into deep learning at a conceptual level. If you want to do that. Some other time.\", 'summary_short': 'Artificial Intelligence, Machine Learning basics', 'summary_full': \" The speaker will cover artificial intelligence and machine learning in the workshop. They will discuss different types of machine learning and problems that can be solved using it, including deep learning, which is a subset of machine learning. The speaker notes that they won't delve into deep learning in detail, but aim to provide the necessary fundamentals for those interested in exploring it further.\"}, {'timestamps': (66.5, 107.42), 'text': \"All that being said, let's get into basics of AI. So, AI can be general, or it can be narrow. When we talk about general artificial intelligence, it's when a machine can learn any tasks that a human can perform. This does not exist there are no Terminator robots. There are no, there are there is no such thing as general AI and experts, very widely in terms of their predictions on when this may actually happen so there are some people who say oh 1020 years, and there's some people who say, not in our times and some people who say, not ever. So, really really broad range of guesses in any case, most AI.\", 'summary_short': 'AI: General vs. Narrow', 'summary_full': 'AI can be either general or narrow. General AI refers to a machine that can learn any task a human can perform, but this does not currently exist and experts have varying predictions on when it might happen, ranging from 10-20 years to never.'}, {'timestamps': (107.54, 161.28), 'text': \"Sorry, all of the AI that exists today, and most of the AI that you hear people talking about is narrow and narrow AI is when a computer exhibits intelligence at one task. To be clear, you can do pretty impressive things with narrow AI. A self driving car for example, has one narrow AI system that does vision, looks at the road and interprets things. There's another AI system that does steering that controls the car. There's another AI system that does route planning that says on a broad level what are we trying to you know where we going, how do we get there. And when you stitch all those together. So, it's a very impressive system but you cannot sit this card down and play chess with it. This car will not learn how to paint. This car will not learn how to speak Russian. Right, it's doing a specific set of tasks, each of which has been trained separately. And that is narrow AI.\", 'summary_short': ' Narrow AI: Task-specific intelligence.', 'summary_full': ' The transcript explains that most AI systems today are \"narrow\" or \"specialized\", meaning they excel at one specific task. The example given is a self-driving car, which has multiple AI systems working together to perform tasks such as vision, steering, and route planning. However, this system is not capable of performing tasks outside of its specific domain, such as playing chess or speaking Russian.'}, {'timestamps': (161.74, 168.26), 'text': \"So, now on when I say AI I'm talking about narrow artificial intelligence. Any questions so far?\", 'summary_short': 'AI = Narrow AI', 'summary_full': ' The speaker is clarifying that when they mention \"AI\", they are specifically referring to \"narrow artificial intelligence\".'}, {'timestamps': (168.5, 197.02), 'text': \"Question from participant. In January, do you fall in with regard to general AI. When do you think it will be possible. I don't think it's going to happen for a while. Like many many decades, but I also think that it's definitely going to happen at some point. Many decades to maybe centuries I don't know. I think technological progress is hard to guess at so I think it's a fool's errand.\", 'summary_short': 'AI development timeline uncertain', 'summary_full': ' The participant asks when they think general AI will be possible, considering it may take many decades or even centuries. They express uncertainty about technological progress, suggesting that predicting the timeline is a \"fool\\'s errand\".'}, {'timestamps': (199.0, 233.82), 'text': \"So, what does narrow AI actually do well typical tasks, as we've seen with the self driving car example include vision, language processing and planning. These are just a couple of examples. So, vision is going to be understanding or creating images or video language processing, understanding or creating speech or text that's going to be like Siri or Amazon Alexa and planning. So, there's a lot of different kinds of planning, you can do route planning motion planning task planning. All these things fall under the category of narrow AI tasks that you can train an algorithm to do.\", 'summary_short': ' Narrow AI excels at vision, language, and planning tasks.', 'summary_full': ' Narrow AI is particularly good at performing typical tasks that involve vision, language processing, and planning. Examples include:\\n\\n* Vision: understanding or creating images or videos\\n* Language processing: understanding or creating speech or text (e.g. Siri, Amazon Alexa)\\n* Planning: route planning, motion planning, task planning, and more\\n\\nThese tasks can be trained using algorithms, and are categorized as narrow AI tasks.'}, {'timestamps': (234.5, 300.38), 'text': \"As far as how we actually build AI. There's a lot of different ways to classical ways to implement artificial intelligence. So, the things that we're learning about this and being like wow this is not intelligent at all this is super dumb are expert systems and tree search. So in an expert system, it's just a person writing a list of rules, if this than that, if this than that. This can be super useful for certain problems. But a lot of the things that we actually think of as really straightforward, turn out to be quite difficult. So, for example, we can identify a table like that. Very, very easily. We know what a table is. But I challenge you to write a list of rules that can define a table. What color is it, what's it made of, how many legs does it have, what shape is it. And even something like what is a table becomes really, really challenging to answer using an expert system. So these can be really helpful and there are some simple ways, or rather, there are some problems that we can do to solve these problems.\", 'summary_short': 'Expert systems limitations', 'summary_full': ' The speaker discusses the limitations of classical AI methods, such as expert systems and tree search. Expert systems rely on humans writing rules (if this, then that) to solve problems, but this approach can be challenging, especially for complex problems. For example, defining what a table is becomes difficult when trying to write a list of rules. The speaker suggests that these methods can still be useful for certain problems, but are not always effective for more complex tasks.'}]\n"
     ]
    }
   ],
   "source": [
    "print(sections_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI solves problems with right data/model\n"
     ]
    }
   ],
   "source": [
    "print(sections_timestamps[0][\"summary_short\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main takeaway from the workshop is that artificial intelligence (AI) can solve many problems when given the right data and model. However, finding the right problem, data, and model can be challenging.\n"
     ]
    }
   ],
   "source": [
    "print(sections_timestamps[0][\"summary_full\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input video file path = ../../../AI_101(5 mins).mp4\n",
      "Completed processing for :  ../../../AI_101(5 mins).mp4\n"
     ]
    }
   ],
   "source": [
    "from Katna.video import Video\n",
    "from Katna.writer import KeyFrameDiskWriter\n",
    "import os\n",
    "\n",
    "# For windows, the below if condition is must.\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "  # initialize video module\n",
    "  vd = Video()\n",
    "\n",
    "  # number of images to be returned\n",
    "  no_of_frames_to_returned = 12\n",
    "\n",
    "  # initialize diskwriter to save data at desired location\n",
    "  diskwriter = KeyFrameDiskWriter(location=\"selectedframes\")\n",
    "\n",
    "  # Video file path\n",
    "  video_file_path = \"../../../AI_101(5 mins).mp4\"\n",
    "\n",
    "  print(f\"Input video file path = {video_file_path}\")\n",
    "\n",
    "  # extract keyframes and process data with diskwriter\n",
    "  vd.extract_video_keyframes(\n",
    "       no_of_frames=no_of_frames_to_returned, file_path=video_file_path,\n",
    "       writer=diskwriter\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718b5e91d4cb431890ce6f080024f8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\work\\Python_venv\\RAG-chat\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\waiho\\.cache\\huggingface\\hub\\models--microsoft--Florence-2-large-ft. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0f3dcdf1e7455aa8d5347834cb3c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_florence2.py:   0%|          | 0.00/15.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-large-ft:\n",
      "- configuration_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2f93b772d74b80afb9a73ffef657d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_florence2.py:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-large-ft:\n",
      "- modeling_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4e1d66d80a4cceafc04d7d3f5ac8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6de50467394ad894951c612ae6c77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccc71f4f5bb4f3f942f81c3012b4e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb960d001d8f473ca462e636b8b3b846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_florence2.py:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-large-ft:\n",
      "- processing_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "C:\\Users\\waiho\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Florence-2-large-ft\\3112cd2e25c969cfdcb600a01489c56737d943d3\\processing_florence2.py:499: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ee9f37acb048df9dbb149bef57827d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db3847b86b34a1583b8bd3323efc453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67171be60bb64324930f6bd8de944eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM \n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-large-ft\", trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large-ft\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small white car is driving on the street. There is a large field of grass behind the car. There are poles in front of the field. \n"
     ]
    }
   ],
   "source": [
    "prompt = \"<MORE_DETAILED_CAPTION>\"\n",
    "\n",
    "image = Image.open(\"selectedframes/AI_101(5 mins)_0.jpeg\")\n",
    "\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    pixel_values=inputs[\"pixel_values\"],\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=False,\n",
    "    num_beams=3\n",
    ")\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "parsed_answer = processor.post_process_generation(generated_text, task=\"<MORE_DETAILED_CAPTION>\", image_size=(image.width, image.height))\n",
    "\n",
    "print(parsed_answer[\"<MORE_DETAILED_CAPTION>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = []\n",
    "\n",
    "for image_path in os.listdir(\"selectedframes\"):\n",
    "    image = Image.open(f\"selectedframes/{image_path}\")\n",
    "\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        num_beams=3\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "    parsed_answer = processor.post_process_generation(generated_text, task=\"<MORE_DETAILED_CAPTION>\", image_size=(image.width, image.height))\n",
    "\n",
    "    captions.append(parsed_answer[\"<MORE_DETAILED_CAPTION>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<instruction>Given some captions for key frames extracted from a video, summarise the video: <captions><caption>A small white car is driving on the street. There is a large field of grass behind the car. There are poles in front of the field. </caption><caption>A robot head is shown in a black and white photo. The robot has a large head with two eyes and a mouth. There are wires coming out of the head. There is smoke behind the robot.</caption><caption>On the left side of the image there is a robot head. The image is in black and white. On the right side the image is of a small white car. The car is in a parking lot. The parking lot has yellow lines on it. There is a field of grass behind the car.</caption><caption>A small white car is driving on the street. There is a large field of grass behind the car. There are poles in the field. </caption><caption>On the left side of the image there is a robot head. The image is in black and white. On the right side the image is a small white car. The car is on the road. The road has yellow lines on it. The grass is green. The sky is blue.</caption><caption>A robot is shown with red eyes. The robot has a metallic head and arms. There is a text above the robot that says, \"Al can be general or narrow.\"</caption><caption>On the left side of the image there is a robot head. The robot head has glowing red eyes. The background of the robot head is gray. The image on the right side is a small white car. The car is parked in a parking lot. The parking lot has yellow lines on it. There is a field of green grass behind the car.</caption><caption>A small white car is driving on the street. There is a large field of grass behind the car. There are poles in front of the field. </caption><caption>A robot is shown in a black and white photo. The robot has red eyes and a black head. There is a gray background behind the robot.</caption><caption>A small white car is driving on the street. There is a large field of grass behind the car. There are poles in front of the field. </caption><caption>A small white car is driving on the street. There is a large field of grass behind the car. There are poles in front of the field. </caption><caption>On the left side of the image there is a robot head. The robot head has glowing red eyes. The background of the robot head is gray. The image on the right side is a small white car. The car is on the road. The road has yellow lines on it. There is a field of green grass behind the car. There are trees in the field.</caption></captions></instruction><|eot_id|> \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<summary>\n",
      "Args:  {'temperature': 1.0, 'repeat_penalty': 1.025, 'min_p': 0.5, 'top_p': 1.0, 'top_k': 0, 'max_tokens': 4096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     405.48 ms\n",
      "llama_print_timings:      sample time =    1505.87 ms /   230 runs   (    6.55 ms per token,   152.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.85 ms /   436 tokens (    0.67 ms per token,  1488.80 tokens per second)\n",
      "llama_print_timings:        eval time =    4494.62 ms /   229 runs   (   19.63 ms per token,    50.95 tokens per second)\n",
      "llama_print_timings:       total time =    6522.34 ms /   665 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'id': 'cmpl-ff1a06e3-2d4a-4245-8eb1-f9e300cce102', 'object': 'text_completion', 'created': 1720266253, 'model': '../video-summarizer-backend/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'Based on the captions, the video appears to be a collection of scenes featuring a small white car and a robot head. The video starts with the car driving on a street with a large field of grass behind it, with poles in front of the field. The car is then shown parked in a parking lot with yellow lines, and the field of grass is visible behind it.\\n\\nThe robot head is introduced in a black and white photo, with wires coming out of its head and smoke behind it. The robot head is also shown in other scenes, sometimes with glowing red eyes, and sometimes with a gray background.\\n\\nThe video also features a comparison between the car and the robot head, with the two images side by side. The car is shown driving on the road, with yellow lines and green grass behind it, while the robot head is shown with its glowing red eyes and gray background.\\n\\nThe final scene shows the car driving on the street again, with the field of grass and poles in front of it. Overall, the video appears to be a collection of scenes showcasing the car and the robot head, with some comparison and contrast between the two.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 606, 'completion_tokens': 229, 'total_tokens': 835}}\n"
     ]
    }
   ],
   "source": [
    "captions_str = \"\"\n",
    "for caption in captions:\n",
    "    captions_str += \"<caption>\" + caption + \"</caption>\"\n",
    "\n",
    "# Generate summary for captions\n",
    "summarize_captions_prompt = f\"\"\"<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "<instruction>Given some captions for key frames extracted from a video, summarise the video: <captions>{captions_str}</captions></instruction><|eot_id|> \n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "<summary>\"\"\"\n",
    "summary_captions = llm.generate(summarize_captions_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the captions, the video appears to be a collection of scenes featuring a small white car and a robot head. The video starts with the car driving on a street with a large field of grass behind it, with poles in front of the field. The car is then shown parked in a parking lot with yellow lines, and the field of grass is visible behind it.\n",
      "\n",
      "The robot head is introduced in a black and white photo, with wires coming out of its head and smoke behind it. The robot head is also shown in other scenes, sometimes with glowing red eyes, and sometimes with a gray background.\n",
      "\n",
      "The video also features a comparison between the car and the robot head, with the two images side by side. The car is shown driving on the road, with yellow lines and green grass behind it, while the robot head is shown with its glowing red eyes and gray background.\n",
      "\n",
      "The final scene shows the car driving on the street again, with the field of grass and poles in front of it. Overall, the video appears to be a collection of scenes showcasing the car and the robot head, with some comparison and contrast between the two.\n"
     ]
    }
   ],
   "source": [
    "print(summary_captions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
